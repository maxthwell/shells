I1018 05:10:05.826323 20549 exec.cpp:162] Version: 1.7.0
I1018 05:10:05.928951 20558 exec.cpp:236] Executor registered on agent cb40f348-94b8-4f7f-aec2-f1fd15e2ba87-S2
I1018 05:10:05.930101 20558 executor.cpp:130] Registered docker executor on ceph-node1
I1018 05:10:05.930234 20558 executor.cpp:186] Starting task mon-n1.102f06a1-d294-11e8-ab34-024220aa8e88
2018-10-18 05:10:10.715548 7fb3c4648700  0 -- :/2408936250 >> 192.168.136.187:6789/0 pipe(0x7fb3c005c570 sd=4 :0 s=1 pgs=0 cs=0 l=1 c=0x7fb3c0062bd0).fault
2018-10-18 05:10:13.725233 7fb3c4547700  0 -- :/2408936250 >> 192.168.136.187:6789/0 pipe(0x7fb3b4000c80 sd=5 :0 s=1 pgs=0 cs=0 l=1 c=0x7fb3b4001f90).fault
2018-10-18 05:10:16.719804 7fb3c4648700  0 -- :/2408936250 >> 192.168.136.187:6789/0 pipe(0x7fb3b40052a0 sd=4 :0 s=1 pgs=0 cs=0 l=1 c=0x7fb3b4006560).fault
2018-10-18 05:10:17.605666 7f6c2243d540  0 set uid:gid to 167:167 (ceph:ceph)
2018-10-18 05:10:17.605729 7f6c2243d540  0 ceph version 10.2.3-426-gee91e06 (ee91e06d3f2176add959bd8b1b5bfb9fbdcda5a8), process ceph-mon, pid 184
2018-10-18 05:10:17.605962 7f6c2243d540  0 pidfile_write: ignore empty --pid-file
2018-10-18 05:10:17.665136 7f6c2243d540  1 leveldb: Recovering log #121
2018-10-18 05:10:17.672861 7f6c2243d540  1 leveldb: Level-0 table #132: started
2018-10-18 05:10:17.690529 7f6c2243d540  1 leveldb: Level-0 table #132: 1966345 bytes OK
2018-10-18 05:10:17.696409 7f6c2243d540  1 leveldb: Delete type=3 #103

2018-10-18 05:10:17.696535 7f6c2243d540  1 leveldb: Delete type=0 #121

2018-10-18 05:10:17.698091 7f6c2243d540  0 starting mon.ceph-node1 rank 0 at 192.168.136.187:6789/0 mon_data /var/lib/ceph/mon/ceph-ceph-node1 fsid 0c845bdd-bbad-4a3e-95d0-fd414660b87c
2018-10-18 05:10:17.699007 7f6c2243d540  1 mon.ceph-node1@-1(probing) e3 preinit fsid 0c845bdd-bbad-4a3e-95d0-fd414660b87c
2018-10-18 05:10:17.699386 7f6c2243d540  1 mon.ceph-node1@-1(probing).paxosservice(pgmap 1..460) refresh upgraded, format 0 -> 1
2018-10-18 05:10:17.699449 7f6c2243d540  1 mon.ceph-node1@-1(probing).pg v0 on_upgrade discarding in-core PGMap
2018-10-18 05:10:17.700731 7f6c2243d540  0 mon.ceph-node1@-1(probing).mds e1 print_map
e1
enable_multiple, ever_enabled_multiple: 0,0
compat: compat={},rocompat={},incompat={1=base v0.20,2=client writeable ranges,3=default file layouts on dirs,4=dir inode in separate object,5=mds uses versioned encoding,6=dirfrag is stored in omap,8=file layout v2}
 
No filesystems configured

2018-10-18 05:10:17.701251 7f6c2243d540  0 mon.ceph-node1@-1(probing).osd e134 crush map has features 2200130813952, adjusting msgr requires
2018-10-18 05:10:17.701277 7f6c2243d540  0 mon.ceph-node1@-1(probing).osd e134 crush map has features 2200130813952, adjusting msgr requires
2018-10-18 05:10:17.701282 7f6c2243d540  0 mon.ceph-node1@-1(probing).osd e134 crush map has features 2200130813952, adjusting msgr requires
2018-10-18 05:10:17.701284 7f6c2243d540  0 mon.ceph-node1@-1(probing).osd e134 crush map has features 2200130813952, adjusting msgr requires
2018-10-18 05:10:17.701750 7f6c2243d540  1 mon.ceph-node1@-1(probing).log v630 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:10:17.701878 7f6c2243d540  1 mon.ceph-node1@-1(probing).paxosservice(auth 1..52) refresh upgraded, format 0 -> 1
2018-10-18 05:10:17.704071 7f6c2243d540  0 mon.ceph-node1@-1(probing) e3  my rank is now 0 (was -1)
2018-10-18 05:10:17.708875 7f6c17efa700  0 -- 192.168.136.187:6789/0 >> 192.168.136.189:6789/0 pipe(0x55bc8e853400 sd=19 :56972 s=2 pgs=295 cs=1 l=0 c=0x55bc8e8aea80).reader missed message?  skipped from seq 0 to 945081018
2018-10-18 05:10:17.709840 7f6c1a100700  0 log_channel(cluster) log [INF] : mon.ceph-node1 calling new monitor election
2018-10-18 05:10:17.709891 7f6c17df9700  0 -- 192.168.136.187:6789/0 >> 192.168.136.188:6789/0 pipe(0x55bc8e852000 sd=10 :53660 s=2 pgs=392 cs=1 l=0 c=0x55bc8e8aed80).reader missed message?  skipped from seq 0 to 1244873656
2018-10-18 05:10:17.710153 7f6c1a100700  1 mon.ceph-node1@0(electing).elector(220) init, last seen epoch 220
2018-10-18 05:10:17.720371 7f6c1a100700  0 log_channel(cluster) log [INF] : mon.ceph-node1 calling new monitor election
2018-10-18 05:10:17.720490 7f6c1a100700  1 mon.ceph-node1@0(electing).elector(223) init, last seen epoch 223
2018-10-18 05:10:17.727314 7f6c1a100700  0 log_channel(cluster) log [INF] : mon.ceph-node1@0 won leader election with quorum 0,1,2
2018-10-18 05:10:17.728801 7f6c1a100700  0 log_channel(cluster) log [INF] : HEALTH_WARN; 1/3 in osds are down
2018-10-18 05:10:17.884658 7f6c1a100700  1 mon.ceph-node1@0(leader).osd e135 e135: 3 osds: 2 up, 3 in
2018-10-18 05:10:17.884797 7f6c1a100700  1 mon.ceph-node1@0(leader).osd e136 e136: 3 osds: 2 up, 3 in
2018-10-18 05:10:17.885895 7f6c1a100700  1 mon.ceph-node1@0(leader).log v632 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:10:17.886705 7f6c1a100700  0 log_channel(cluster) log [WRN] : mon.1 192.168.136.188:6789/0 clock skew 1160.72s > max 0.05s
2018-10-18 05:10:17.886841 7f6c1a100700  0 log_channel(cluster) log [WRN] : mon.2 192.168.136.189:6789/0 clock skew 1167.51s > max 0.05s
2018-10-18 05:10:17.887396 7f6c1a100700  0 log_channel(cluster) log [INF] : monmap e3: 3 mons at {ceph-node1=192.168.136.187:6789/0,ceph-node2=192.168.136.188:6789/0,ceph-node3=192.168.136.189:6789/0}
2018-10-18 05:10:17.887475 7f6c1a100700  0 log_channel(cluster) log [INF] : pgmap v464: 96 pgs: 96 peering; 1607 bytes data, 122 MB used, 199 GB / 199 GB avail
2018-10-18 05:10:17.887639 7f6c1a100700  0 log_channel(cluster) log [INF] : fsmap e1:
2018-10-18 05:10:17.887985 7f6c1a100700  0 log_channel(cluster) log [INF] : osdmap e136: 3 osds: 2 up, 3 in
2018-10-18 05:10:17.889369 7f6c1a100700  0 log_channel(cluster) log [WRN] : message from mon.2 was stamped 1167.739555s in the future, clocks not synchronized
2018-10-18 05:10:17.944755 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v633 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:10:18.110734 7f6c1a100700  0 mon.ceph-node1@0(leader) e3 handle_command mon_command({"prefix": "health"} v 0) v1
2018-10-18 05:10:18.110796 7f6c1a100700  0 log_channel(audit) log [DBG] : from='client.? 192.168.136.187:0/3413282621' entity='client.bootstrap-osd' cmd=[{"prefix": "health"}]: dispatch
2018-10-18 05:10:21.842166 7f6c1a100700  0 mon.ceph-node1@0(leader) e3 handle_command mon_command({"prefix": "osd find", "id": 0} v 0) v1
2018-10-18 05:10:21.842227 7f6c1a100700  0 log_channel(audit) log [DBG] : from='client.? 192.168.136.187:0/2158710644' entity='osd.0' cmd=[{"prefix": "osd find", "id": 0}]: dispatch
2018-10-18 05:10:22.926385 7f6c1c2d1700  1 mon.ceph-node1@0(leader).osd e137 e137: 3 osds: 3 up, 3 in
2018-10-18 05:10:22.927657 7f6c1c2d1700  0 log_channel(cluster) log [INF] : osd.0 192.168.136.187:6800/21887 boot
2018-10-18 05:10:22.929067 7f6c1c2d1700  0 log_channel(cluster) log [INF] : osdmap e137: 3 osds: 3 up, 3 in
2018-10-18 05:10:22.934414 7f6c1a100700  0 log_channel(cluster) log [WRN] : message from mon.2 was stamped 1167.740296s in the future, clocks not synchronized
2018-10-18 05:10:22.943296 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v465: 96 pgs: 96 peering; 1607 bytes data, 122 MB used, 199 GB / 199 GB avail
2018-10-18 05:10:23.962095 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v636 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:10:28.481365 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v466: 96 pgs: 96 peering; 1607 bytes data, 114 MB used, 199 GB / 199 GB avail
2018-10-18 05:10:29.491423 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v637 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:10:45.013224 7f6c1c2d1700  1 mon.ceph-node1@0(leader).osd e138 e138: 3 osds: 3 up, 3 in
2018-10-18 05:10:45.015209 7f6c1c2d1700  0 log_channel(cluster) log [INF] : osdmap e138: 3 osds: 3 up, 3 in
2018-10-18 05:10:45.077264 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v468: 96 pgs: 43 remapped+peering, 53 peering; 1607 bytes data, 115 MB used, 199 GB / 199 GB avail; 19870 B/s rd, 0 B/s wr, 32 op/s
2018-10-18 05:10:46.026878 7f6c1c2d1700  1 mon.ceph-node1@0(leader).osd e139 e139: 3 osds: 3 up, 3 in
2018-10-18 05:10:46.051012 7f6c1c2d1700  0 log_channel(cluster) log [INF] : osdmap e139: 3 osds: 3 up, 3 in
2018-10-18 05:10:46.061068 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v638 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:10:46.062997 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v469: 96 pgs: 43 remapped+peering, 53 peering; 1607 bytes data, 115 MB used, 199 GB / 199 GB avail
2018-10-18 05:10:47.070934 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v639 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:10:47.889668 7f6c1a100700  0 log_channel(cluster) log [WRN] : mon.2 192.168.136.189:6789/0 clock skew 1167.74s > max 0.05s
2018-10-18 05:10:47.889815 7f6c1a100700  0 log_channel(cluster) log [WRN] : mon.1 192.168.136.188:6789/0 clock skew 1160.94s > max 0.05s
2018-10-18 05:10:48.103463 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v640 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:10:48.106453 7f6c1a100700  0 log_channel(cluster) log [WRN] : message from mon.1 was stamped 1160.938235s in the future, clocks not synchronized
2018-10-18 05:10:49.133581 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v641 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:10:49.223287 7f6c1c2d1700  1 mon.ceph-node1@0(leader).osd e140 e140: 3 osds: 3 up, 3 in
2018-10-18 05:10:49.229224 7f6c1c2d1700  0 log_channel(cluster) log [INF] : osdmap e140: 3 osds: 3 up, 3 in
2018-10-18 05:10:49.266668 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v470: 96 pgs: 17 active+clean, 53 remapped, 26 remapped+peering; 1607 bytes data, 117 MB used, 199 GB / 199 GB avail; 71422 B/s rd, 0 B/s wr, 117 op/s; 0 B/s, 5 objects/s recovering
2018-10-18 05:10:49.298490 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v471: 96 pgs: 17 active+clean, 53 remapped, 26 remapped+peering; 1607 bytes data, 117 MB used, 199 GB / 199 GB avail; 89784 B/s rd, 0 B/s wr, 147 op/s; 0 B/s, 7 objects/s recovering
2018-10-18 05:10:50.216227 7f6c1c2d1700  1 mon.ceph-node1@0(leader).osd e141 e141: 3 osds: 3 up, 3 in
2018-10-18 05:10:50.218754 7f6c1c2d1700  0 log_channel(cluster) log [INF] : osdmap e141: 3 osds: 3 up, 3 in
2018-10-18 05:10:50.243296 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v642 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:10:50.243672 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v472: 96 pgs: 17 active+clean, 53 remapped, 26 remapped+peering; 1607 bytes data, 117 MB used, 199 GB / 199 GB avail
2018-10-18 05:10:51.353080 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v643 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:10:53.504976 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v473: 96 pgs: 33 active+clean, 37 remapped, 26 remapped+peering; 1607 bytes data, 117 MB used, 199 GB / 199 GB avail; 0 B/s, 15 objects/s recovering
2018-10-18 05:10:54.526719 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v644 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:10:54.563878 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v474: 96 pgs: 59 active+clean, 37 remapped; 1607 bytes data, 117 MB used, 199 GB / 199 GB avail; 0 B/s, 53 objects/s recovering
2018-10-18 05:10:55.586211 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v645 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:10:57.605441 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v475: 96 pgs: 96 active+clean; 1607 bytes data, 118 MB used, 199 GB / 199 GB avail; 0 B/s, 54 objects/s recovering
2018-10-18 05:10:58.616619 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v476: 96 pgs: 96 active+clean; 1607 bytes data, 118 MB used, 199 GB / 199 GB avail; 0 B/s, 14 objects/s recovering
2018-10-18 05:10:58.726648 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v646 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:10:59.742546 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v647 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:11:03.010488 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v477: 96 pgs: 96 active+clean; 1607 bytes data, 118 MB used, 199 GB / 199 GB avail
2018-10-18 05:11:04.019774 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v648 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:11:06.582412 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v478: 96 pgs: 96 active+clean; 1607 bytes data, 118 MB used, 199 GB / 199 GB avail
2018-10-18 05:11:07.596290 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v649 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:11:17.703704 7f6c1a901700  0 mon.ceph-node1@0(leader).data_health(224) update_stats avail 69% total 51175 MB, used 15441 MB, avail 35733 MB
2018-10-18 05:11:17.729004 7f6c1a901700  0 log_channel(cluster) log [INF] : HEALTH_WARN; clock skew detected on mon.ceph-node2, mon.ceph-node3; Monitor clock skew detected 
2018-10-18 05:11:17.787659 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v650 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:11:18.801662 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v479: 96 pgs: 96 active+clean; 1607 bytes data, 118 MB used, 199 GB / 199 GB avail
2018-10-18 05:11:19.810686 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v651 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:11:21.606322 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v480: 96 pgs: 96 active+clean; 1607 bytes data, 118 MB used, 199 GB / 199 GB avail
2018-10-18 05:11:22.615211 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v652 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:11:23.643889 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v481: 96 pgs: 96 active+clean; 1607 bytes data, 118 MB used, 199 GB / 199 GB avail
2018-10-18 05:11:24.666379 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v653 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:11:24.686393 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v482: 96 pgs: 96 active+clean; 1607 bytes data, 118 MB used, 199 GB / 199 GB avail
2018-10-18 05:11:25.705417 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v654 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:11:27.607000 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v483: 96 pgs: 96 active+clean; 1607 bytes data, 118 MB used, 199 GB / 199 GB avail
2018-10-18 05:11:28.624078 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v655 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:11:28.641452 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v484: 96 pgs: 96 active+clean; 1607 bytes data, 118 MB used, 199 GB / 199 GB avail
2018-10-18 05:11:29.652330 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v656 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:11:30.664049 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v485: 96 pgs: 96 active+clean; 1607 bytes data, 118 MB used, 199 GB / 199 GB avail
2018-10-18 05:11:31.680314 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v657 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:11:47.892098 7f6c1a100700  0 log_channel(cluster) log [WRN] : mon.2 192.168.136.189:6789/0 clock skew 1167.74s > max 0.05s
2018-10-18 05:11:47.892230 7f6c1a100700  0 log_channel(cluster) log [WRN] : mon.1 192.168.136.188:6789/0 clock skew 1160.94s > max 0.05s
2018-10-18 05:11:47.956541 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v658 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:12:17.704346 7f6c1a901700  0 mon.ceph-node1@0(leader).data_health(224) update_stats avail 69% total 51175 MB, used 15441 MB, avail 35733 MB
2018-10-18 05:12:53.969117 7f6c1a100700  0 log_channel(cluster) log [WRN] : message from mon.1 was stamped 1160.937548s in the future, clocks not synchronized
2018-10-18 05:12:54.044565 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v659 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:13:17.704857 7f6c1a901700  0 mon.ceph-node1@0(leader).data_health(224) update_stats avail 69% total 51175 MB, used 15441 MB, avail 35733 MB
2018-10-18 05:13:17.894130 7f6c1a100700  0 log_channel(cluster) log [WRN] : mon.1 192.168.136.188:6789/0 clock skew 1160.94s > max 0.05s
2018-10-18 05:13:17.894278 7f6c1a100700  0 log_channel(cluster) log [WRN] : mon.2 192.168.136.189:6789/0 clock skew 1167.74s > max 0.05s
2018-10-18 05:13:17.960845 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v660 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:14:17.706378 7f6c1a901700  0 mon.ceph-node1@0(leader).data_health(224) update_stats avail 69% total 51175 MB, used 15441 MB, avail 35733 MB
2018-10-18 05:15:17.706872 7f6c1a901700  0 mon.ceph-node1@0(leader).data_health(224) update_stats avail 69% total 51175 MB, used 15462 MB, avail 35712 MB
2018-10-18 05:15:17.899294 7f6c1a100700  0 log_channel(cluster) log [WRN] : mon.1 192.168.136.188:6789/0 clock skew 1160.94s > max 0.05s
2018-10-18 05:15:17.903013 7f6c1a100700  0 log_channel(cluster) log [WRN] : mon.2 192.168.136.189:6789/0 clock skew 1167.73s > max 0.05s
2018-10-18 05:15:17.972479 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v661 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:16:17.709828 7f6c1a901700  0 mon.ceph-node1@0(leader).data_health(224) update_stats avail 69% total 51175 MB, used 15462 MB, avail 35712 MB
2018-10-18 05:16:18.503021 7f6c1a100700  0 mon.ceph-node1@0(leader) e3 handle_command mon_command({"prefix": "health"} v 0) v1
2018-10-18 05:16:18.503141 7f6c1a100700  0 log_channel(audit) log [DBG] : from='client.? 192.168.136.188:0/649257130' entity='client.bootstrap-rgw' cmd=[{"prefix": "health"}]: dispatch
2018-10-18 05:16:18.911262 7f6c1a100700  0 mon.ceph-node1@0(leader) e3 handle_command mon_command({"prefix": "auth get-or-create", "entity": "client.rgw.ceph-node2", "caps": ["osd", "allow rwx", "mon", "allow rw"]} v 0) v1
2018-10-18 05:16:18.911322 7f6c1a100700  0 log_channel(audit) log [INF] : from='client.? 192.168.136.188:0/4004544741' entity='client.bootstrap-rgw' cmd=[{"prefix": "auth get-or-create", "entity": "client.rgw.ceph-node2", "caps": ["osd", "allow rwx", "mon", "allow rw"]}]: dispatch
2018-10-18 05:16:18.925653 7f6c1c2d1700  0 log_channel(audit) log [INF] : from='client.? 192.168.136.188:0/4004544741' entity='client.bootstrap-rgw' cmd='[{"prefix": "auth get-or-create", "entity": "client.rgw.ceph-node2", "caps": ["osd", "allow rwx", "mon", "allow rw"]}]': finished
2018-10-18 05:16:19.607616 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v663 unable to write to '/var/log/ceph/ceph.audit.log' for channel 'audit': (2) No such file or directory
2018-10-18 05:16:20.619040 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v486: 96 pgs: 96 active+clean; 1607 bytes data, 118 MB used, 199 GB / 199 GB avail; 314 B/s rd, 0 B/s wr, 0 op/s
2018-10-18 05:16:21.633420 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v664 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:16:23.741093 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v487: 96 pgs: 96 active+clean; 1607 bytes data, 119 MB used, 199 GB / 199 GB avail; 1554 B/s rd, 0 B/s wr, 2 op/s
2018-10-18 05:16:24.761825 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v665 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:16:25.784591 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v488: 96 pgs: 96 active+clean; 1607 bytes data, 119 MB used, 199 GB / 199 GB avail; 100 kB/s rd, 0 B/s wr, 168 op/s
2018-10-18 05:16:27.019198 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v666 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:16:28.787666 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v489: 96 pgs: 96 active+clean; 1607 bytes data, 119 MB used, 199 GB / 199 GB avail; 32581 B/s rd, 0 B/s wr, 53 op/s
2018-10-18 05:16:29.809271 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v667 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:16:30.815163 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v490: 96 pgs: 96 active+clean; 1607 bytes data, 119 MB used, 199 GB / 199 GB avail
2018-10-18 05:16:31.823339 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v668 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:17:08.549198 7f6c1a100700  0 mon.ceph-node1@0(leader) e3 handle_command mon_command({"prefix": "health"} v 0) v1
2018-10-18 05:17:08.549264 7f6c1a100700  0 log_channel(audit) log [DBG] : from='client.? 192.168.136.189:0/1693475807' entity='client.bootstrap-rgw' cmd=[{"prefix": "health"}]: dispatch
2018-10-18 05:17:08.954451 7f6c1a100700  0 mon.ceph-node1@0(leader) e3 handle_command mon_command({"prefix": "auth get-or-create", "entity": "client.rgw.ceph-node3", "caps": ["osd", "allow rwx", "mon", "allow rw"]} v 0) v1
2018-10-18 05:17:08.954524 7f6c1a100700  0 log_channel(audit) log [INF] : from='client.? 192.168.136.189:0/3767982810' entity='client.bootstrap-rgw' cmd=[{"prefix": "auth get-or-create", "entity": "client.rgw.ceph-node3", "caps": ["osd", "allow rwx", "mon", "allow rw"]}]: dispatch
2018-10-18 05:17:08.960344 7f6c1c2d1700  0 log_channel(audit) log [INF] : from='client.? 192.168.136.189:0/3767982810' entity='client.bootstrap-rgw' cmd='[{"prefix": "auth get-or-create", "entity": "client.rgw.ceph-node3", "caps": ["osd", "allow rwx", "mon", "allow rw"]}]': finished
2018-10-18 05:17:09.640766 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v670 unable to write to '/var/log/ceph/ceph.audit.log' for channel 'audit': (2) No such file or directory
2018-10-18 05:17:10.655380 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v491: 96 pgs: 96 active+clean; 1607 bytes data, 119 MB used, 199 GB / 199 GB avail; 3290 B/s rd, 0 B/s wr, 5 op/s
2018-10-18 05:17:11.662447 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v671 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:17:13.796098 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v492: 96 pgs: 96 active+clean; 1607 bytes data, 120 MB used, 199 GB / 199 GB avail; 11535 B/s rd, 0 B/s wr, 19 op/s
2018-10-18 05:17:14.878343 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v672 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:17:15.884976 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v493: 96 pgs: 96 active+clean; 1607 bytes data, 121 MB used, 199 GB / 199 GB avail; 93261 B/s rd, 0 B/s wr, 152 op/s
2018-10-18 05:17:16.917500 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v673 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:17:17.710376 7f6c1a901700  0 mon.ceph-node1@0(leader).data_health(224) update_stats avail 69% total 51175 MB, used 15463 MB, avail 35711 MB
2018-10-18 05:17:18.778835 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v494: 96 pgs: 96 active+clean; 1607 bytes data, 121 MB used, 199 GB / 199 GB avail; 24789 B/s rd, 0 B/s wr, 40 op/s
2018-10-18 05:17:19.806951 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v674 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:17:19.816635 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v495: 96 pgs: 96 active+clean; 1607 bytes data, 121 MB used, 199 GB / 199 GB avail
2018-10-18 05:17:20.835154 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v675 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:17:20.850340 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v496: 96 pgs: 96 active+clean; 1607 bytes data, 121 MB used, 199 GB / 199 GB avail
2018-10-18 05:17:21.866098 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v676 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:17:47.905343 7f6c1a100700  0 log_channel(cluster) log [WRN] : mon.2 192.168.136.189:6789/0 clock skew 1167.74s > max 0.05s
2018-10-18 05:17:47.905459 7f6c1a100700  0 log_channel(cluster) log [WRN] : mon.1 192.168.136.188:6789/0 clock skew 1160.94s > max 0.05s
2018-10-18 05:17:47.976642 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v677 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:18:17.712341 7f6c1a901700  0 mon.ceph-node1@0(leader).data_health(224) update_stats avail 69% total 51175 MB, used 15463 MB, avail 35711 MB
2018-10-18 05:19:17.716252 7f6c1a901700  0 mon.ceph-node1@0(leader).data_health(224) update_stats avail 69% total 51175 MB, used 15463 MB, avail 35711 MB
2018-10-18 05:20:17.716755 7f6c1a901700  0 mon.ceph-node1@0(leader).data_health(224) update_stats avail 69% total 51175 MB, used 15463 MB, avail 35711 MB
2018-10-18 05:20:18.971338 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v497: 96 pgs: 96 active+clean; 1607 bytes data, 121 MB used, 199 GB / 199 GB avail; 17 B/s rd, 0 B/s wr, 0 op/s
2018-10-18 05:20:19.980695 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v678 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:20:20.994597 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v498: 96 pgs: 96 active+clean; 1607 bytes data, 121 MB used, 199 GB / 199 GB avail; 596 B/s rd, 0 B/s wr, 0 op/s
2018-10-18 05:20:22.015567 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v679 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:20:23.964046 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v499: 96 pgs: 96 active+clean; 1607 bytes data, 121 MB used, 199 GB / 199 GB avail; 33893 B/s rd, 0 B/s wr, 55 op/s
2018-10-18 05:20:24.974066 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v500: 96 pgs: 96 active+clean; 1607 bytes data, 121 MB used, 199 GB / 199 GB avail; 57843 B/s rd, 0 B/s wr, 94 op/s
2018-10-18 05:20:24.983442 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v680 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:20:26.002433 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v681 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:20:26.016104 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v501: 96 pgs: 96 active+clean; 1607 bytes data, 122 MB used, 199 GB / 199 GB avail; 104 kB/s rd, 0 B/s wr, 173 op/s
2018-10-18 05:20:27.052732 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v682 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:20:29.044511 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v502: 96 pgs: 96 active+clean; 1607 bytes data, 122 MB used, 199 GB / 199 GB avail; 13059 B/s rd, 0 B/s wr, 21 op/s
2018-10-18 05:20:30.054572 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v683 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:20:30.069858 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v503: 96 pgs: 96 active+clean; 1607 bytes data, 122 MB used, 199 GB / 199 GB avail
2018-10-18 05:20:31.077986 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v684 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:20:31.087684 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v504: 96 pgs: 96 active+clean; 1607 bytes data, 121 MB used, 199 GB / 199 GB avail
2018-10-18 05:20:32.095092 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v685 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:20:47.907641 7f6c1a100700  0 log_channel(cluster) log [WRN] : mon.1 192.168.136.188:6789/0 clock skew 1160.94s > max 0.05s
2018-10-18 05:20:47.908356 7f6c1a100700  0 log_channel(cluster) log [WRN] : mon.2 192.168.136.189:6789/0 clock skew 1167.74s > max 0.05s
2018-10-18 05:20:47.983716 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v686 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:21:17.717291 7f6c1a901700  0 mon.ceph-node1@0(leader).data_health(224) update_stats avail 69% total 51175 MB, used 15463 MB, avail 35711 MB
2018-10-18 05:22:17.717859 7f6c1a901700  0 mon.ceph-node1@0(leader).data_health(224) update_stats avail 69% total 51175 MB, used 15463 MB, avail 35711 MB
2018-10-18 05:22:48.987933 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v505: 96 pgs: 96 active+clean; 1607 bytes data, 121 MB used, 199 GB / 199 GB avail; 312 B/s rd, 0 op/s
2018-10-18 05:22:50.143008 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v506: 96 pgs: 96 active+clean; 1607 bytes data, 121 MB used, 199 GB / 199 GB avail; 662 B/s rd, 0 op/s
2018-10-18 05:22:50.185942 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v687 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:22:50.250686 7f6c1c2d1700  1 mon.ceph-node1@0(leader).osd e142 e142: 3 osds: 3 up, 3 in
2018-10-18 05:22:50.268234 7f6c1c2d1700  0 log_channel(cluster) log [INF] : osdmap e142: 3 osds: 3 up, 3 in
2018-10-18 05:22:50.297202 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v507: 104 pgs: 8 creating, 96 active+clean; 1607 bytes data, 121 MB used, 199 GB / 199 GB avail; 36622 B/s rd, 53 op/s
2018-10-18 05:22:51.200123 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v688 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:22:51.290007 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v508: 104 pgs: 8 creating, 96 active+clean; 1607 bytes data, 122 MB used, 199 GB / 199 GB avail; 17492 B/s rd, 25 op/s
2018-10-18 05:22:51.303770 7f6c1c2d1700  1 mon.ceph-node1@0(leader).osd e143 e143: 3 osds: 3 up, 3 in
2018-10-18 05:22:51.305653 7f6c1c2d1700  0 log_channel(cluster) log [INF] : osdmap e143: 3 osds: 3 up, 3 in
2018-10-18 05:22:51.318590 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v509: 104 pgs: 8 creating, 96 active+clean; 1607 bytes data, 122 MB used, 199 GB / 199 GB avail; 19454 B/s rd, 28 op/s
2018-10-18 05:22:52.301820 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v689 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:22:53.942879 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v510: 104 pgs: 5 creating, 99 active+clean; 2079 bytes data, 122 MB used, 199 GB / 199 GB avail; 1552 B/s rd, 1164 B/s wr, 6 op/s
2018-10-18 05:22:55.205100 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v511: 104 pgs: 2 creating, 102 active+clean; 2079 bytes data, 122 MB used, 199 GB / 199 GB avail; 1126 B/s rd, 844 B/s wr, 5 op/s
2018-10-18 05:22:55.245662 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v690 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:22:56.254062 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v512: 104 pgs: 104 active+clean; 2079 bytes data, 122 MB used, 199 GB / 199 GB avail; 0 B/s rd, 0 B/s wr, 0 op/s
2018-10-18 05:22:56.264632 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v691 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:22:57.290990 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v692 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:22:58.924139 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v513: 104 pgs: 104 active+clean; 2079 bytes data, 122 MB used, 199 GB / 199 GB avail
2018-10-18 05:22:59.938754 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v693 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:22:59.955506 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v514: 104 pgs: 104 active+clean; 2079 bytes data, 122 MB used, 199 GB / 199 GB avail
2018-10-18 05:23:00.977605 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v694 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:23:00.990417 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v515: 104 pgs: 104 active+clean; 2079 bytes data, 122 MB used, 199 GB / 199 GB avail
2018-10-18 05:23:02.003315 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v695 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:23:17.720154 7f6c1a901700  0 mon.ceph-node1@0(leader).data_health(224) update_stats avail 69% total 51175 MB, used 15464 MB, avail 35710 MB
2018-10-18 05:23:20.011362 7f6c1a100700  0 log_channel(cluster) log [WRN] : message from mon.1 was stamped 1160.937562s in the future, clocks not synchronized
2018-10-18 05:23:20.077159 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v696 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:23:40.340828 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v516: 104 pgs: 104 active+clean; 2079 bytes data, 122 MB used, 199 GB / 199 GB avail; 156 B/s rd, 0 op/s
2018-10-18 05:23:41.364120 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v697 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:23:43.935399 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v517: 104 pgs: 104 active+clean; 2079 bytes data, 122 MB used, 199 GB / 199 GB avail; 500 B/s rd, 0 op/s
2018-10-18 05:23:44.959436 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v698 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:23:44.975393 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v518: 104 pgs: 104 active+clean; 2079 bytes data, 122 MB used, 199 GB / 199 GB avail; 6893 B/s rd, 9 op/s
2018-10-18 05:23:45.993316 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v699 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:23:46.005577 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v519: 104 pgs: 104 active+clean; 2079 bytes data, 122 MB used, 199 GB / 199 GB avail; 8004 B/s rd, 11 op/s
2018-10-18 05:23:47.041285 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v700 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:23:48.941742 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v520: 104 pgs: 104 active+clean; 2079 bytes data, 122 MB used, 199 GB / 199 GB avail
2018-10-18 05:23:49.962489 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v701 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:23:49.982462 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v521: 104 pgs: 104 active+clean; 2079 bytes data, 122 MB used, 199 GB / 199 GB avail
2018-10-18 05:23:51.008807 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v702 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:23:51.023184 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v522: 104 pgs: 104 active+clean; 2079 bytes data, 122 MB used, 199 GB / 199 GB avail
2018-10-18 05:23:52.050592 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v703 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:23:54.060117 7f6c1c2d1700  1 mon.ceph-node1@0(leader).osd e144 e144: 3 osds: 3 up, 3 in
2018-10-18 05:23:54.063097 7f6c1c2d1700  0 log_channel(cluster) log [INF] : osdmap e144: 3 osds: 3 up, 3 in
2018-10-18 05:23:54.085262 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v523: 112 pgs: 8 creating, 104 active+clean; 2079 bytes data, 122 MB used, 199 GB / 199 GB avail
2018-10-18 05:23:55.082566 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v704 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:23:55.104486 7f6c1c2d1700  1 mon.ceph-node1@0(leader).osd e145 e145: 3 osds: 3 up, 3 in
2018-10-18 05:23:55.109410 7f6c1c2d1700  0 log_channel(cluster) log [INF] : osdmap e145: 3 osds: 3 up, 3 in
2018-10-18 05:23:55.123941 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v524: 112 pgs: 8 creating, 104 active+clean; 2079 bytes data, 122 MB used, 199 GB / 199 GB avail
2018-10-18 05:23:56.126440 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v705 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:23:56.144227 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v525: 112 pgs: 4 creating, 108 active+clean; 2079 bytes data, 122 MB used, 199 GB / 199 GB avail
2018-10-18 05:23:57.152530 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v706 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:23:58.954132 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v526: 112 pgs: 1 creating, 111 active+clean; 2079 bytes data, 122 MB used, 199 GB / 199 GB avail; 0 B/s wr, 2 op/s
2018-10-18 05:23:59.960811 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v707 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:23:59.995270 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v527: 112 pgs: 112 active+clean; 2079 bytes data, 122 MB used, 199 GB / 199 GB avail; 4277 B/s rd, 0 B/s wr, 7 op/s
2018-10-18 05:24:01.002734 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v708 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:24:01.009972 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v528: 112 pgs: 112 active+clean; 2079 bytes data, 122 MB used, 199 GB / 199 GB avail; 7968 B/s rd, 0 B/s wr, 9 op/s
2018-10-18 05:24:02.020201 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v709 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:24:03.940809 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v529: 112 pgs: 112 active+clean; 2079 bytes data, 122 MB used, 199 GB / 199 GB avail; 1286 B/s rd, 1 op/s
2018-10-18 05:24:04.960346 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v710 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:24:04.977660 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v530: 112 pgs: 112 active+clean; 2079 bytes data, 122 MB used, 199 GB / 199 GB avail; 1295 B/s rd, 1 op/s
2018-10-18 05:24:04.994879 7f6c16313700  1 leveldb: Level-0 table #135: started
2018-10-18 05:24:05.016310 7f6c16313700  1 leveldb: Level-0 table #135: 3131842 bytes OK
2018-10-18 05:24:05.019425 7f6c16313700  1 leveldb: Delete type=0 #133

2018-10-18 05:24:05.021102 7f6c16313700  1 leveldb: Manual compaction at level-0 from 'paxos\x00753' @ 72057594037927935 : 1 .. 'paxos\x001005' @ 0 : 0; will stop at 'pgmap_pg\x004.7' @ 18344 : 1

2018-10-18 05:24:05.021133 7f6c16313700  1 leveldb: Compacting 2@0 + 5@1 files
2018-10-18 05:24:05.039456 7f6c16313700  1 leveldb: Generated table #136: 283 keys, 2141072 bytes
2018-10-18 05:24:05.053362 7f6c16313700  1 leveldb: Generated table #137: 165 keys, 2162851 bytes
2018-10-18 05:24:05.068783 7f6c16313700  1 leveldb: Generated table #138: 372 keys, 2099541 bytes
2018-10-18 05:24:05.093000 7f6c16313700  1 leveldb: Generated table #139: 198 keys, 2105000 bytes
2018-10-18 05:24:05.115133 7f6c16313700  1 leveldb: Generated table #140: 181 keys, 2133662 bytes
2018-10-18 05:24:05.130077 7f6c16313700  1 leveldb: Generated table #141: 825 keys, 1770280 bytes
2018-10-18 05:24:05.130478 7f6c16313700  1 leveldb: Compacted 2@0 + 5@1 files => 12412406 bytes
2018-10-18 05:24:05.131086 7f6c16313700  1 leveldb: compacted to: files[ 0 6 2 0 0 0 0 ]
2018-10-18 05:24:05.131370 7f6c16313700  1 leveldb: Delete type=2 #127

2018-10-18 05:24:05.132206 7f6c16313700  1 leveldb: Delete type=2 #128

2018-10-18 05:24:05.132950 7f6c16313700  1 leveldb: Delete type=2 #124

2018-10-18 05:24:05.133773 7f6c16313700  1 leveldb: Delete type=2 #125

2018-10-18 05:24:05.134487 7f6c16313700  1 leveldb: Delete type=2 #126

2018-10-18 05:24:05.136000 7f6c16313700  1 leveldb: Delete type=2 #132

2018-10-18 05:24:05.136768 7f6c16313700  1 leveldb: Delete type=2 #135

2018-10-18 05:24:05.137809 7f6c16313700  1 leveldb: Compacting 1@1 + 2@2 files
2018-10-18 05:24:05.157200 7f6c16313700  1 leveldb: Generated table #142: 901 keys, 2140710 bytes
2018-10-18 05:24:05.172328 7f6c16313700  1 leveldb: Generated table #143: 161 keys, 2121237 bytes
2018-10-18 05:24:05.188822 7f6c16313700  1 leveldb: Generated table #144: 156 keys, 2132919 bytes
2018-10-18 05:24:05.191318 7f6c16313700  1 leveldb: Generated table #145: 1 keys, 13481 bytes
2018-10-18 05:24:05.191355 7f6c16313700  1 leveldb: Compacted 1@1 + 2@2 files => 6408347 bytes
2018-10-18 05:24:05.191643 7f6c16313700  1 leveldb: compacted to: files[ 0 5 4 0 0 0 0 ]
2018-10-18 05:24:05.192068 7f6c16313700  1 leveldb: Delete type=2 #129

2018-10-18 05:24:05.193011 7f6c16313700  1 leveldb: Delete type=2 #130

2018-10-18 05:24:05.193892 7f6c16313700  1 leveldb: Delete type=2 #136

2018-10-18 05:24:05.194529 7f6c16313700  1 leveldb: Manual compaction at level-0 from 'pgmap_pg\x004.7' @ 18344 : 1 .. 'paxos\x001005' @ 0 : 0; will stop at (end)

2018-10-18 05:24:05.983574 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v711 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:24:06.018311 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v531: 112 pgs: 112 active+clean; 2079 bytes data, 122 MB used, 199 GB / 199 GB avail; 995 B/s rd, 1 op/s
2018-10-18 05:24:07.044313 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v712 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:24:13.955087 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v532: 112 pgs: 112 active+clean; 2079 bytes data, 122 MB used, 199 GB / 199 GB avail; 568 B/s rd, 0 B/s wr, 2 op/s
2018-10-18 05:24:14.973291 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v713 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:24:14.997540 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v533: 112 pgs: 112 active+clean; 2079 bytes data, 122 MB used, 199 GB / 199 GB avail; 799 B/s rd, 0 B/s wr, 2 op/s
2018-10-18 05:24:16.013478 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v714 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:24:16.032361 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v534: 112 pgs: 112 active+clean; 2079 bytes data, 122 MB used, 199 GB / 199 GB avail; 1989 B/s rd, 0 B/s wr, 3 op/s
2018-10-18 05:24:17.058585 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v715 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:24:17.721577 7f6c1a901700  0 mon.ceph-node1@0(leader).data_health(224) update_stats avail 69% total 51175 MB, used 15461 MB, avail 35713 MB
2018-10-18 05:24:17.915069 7f6c1a100700  0 log_channel(cluster) log [WRN] : mon.1 192.168.136.188:6789/0 clock skew 1160.94s > max 0.05s
2018-10-18 05:24:17.915370 7f6c1a100700  0 log_channel(cluster) log [WRN] : mon.2 192.168.136.189:6789/0 clock skew 1167.74s > max 0.05s
2018-10-18 05:24:18.125738 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v716 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:24:19.138209 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v535: 112 pgs: 112 active+clean; 2079 bytes data, 122 MB used, 199 GB / 199 GB avail
2018-10-18 05:24:20.151204 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v717 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:24:21.163711 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v536: 112 pgs: 112 active+clean; 2079 bytes data, 122 MB used, 199 GB / 199 GB avail
2018-10-18 05:24:22.188306 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v718 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:25:17.722741 7f6c1a901700  0 mon.ceph-node1@0(leader).data_health(224) update_stats avail 69% total 51175 MB, used 15461 MB, avail 35713 MB
2018-10-18 05:25:20.386449 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v537: 112 pgs: 112 active+clean; 2079 bytes data, 122 MB used, 199 GB / 199 GB avail
2018-10-18 05:25:21.409464 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v719 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:25:23.990979 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v538: 112 pgs: 112 active+clean; 2079 bytes data, 122 MB used, 199 GB / 199 GB avail; 65 B/s rd, 0 B/s wr, 0 op/s
2018-10-18 05:25:25.003537 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v720 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:25:25.023431 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v539: 112 pgs: 112 active+clean; 2079 bytes data, 122 MB used, 199 GB / 199 GB avail; 888 B/s rd, 0 B/s wr, 1 op/s
2018-10-18 05:25:26.030876 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v721 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:25:26.048477 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v540: 112 pgs: 112 active+clean; 2079 bytes data, 122 MB used, 199 GB / 199 GB avail
2018-10-18 05:25:27.063625 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v722 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:25:28.984965 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v541: 112 pgs: 112 active+clean; 2079 bytes data, 122 MB used, 199 GB / 199 GB avail
2018-10-18 05:25:30.001129 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v723 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:25:30.008968 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v542: 112 pgs: 112 active+clean; 2079 bytes data, 122 MB used, 199 GB / 199 GB avail
2018-10-18 05:25:31.015245 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v724 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:25:35.506235 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v543: 112 pgs: 112 active+clean; 2079 bytes data, 122 MB used, 199 GB / 199 GB avail; 954 B/s rd, 1 op/s
2018-10-18 05:25:36.516504 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v725 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:25:38.997791 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v544: 112 pgs: 112 active+clean; 2079 bytes data, 122 MB used, 199 GB / 199 GB avail; 2393 B/s rd, 3 op/s
2018-10-18 05:25:40.014296 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v726 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:25:40.037686 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v545: 112 pgs: 112 active+clean; 2079 bytes data, 122 MB used, 199 GB / 199 GB avail; 6909 B/s rd, 9 op/s
2018-10-18 05:25:41.063880 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v727 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:25:41.082729 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v546: 112 pgs: 112 active+clean; 2079 bytes data, 122 MB used, 199 GB / 199 GB avail; 7912 B/s rd, 11 op/s
2018-10-18 05:25:42.098776 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v728 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:25:44.004599 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v547: 112 pgs: 112 active+clean; 2079 bytes data, 122 MB used, 199 GB / 199 GB avail
2018-10-18 05:25:45.019613 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v729 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:25:45.032712 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v548: 112 pgs: 112 active+clean; 2079 bytes data, 122 MB used, 199 GB / 199 GB avail
2018-10-18 05:25:46.068116 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v730 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:25:46.094212 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v549: 112 pgs: 112 active+clean; 2079 bytes data, 122 MB used, 199 GB / 199 GB avail
2018-10-18 05:25:47.118800 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v731 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:26:17.725451 7f6c1a901700  0 mon.ceph-node1@0(leader).data_health(224) update_stats avail 69% total 51175 MB, used 15462 MB, avail 35712 MB
2018-10-18 05:26:20.427057 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v550: 112 pgs: 112 active+clean; 2079 bytes data, 122 MB used, 199 GB / 199 GB avail; 1787 B/s rd, 0 B/s wr, 2 op/s
2018-10-18 05:26:21.443219 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v732 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:26:24.007520 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v551: 112 pgs: 112 active+clean; 2079 bytes data, 122 MB used, 199 GB / 199 GB avail; 3317 B/s rd, 0 B/s wr, 5 op/s
2018-10-18 05:26:25.031839 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v733 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:26:25.050304 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v552: 112 pgs: 112 active+clean; 2079 bytes data, 123 MB used, 199 GB / 199 GB avail; 50808 B/s rd, 0 B/s wr, 82 op/s
2018-10-18 05:26:26.078680 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v734 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:26:26.094232 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v553: 112 pgs: 112 active+clean; 2079 bytes data, 123 MB used, 199 GB / 199 GB avail; 125 kB/s rd, 0 B/s wr, 208 op/s
2018-10-18 05:26:27.123242 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v735 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:26:29.006686 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v554: 112 pgs: 112 active+clean; 2079 bytes data, 123 MB used, 199 GB / 199 GB avail; 23914 B/s rd, 0 B/s wr, 38 op/s
2018-10-18 05:26:30.018753 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v736 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:26:30.027805 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v555: 112 pgs: 112 active+clean; 2079 bytes data, 123 MB used, 199 GB / 199 GB avail
2018-10-18 05:26:31.043136 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v737 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:26:31.054940 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v556: 112 pgs: 112 active+clean; 2079 bytes data, 123 MB used, 199 GB / 199 GB avail
2018-10-18 05:26:32.067401 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v738 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:27:10.445204 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v557: 112 pgs: 112 active+clean; 2079 bytes data, 123 MB used, 199 GB / 199 GB avail; 1793 B/s rd, 0 B/s wr, 2 op/s
2018-10-18 05:27:11.455712 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v739 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:27:14.044650 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v558: 112 pgs: 112 active+clean; 2079 bytes data, 123 MB used, 199 GB / 199 GB avail; 3144 B/s rd, 0 B/s wr, 5 op/s
2018-10-18 05:27:15.064355 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v740 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:27:15.073390 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v559: 112 pgs: 112 active+clean; 2079 bytes data, 124 MB used, 199 GB / 199 GB avail; 50641 B/s rd, 0 B/s wr, 82 op/s
2018-10-18 05:27:16.087233 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v741 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:27:16.100242 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v560: 112 pgs: 112 active+clean; 2079 bytes data, 124 MB used, 199 GB / 199 GB avail; 120 kB/s rd, 0 B/s wr, 201 op/s
2018-10-18 05:27:17.123247 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v742 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:27:17.726150 7f6c1a901700  0 mon.ceph-node1@0(leader).data_health(224) update_stats avail 69% total 51175 MB, used 15462 MB, avail 35712 MB
2018-10-18 05:27:19.023297 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v561: 112 pgs: 112 active+clean; 2079 bytes data, 124 MB used, 199 GB / 199 GB avail; 21669 B/s rd, 0 B/s wr, 35 op/s
2018-10-18 05:27:20.048429 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v743 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:27:20.072083 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v562: 112 pgs: 112 active+clean; 2079 bytes data, 124 MB used, 199 GB / 199 GB avail
2018-10-18 05:27:21.085022 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v744 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:27:21.092678 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v563: 112 pgs: 112 active+clean; 2079 bytes data, 124 MB used, 199 GB / 199 GB avail
2018-10-18 05:27:22.108624 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v745 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:28:17.726670 7f6c1a901700  0 mon.ceph-node1@0(leader).data_health(224) update_stats avail 69% total 51175 MB, used 15462 MB, avail 35712 MB
2018-10-18 05:28:17.917775 7f6c1a100700  0 log_channel(cluster) log [WRN] : mon.2 192.168.136.189:6789/0 clock skew 1167.74s > max 0.05s
2018-10-18 05:28:17.919296 7f6c1a100700  0 log_channel(cluster) log [WRN] : mon.1 192.168.136.188:6789/0 clock skew 1160.93s > max 0.05s
2018-10-18 05:28:17.992374 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v746 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:28:34.073028 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v564: 112 pgs: 112 active+clean; 2079 bytes data, 124 MB used, 199 GB / 199 GB avail; 238 B/s rd, 0 op/s
2018-10-18 05:28:35.087443 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v747 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:28:35.101725 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v565: 112 pgs: 112 active+clean; 2079 bytes data, 124 MB used, 199 GB / 199 GB avail; 456 B/s rd, 0 op/s
2018-10-18 05:28:36.111392 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v748 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:28:36.121928 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v566: 112 pgs: 112 active+clean; 2079 bytes data, 124 MB used, 199 GB / 199 GB avail; 11481 B/s rd, 17 op/s
2018-10-18 05:28:37.139558 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v749 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:28:39.066191 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v567: 112 pgs: 112 active+clean; 2079 bytes data, 124 MB used, 199 GB / 199 GB avail; 1804 B/s rd, 2 op/s
2018-10-18 05:28:40.080414 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v750 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:28:40.098309 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v568: 112 pgs: 112 active+clean; 2079 bytes data, 124 MB used, 199 GB / 199 GB avail
2018-10-18 05:28:41.109001 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v751 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:28:41.116000 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v569: 112 pgs: 112 active+clean; 2079 bytes data, 124 MB used, 199 GB / 199 GB avail
2018-10-18 05:28:42.248448 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v752 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:28:42.884243 7f6c16313700  1 leveldb: Level-0 table #147: started
2018-10-18 05:28:42.894799 7f6c16313700  1 leveldb: Level-0 table #147: 1346452 bytes OK
2018-10-18 05:28:42.895421 7f6c16313700  1 leveldb: Delete type=0 #134

2018-10-18 05:28:42.896369 7f6c16313700  1 leveldb: Manual compaction at level-0 from 'logm\x000' @ 72057594037927935 : 1 .. 'logm\x00252' @ 0 : 0; will stop at 'pgmap_pg\x006.0' @ 21982 : 1

2018-10-18 05:28:42.896399 7f6c16313700  1 leveldb: Compacting 1@0 + 5@1 files
2018-10-18 05:28:42.917842 7f6c16313700  1 leveldb: Generated table #148: 650 keys, 2143516 bytes
2018-10-18 05:28:42.941395 7f6c16313700  1 leveldb: Generated table #149: 368 keys, 2098711 bytes
2018-10-18 05:28:42.956882 7f6c16313700  1 leveldb: Generated table #150: 204 keys, 2154676 bytes
2018-10-18 05:28:42.971804 7f6c16313700  1 leveldb: Generated table #151: 178 keys, 2139959 bytes
2018-10-18 05:28:42.986387 7f6c16313700  1 leveldb: Generated table #152: 232 keys, 2109531 bytes
2018-10-18 05:28:42.992558 7f6c16313700  1 leveldb: Generated table #153: 707 keys, 269005 bytes
2018-10-18 05:28:42.992623 7f6c16313700  1 leveldb: Compacted 1@0 + 5@1 files => 10915398 bytes
2018-10-18 05:28:42.993718 7f6c16313700  1 leveldb: compacted to: files[ 0 6 4 0 0 0 0 ]
2018-10-18 05:28:42.994049 7f6c16313700  1 leveldb: Delete type=2 #138

2018-10-18 05:28:42.994939 7f6c16313700  1 leveldb: Delete type=2 #139

2018-10-18 05:28:42.995665 7f6c16313700  1 leveldb: Delete type=2 #140

2018-10-18 05:28:42.996382 7f6c16313700  1 leveldb: Delete type=2 #141

2018-10-18 05:28:42.997035 7f6c16313700  1 leveldb: Delete type=2 #137

2018-10-18 05:28:42.997838 7f6c16313700  1 leveldb: Delete type=2 #147

2018-10-18 05:28:42.998313 7f6c16313700  1 leveldb: Compacting 1@1 + 4@2 files
2018-10-18 05:28:43.018447 7f6c16313700  1 leveldb: Generated table #154: 703 keys, 2147386 bytes
2018-10-18 05:28:43.035972 7f6c16313700  1 leveldb: Generated table #155: 155 keys, 2107772 bytes
2018-10-18 05:28:43.047480 7f6c16313700  1 leveldb: Generated table #156: 116 keys, 1538417 bytes
2018-10-18 05:28:43.047526 7f6c16313700  1 leveldb: Compacted 1@1 + 4@2 files => 5793575 bytes
2018-10-18 05:28:43.050092 7f6c16313700  1 leveldb: compacted to: files[ 0 5 3 0 0 0 0 ]
2018-10-18 05:28:43.050304 7f6c16313700  1 leveldb: Delete type=2 #145

2018-10-18 05:28:43.050919 7f6c16313700  1 leveldb: Delete type=2 #142

2018-10-18 05:28:43.054579 7f6c16313700  1 leveldb: Delete type=2 #143

2018-10-18 05:28:43.055402 7f6c16313700  1 leveldb: Delete type=2 #144

2018-10-18 05:28:43.056313 7f6c16313700  1 leveldb: Delete type=2 #148

2018-10-18 05:28:43.056988 7f6c16313700  1 leveldb: Manual compaction at level-0 from 'pgmap_pg\x006.0' @ 21982 : 1 .. 'logm\x00252' @ 0 : 0; will stop at (end)

2018-10-18 05:28:43.057136 7f6c16313700  1 leveldb: Manual compaction at level-1 from 'logm\x000' @ 72057594037927935 : 1 .. 'logm\x00252' @ 0 : 0; will stop at (end)

2018-10-18 05:28:43.057464 7f6c16313700  1 leveldb: Level-0 table #158: started
2018-10-18 05:28:43.057512 7f6c16313700  1 leveldb: Level-0 table #158: 0 bytes OK
2018-10-18 05:28:43.058964 7f6c16313700  1 leveldb: Delete type=0 #146

2018-10-18 05:28:43.059168 7f6c16313700  1 leveldb: Manual compaction at level-0 from 'logm\x00full_0' @ 72057594037927935 : 1 .. 'logm\x00full_252' @ 0 : 0; will stop at (end)

2018-10-18 05:28:43.059331 7f6c16313700  1 leveldb: Manual compaction at level-1 from 'logm\x00full_0' @ 72057594037927935 : 1 .. 'logm\x00full_252' @ 0 : 0; will stop at (end)

2018-10-18 05:29:17.727605 7f6c1a901700  0 mon.ceph-node1@0(leader).data_health(224) update_stats avail 69% total 51175 MB, used 15459 MB, avail 35715 MB
2018-10-18 05:29:24.075349 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v570: 112 pgs: 112 active+clean; 2079 bytes data, 124 MB used, 199 GB / 199 GB avail; 858 B/s rd, 47 B/s wr, 1 op/s
2018-10-18 05:29:25.103503 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v753 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:29:25.133682 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v571: 112 pgs: 112 active+clean; 2079 bytes data, 124 MB used, 199 GB / 199 GB avail; 1210 B/s rd, 46 B/s wr, 1 op/s
2018-10-18 05:29:26.152350 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v754 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:29:26.174010 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v572: 112 pgs: 112 active+clean; 2079 bytes data, 124 MB used, 199 GB / 199 GB avail; 14826 B/s rd, 21 op/s
2018-10-18 05:29:27.178944 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v755 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:29:29.082267 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v573: 112 pgs: 112 active+clean; 2079 bytes data, 124 MB used, 199 GB / 199 GB avail; 10789 B/s rd, 256 B/s wr, 16 op/s
2018-10-18 05:29:30.100928 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v756 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:29:30.124523 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v574: 112 pgs: 112 active+clean; 2079 bytes data, 124 MB used, 199 GB / 199 GB avail; 11411 B/s rd, 259 B/s wr, 17 op/s
2018-10-18 05:29:31.143149 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v757 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:29:31.175570 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v575: 112 pgs: 112 active+clean; 2079 bytes data, 124 MB used, 199 GB / 199 GB avail; 8426 B/s rd, 495 B/s wr, 15 op/s
2018-10-18 05:29:32.191646 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v758 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:29:34.079421 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v576: 112 pgs: 112 active+clean; 2079 bytes data, 124 MB used, 199 GB / 199 GB avail; 1542 B/s rd, 257 B/s wr, 6 op/s
2018-10-18 05:29:35.106289 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v759 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:29:35.146437 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v577: 112 pgs: 112 active+clean; 2079 bytes data, 124 MB used, 199 GB / 199 GB avail; 7519 B/s rd, 0 B/s wr, 12 op/s
2018-10-18 05:29:36.160875 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v760 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:29:36.177542 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v578: 112 pgs: 112 active+clean; 2079 bytes data, 124 MB used, 199 GB / 199 GB avail; 11808 B/s rd, 0 B/s wr, 13 op/s
2018-10-18 05:29:37.186007 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v761 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:29:39.076686 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v579: 112 pgs: 112 active+clean; 2079 bytes data, 124 MB used, 199 GB / 199 GB avail; 770 B/s rd, 0 B/s wr, 3 op/s
2018-10-18 05:29:40.113212 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v762 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:29:40.143442 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v580: 112 pgs: 112 active+clean; 2079 bytes data, 124 MB used, 199 GB / 199 GB avail; 1819 B/s rd, 0 B/s wr, 5 op/s
2018-10-18 05:29:41.157217 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v763 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:29:41.168379 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v581: 112 pgs: 112 active+clean; 2079 bytes data, 124 MB used, 199 GB / 199 GB avail; 1969 B/s rd, 0 B/s wr, 3 op/s
2018-10-18 05:29:42.181145 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v764 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:29:44.075959 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v582: 112 pgs: 112 active+clean; 2079 bytes data, 124 MB used, 199 GB / 199 GB avail; 771 B/s rd, 0 B/s wr, 3 op/s
2018-10-18 05:29:45.085603 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v765 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:29:45.103956 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v583: 112 pgs: 112 active+clean; 2079 bytes data, 124 MB used, 199 GB / 199 GB avail; 1824 B/s rd, 0 B/s wr, 5 op/s
2018-10-18 05:29:46.125223 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v766 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:29:46.136973 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v584: 112 pgs: 112 active+clean; 2079 bytes data, 124 MB used, 199 GB / 199 GB avail; 2012 B/s rd, 0 B/s wr, 3 op/s
2018-10-18 05:29:47.151854 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v767 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:29:49.073518 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v585: 112 pgs: 112 active+clean; 2079 bytes data, 124 MB used, 199 GB / 199 GB avail
2018-10-18 05:29:50.087104 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v768 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:29:50.092340 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v586: 112 pgs: 112 active+clean; 2079 bytes data, 124 MB used, 199 GB / 199 GB avail
2018-10-18 05:29:51.114584 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v769 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:29:51.126087 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v587: 112 pgs: 112 active+clean; 2079 bytes data, 124 MB used, 199 GB / 199 GB avail
2018-10-18 05:29:52.149492 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v770 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:30:17.728199 7f6c1a901700  0 mon.ceph-node1@0(leader).data_health(224) update_stats avail 69% total 51175 MB, used 15460 MB, avail 35714 MB
2018-10-18 05:30:19.087964 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v588: 112 pgs: 112 active+clean; 2079 bytes data, 124 MB used, 199 GB / 199 GB avail; 146 B/s rd, 0 B/s wr, 0 op/s
2018-10-18 05:30:20.104561 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v771 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:30:20.145650 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v589: 112 pgs: 112 active+clean; 2079 bytes data, 124 MB used, 199 GB / 199 GB avail; 1200 B/s rd, 0 B/s wr, 1 op/s
2018-10-18 05:30:21.155591 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v590: 112 pgs: 112 active+clean; 2079 bytes data, 124 MB used, 199 GB / 199 GB avail; 66194 B/s rd, 0 B/s wr, 107 op/s
2018-10-18 05:30:21.197485 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v772 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:30:22.218461 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v773 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:30:24.096360 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v591: 112 pgs: 112 active+clean; 2079 bytes data, 124 MB used, 199 GB / 199 GB avail; 41540 B/s rd, 0 B/s wr, 67 op/s
2018-10-18 05:30:25.132389 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v774 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:30:25.213531 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v592: 112 pgs: 112 active+clean; 2079 bytes data, 125 MB used, 199 GB / 199 GB avail; 50171 B/s rd, 0 B/s wr, 81 op/s
2018-10-18 05:30:26.227146 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v775 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:30:26.237107 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v593: 112 pgs: 112 active+clean; 2079 bytes data, 117 MB used, 199 GB / 199 GB avail; 89348 B/s rd, 0 B/s wr, 145 op/s
2018-10-18 05:30:27.245802 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v776 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:30:29.088817 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v594: 112 pgs: 112 active+clean; 2079 bytes data, 117 MB used, 199 GB / 199 GB avail; 13111 B/s rd, 0 B/s wr, 21 op/s
2018-10-18 05:30:30.095340 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v777 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:30:30.111762 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v595: 112 pgs: 112 active+clean; 2079 bytes data, 117 MB used, 199 GB / 199 GB avail
2018-10-18 05:30:31.124788 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v778 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:30:31.142309 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v596: 112 pgs: 112 active+clean; 2079 bytes data, 117 MB used, 199 GB / 199 GB avail
2018-10-18 05:30:32.163169 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v779 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:31:17.728717 7f6c1a901700  0 mon.ceph-node1@0(leader).data_health(224) update_stats avail 69% total 51175 MB, used 15460 MB, avail 35714 MB
2018-10-18 05:31:20.597766 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v597: 112 pgs: 112 active+clean; 2079 bytes data, 117 MB used, 199 GB / 199 GB avail
2018-10-18 05:31:21.604799 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v780 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:31:24.111115 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v598: 112 pgs: 112 active+clean; 2079 bytes data, 117 MB used, 199 GB / 199 GB avail; 96 B/s rd, 0 B/s wr, 0 op/s
2018-10-18 05:31:25.122305 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v781 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:31:25.130824 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v599: 112 pgs: 112 active+clean; 2079 bytes data, 117 MB used, 199 GB / 199 GB avail; 1130 B/s rd, 0 B/s wr, 1 op/s
2018-10-18 05:31:26.145704 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v782 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:31:26.153604 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v600: 112 pgs: 112 active+clean; 2079 bytes data, 117 MB used, 199 GB / 199 GB avail
2018-10-18 05:31:27.163850 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v783 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:31:29.110769 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v601: 112 pgs: 112 active+clean; 2079 bytes data, 117 MB used, 199 GB / 199 GB avail
2018-10-18 05:31:30.127235 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v784 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:31:30.142749 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v602: 112 pgs: 112 active+clean; 2079 bytes data, 117 MB used, 199 GB / 199 GB avail
2018-10-18 05:31:31.198285 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v785 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:32:09.467240 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v603: 112 pgs: 112 active+clean; 2079 bytes data, 117 MB used, 199 GB / 199 GB avail
2018-10-18 05:32:10.483298 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v786 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:32:11.491676 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v604: 112 pgs: 112 active+clean; 2079 bytes data, 117 MB used, 199 GB / 199 GB avail
2018-10-18 05:32:12.505339 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v787 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:32:14.133110 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v605: 112 pgs: 112 active+clean; 2079 bytes data, 117 MB used, 199 GB / 199 GB avail; 438 B/s rd, 0 B/s wr, 0 op/s
2018-10-18 05:32:15.145658 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v788 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:32:15.156334 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v606: 112 pgs: 112 active+clean; 2079 bytes data, 117 MB used, 199 GB / 199 GB avail; 560 B/s rd, 0 B/s wr, 1 op/s
2018-10-18 05:32:16.173306 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v789 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:32:16.189365 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v607: 112 pgs: 112 active+clean; 2079 bytes data, 117 MB used, 199 GB / 199 GB avail
2018-10-18 05:32:17.210260 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v790 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:32:17.729270 7f6c1a901700  0 mon.ceph-node1@0(leader).data_health(224) update_stats avail 69% total 51175 MB, used 15461 MB, avail 35713 MB
2018-10-18 05:32:19.468874 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v608: 112 pgs: 112 active+clean; 2079 bytes data, 117 MB used, 199 GB / 199 GB avail
2018-10-18 05:32:20.489403 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v791 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:32:24.156165 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v609: 112 pgs: 112 active+clean; 2079 bytes data, 117 MB used, 199 GB / 199 GB avail; 1927 B/s rd, 2 op/s
2018-10-18 05:32:25.163663 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v792 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:32:25.177399 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v610: 112 pgs: 112 active+clean; 2079 bytes data, 117 MB used, 199 GB / 199 GB avail; 5564 B/s rd, 7 op/s
2018-10-18 05:32:26.187039 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v793 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:32:26.239792 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v611: 112 pgs: 112 active+clean; 2079 bytes data, 117 MB used, 199 GB / 199 GB avail; 11008 B/s rd, 16 op/s
2018-10-18 05:32:27.256094 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v794 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:32:29.148856 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v612: 112 pgs: 112 active+clean; 2079 bytes data, 117 MB used, 199 GB / 199 GB avail; 1545 B/s rd, 2 op/s
2018-10-18 05:32:30.172944 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v795 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:32:30.184402 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v613: 112 pgs: 112 active+clean; 2079 bytes data, 117 MB used, 199 GB / 199 GB avail
2018-10-18 05:32:31.199967 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v796 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:32:31.212115 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v614: 112 pgs: 112 active+clean; 2079 bytes data, 117 MB used, 199 GB / 199 GB avail
2018-10-18 05:32:32.229557 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v797 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:32:47.921940 7f6c1a100700  0 log_channel(cluster) log [WRN] : mon.1 192.168.136.188:6789/0 clock skew 1160.94s > max 0.05s
2018-10-18 05:32:47.922639 7f6c1a100700  0 log_channel(cluster) log [WRN] : mon.2 192.168.136.189:6789/0 clock skew 1167.74s > max 0.05s
2018-10-18 05:32:47.990819 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v798 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:33:17.729772 7f6c1a901700  0 mon.ceph-node1@0(leader).data_health(224) update_stats avail 69% total 51175 MB, used 15461 MB, avail 35713 MB
2018-10-18 05:34:17.730300 7f6c1a901700  0 mon.ceph-node1@0(leader).data_health(224) update_stats avail 69% total 51175 MB, used 15461 MB, avail 35713 MB
2018-10-18 05:34:29.200350 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v615: 112 pgs: 112 active+clean; 2079 bytes data, 117 MB used, 199 GB / 199 GB avail; 86 B/s rd, 0 op/s
2018-10-18 05:34:30.215797 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v799 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:34:30.236318 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v616: 112 pgs: 112 active+clean; 2079 bytes data, 117 MB used, 199 GB / 199 GB avail; 283 B/s rd, 0 B/s wr, 0 op/s
2018-10-18 05:34:31.255869 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v800 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:34:31.271342 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v617: 112 pgs: 112 active+clean; 2079 bytes data, 117 MB used, 199 GB / 199 GB avail; 16483 B/s rd, 0 B/s wr, 25 op/s
2018-10-18 05:34:32.278864 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v801 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:34:34.206073 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v618: 112 pgs: 112 active+clean; 2079 bytes data, 117 MB used, 199 GB / 199 GB avail; 20786 B/s rd, 0 B/s wr, 33 op/s
2018-10-18 05:34:35.236000 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v802 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:34:35.255729 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v619: 112 pgs: 112 active+clean; 2079 bytes data, 117 MB used, 199 GB / 199 GB avail; 74373 B/s rd, 0 B/s wr, 120 op/s
2018-10-18 05:34:36.329774 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v803 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:34:36.427658 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v620: 112 pgs: 112 active+clean; 2079 bytes data, 118 MB used, 199 GB / 199 GB avail; 203 kB/s rd, 0 B/s wr, 338 op/s
2018-10-18 05:34:37.467430 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v804 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:34:39.197749 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v621: 112 pgs: 112 active+clean; 2079 bytes data, 118 MB used, 199 GB / 199 GB avail; 57018 B/s rd, 0 B/s wr, 92 op/s
2018-10-18 05:34:40.224328 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v805 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:34:40.239315 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v622: 112 pgs: 112 active+clean; 2079 bytes data, 119 MB used, 199 GB / 199 GB avail; 14039 B/s rd, 0 B/s wr, 22 op/s
2018-10-18 05:34:41.245121 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v623: 112 pgs: 112 active+clean; 2079 bytes data, 119 MB used, 199 GB / 199 GB avail; 21033 B/s rd, 0 B/s wr, 33 op/s
2018-10-18 05:34:41.254416 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v806 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:34:42.282355 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v807 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:34:44.204943 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v624: 112 pgs: 112 active+clean; 2079 bytes data, 119 MB used, 199 GB / 199 GB avail; 11031 B/s rd, 15 op/s
2018-10-18 05:34:45.232081 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v808 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:34:45.254858 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v625: 112 pgs: 112 active+clean; 2079 bytes data, 119 MB used, 199 GB / 199 GB avail; 17783 B/s rd, 24 op/s
2018-10-18 05:34:46.276608 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v809 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:34:46.297720 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v626: 112 pgs: 112 active+clean; 2079 bytes data, 119 MB used, 199 GB / 199 GB avail; 19815 B/s rd, 29 op/s
2018-10-18 05:34:47.307528 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v810 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:34:49.207538 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v627: 112 pgs: 112 active+clean; 2079 bytes data, 119 MB used, 199 GB / 199 GB avail; 2055 B/s rd, 3 op/s
2018-10-18 05:34:50.212880 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v811 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:34:50.218289 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v628: 112 pgs: 112 active+clean; 2079 bytes data, 119 MB used, 199 GB / 199 GB avail
2018-10-18 05:34:51.225715 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v812 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:34:51.241837 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v629: 112 pgs: 112 active+clean; 2079 bytes data, 119 MB used, 199 GB / 199 GB avail
2018-10-18 05:34:52.247947 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v813 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:34:54.211661 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v630: 112 pgs: 112 active+clean; 2079 bytes data, 119 MB used, 199 GB / 199 GB avail
2018-10-18 05:34:55.510265 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v814 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:34:55.518313 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v631: 112 pgs: 112 active+clean; 2079 bytes data, 119 MB used, 199 GB / 199 GB avail
2018-10-18 05:34:56.523841 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v815 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:34:59.220757 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v632: 112 pgs: 112 active+clean; 2079 bytes data, 119 MB used, 199 GB / 199 GB avail
2018-10-18 05:35:00.239838 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v816 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:35:00.251870 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v633: 112 pgs: 112 active+clean; 2079 bytes data, 119 MB used, 199 GB / 199 GB avail
2018-10-18 05:35:01.262198 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v817 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:35:01.279082 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v634: 112 pgs: 112 active+clean; 2079 bytes data, 119 MB used, 199 GB / 199 GB avail
2018-10-18 05:35:02.292512 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v818 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:35:04.213386 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v635: 112 pgs: 112 active+clean; 2079 bytes data, 119 MB used, 199 GB / 199 GB avail
2018-10-18 05:35:05.232258 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v819 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:35:05.245488 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v636: 112 pgs: 112 active+clean; 2079 bytes data, 119 MB used, 199 GB / 199 GB avail
2018-10-18 05:35:06.270359 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v820 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:35:06.283788 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v637: 112 pgs: 112 active+clean; 2079 bytes data, 119 MB used, 199 GB / 199 GB avail
2018-10-18 05:35:07.313152 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v821 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:35:17.731011 7f6c1a901700  0 mon.ceph-node1@0(leader).data_health(224) update_stats avail 69% total 51175 MB, used 15467 MB, avail 35707 MB
2018-10-18 05:35:29.223354 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v638: 112 pgs: 112 active+clean; 2079 bytes data, 119 MB used, 199 GB / 199 GB avail; 356 B/s rd, 0 B/s wr, 0 op/s
2018-10-18 05:35:30.240834 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v822 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:35:30.254212 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v639: 112 pgs: 112 active+clean; 2079 bytes data, 119 MB used, 199 GB / 199 GB avail; 1708 B/s rd, 0 B/s wr, 2 op/s
2018-10-18 05:35:31.283821 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v823 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:35:31.297936 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v640: 112 pgs: 112 active+clean; 2079 bytes data, 119 MB used, 199 GB / 199 GB avail; 40037 B/s rd, 0 B/s wr, 68 op/s
2018-10-18 05:35:32.320664 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v824 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:35:34.219519 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v641: 112 pgs: 112 active+clean; 2079 bytes data, 119 MB used, 199 GB / 199 GB avail; 12327 B/s rd, 0 B/s wr, 21 op/s
2018-10-18 05:35:35.227113 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v825 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:35:35.235870 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v642: 112 pgs: 112 active+clean; 2079 bytes data, 119 MB used, 199 GB / 199 GB avail
2018-10-18 05:35:36.247931 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v826 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:35:36.269137 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v643: 112 pgs: 112 active+clean; 2079 bytes data, 119 MB used, 199 GB / 199 GB avail
2018-10-18 05:35:37.289649 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v827 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:36:17.733811 7f6c1a901700  0 mon.ceph-node1@0(leader).data_health(224) update_stats avail 69% total 51175 MB, used 15467 MB, avail 35707 MB
2018-10-18 05:36:20.704929 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v644: 112 pgs: 112 active+clean; 2079 bytes data, 119 MB used, 199 GB / 199 GB avail; 575 B/s rd, 0 B/s wr, 0 op/s
2018-10-18 05:36:21.718735 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v828 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:36:24.242943 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v645: 112 pgs: 112 active+clean; 2079 bytes data, 119 MB used, 199 GB / 199 GB avail; 1877 B/s rd, 0 B/s wr, 3 op/s
2018-10-18 05:36:25.257391 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v829 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:36:25.270195 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v646: 112 pgs: 112 active+clean; 2079 bytes data, 119 MB used, 199 GB / 199 GB avail; 51358 B/s rd, 0 B/s wr, 83 op/s
2018-10-18 05:36:26.285397 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v830 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:36:26.306981 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v647: 112 pgs: 112 active+clean; 2079 bytes data, 120 MB used, 199 GB / 199 GB avail; 143 kB/s rd, 0 B/s wr, 239 op/s
2018-10-18 05:36:27.321377 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v831 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:36:29.259866 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v648: 112 pgs: 112 active+clean; 2079 bytes data, 120 MB used, 199 GB / 199 GB avail; 32838 B/s rd, 0 B/s wr, 53 op/s
2018-10-18 05:36:30.274606 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v832 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:36:30.294231 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v649: 112 pgs: 112 active+clean; 2079 bytes data, 120 MB used, 199 GB / 199 GB avail
2018-10-18 05:36:31.312598 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v833 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:36:31.322513 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v650: 112 pgs: 112 active+clean; 2079 bytes data, 120 MB used, 199 GB / 199 GB avail
2018-10-18 05:36:32.340504 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v834 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:36:34.254802 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v651: 112 pgs: 112 active+clean; 2079 bytes data, 120 MB used, 199 GB / 199 GB avail; 3859 B/s rd, 5 op/s
2018-10-18 05:36:35.272343 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v835 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:36:35.287004 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v652: 112 pgs: 112 active+clean; 2079 bytes data, 120 MB used, 199 GB / 199 GB avail; 8012 B/s rd, 11 op/s
2018-10-18 05:36:36.300236 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v836 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:36:36.313614 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v653: 112 pgs: 112 active+clean; 2079 bytes data, 120 MB used, 199 GB / 199 GB avail; 11000 B/s rd, 16 op/s
2018-10-18 05:36:36.326312 7f6c16313700  1 leveldb: Level-0 table #160: started
2018-10-18 05:36:36.346352 7f6c16313700  1 leveldb: Level-0 table #160: 2783876 bytes OK
2018-10-18 05:36:36.347116 7f6c16313700  1 leveldb: Delete type=0 #157

2018-10-18 05:36:36.348685 7f6c16313700  1 leveldb: Manual compaction at level-0 from 'paxos\x001004' @ 72057594037927935 : 1 .. 'paxos\x001256' @ 0 : 0; will stop at 'pgmap_pg\x006.0' @ 23458 : 1

2018-10-18 05:36:36.348712 7f6c16313700  1 leveldb: Compacting 1@0 + 5@1 files
2018-10-18 05:36:36.487238 7f6c16313700  1 leveldb: Generated table #161: 232 keys, 2159031 bytes
2018-10-18 05:36:36.506054 7f6c16313700  1 leveldb: Generated table #162: 404 keys, 2168816 bytes
2018-10-18 05:36:36.521755 7f6c16313700  1 leveldb: Generated table #163: 228 keys, 2113745 bytes
2018-10-18 05:36:36.543431 7f6c16313700  1 leveldb: Generated table #164: 995 keys, 1973396 bytes
2018-10-18 05:36:36.543484 7f6c16313700  1 leveldb: Compacted 1@0 + 5@1 files => 8414988 bytes
2018-10-18 05:36:36.544077 7f6c16313700  1 leveldb: compacted to: files[ 0 4 3 0 0 0 0 ]
2018-10-18 05:36:36.544560 7f6c16313700  1 leveldb: Delete type=2 #149

2018-10-18 05:36:36.545641 7f6c16313700  1 leveldb: Delete type=2 #150

2018-10-18 05:36:36.546892 7f6c16313700  1 leveldb: Delete type=2 #151

2018-10-18 05:36:36.547872 7f6c16313700  1 leveldb: Delete type=2 #152

2018-10-18 05:36:36.548590 7f6c16313700  1 leveldb: Delete type=2 #153

2018-10-18 05:36:36.550192 7f6c16313700  1 leveldb: Delete type=2 #160

2018-10-18 05:36:36.551124 7f6c16313700  1 leveldb: Manual compaction at level-0 from 'pgmap_pg\x006.0' @ 23458 : 1 .. 'paxos\x001256' @ 0 : 0; will stop at (end)

2018-10-18 05:36:37.327472 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v837 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:36:39.256993 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v654: 112 pgs: 112 active+clean; 2079 bytes data, 120 MB used, 199 GB / 199 GB avail; 1541 B/s rd, 2 op/s
2018-10-18 05:36:40.278045 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v838 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:36:40.300597 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v655: 112 pgs: 112 active+clean; 2079 bytes data, 120 MB used, 199 GB / 199 GB avail
2018-10-18 05:36:41.316555 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v839 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:36:41.326274 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v656: 112 pgs: 112 active+clean; 2079 bytes data, 120 MB used, 199 GB / 199 GB avail
2018-10-18 05:36:42.340645 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v840 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:37:10.840574 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v657: 112 pgs: 112 active+clean; 2079 bytes data, 120 MB used, 199 GB / 199 GB avail; 730 B/s rd, 0 B/s wr, 1 op/s
2018-10-18 05:37:12.098085 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v841 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:37:14.270085 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v658: 112 pgs: 112 active+clean; 2079 bytes data, 120 MB used, 199 GB / 199 GB avail; 2610 B/s rd, 0 B/s wr, 4 op/s
2018-10-18 05:37:15.280588 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v842 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:37:15.291820 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v659: 112 pgs: 112 active+clean; 2079 bytes data, 120 MB used, 199 GB / 199 GB avail; 51373 B/s rd, 0 B/s wr, 83 op/s
2018-10-18 05:37:16.310428 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v843 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:37:16.321795 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v660: 112 pgs: 112 active+clean; 2079 bytes data, 121 MB used, 199 GB / 199 GB avail; 145 kB/s rd, 0 B/s wr, 242 op/s
2018-10-18 05:37:17.344226 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v844 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:37:17.734504 7f6c1a901700  0 mon.ceph-node1@0(leader).data_health(224) update_stats avail 69% total 51175 MB, used 15464 MB, avail 35710 MB
2018-10-18 05:37:19.347363 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v661: 112 pgs: 112 active+clean; 2549 bytes data, 121 MB used, 199 GB / 199 GB avail; 42894 B/s rd, 770 B/s wr, 72 op/s
2018-10-18 05:37:20.371179 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v845 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:37:20.385208 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v662: 112 pgs: 112 active+clean; 2549 bytes data, 121 MB used, 199 GB / 199 GB avail; 12892 B/s rd, 758 B/s wr, 23 op/s
2018-10-18 05:37:21.400824 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v846 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:37:21.422699 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v663: 112 pgs: 112 active+clean; 2549 bytes data, 121 MB used, 199 GB / 199 GB avail; 14394 B/s rd, 0 B/s wr, 23 op/s
2018-10-18 05:37:22.455436 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v847 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:37:24.274726 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v664: 112 pgs: 112 active+clean; 2549 bytes data, 121 MB used, 199 GB / 199 GB avail; 3665 B/s rd, 0 B/s wr, 6 op/s
2018-10-18 05:37:25.297125 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v848 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:37:25.332317 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v665: 112 pgs: 112 active+clean; 2549 bytes data, 121 MB used, 199 GB / 199 GB avail
2018-10-18 05:37:26.340156 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v849 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:37:26.348807 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v666: 112 pgs: 112 active+clean; 2549 bytes data, 121 MB used, 199 GB / 199 GB avail
2018-10-18 05:37:27.371341 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v850 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:37:29.277745 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v667: 112 pgs: 112 active+clean; 2549 bytes data, 121 MB used, 199 GB / 199 GB avail
2018-10-18 05:37:30.290417 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v851 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:37:30.295579 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v668: 112 pgs: 112 active+clean; 2549 bytes data, 121 MB used, 199 GB / 199 GB avail
2018-10-18 05:37:31.304653 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v852 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:37:34.278500 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v669: 112 pgs: 112 active+clean; 2549 bytes data, 121 MB used, 199 GB / 199 GB avail; 409 B/s rd, 0 B/s wr, 0 op/s
2018-10-18 05:37:35.368248 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v853 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:37:35.386440 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v670: 112 pgs: 112 active+clean; 2549 bytes data, 121 MB used, 199 GB / 199 GB avail; 403 B/s rd, 0 B/s wr, 0 op/s
2018-10-18 05:37:36.401388 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v854 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:37:36.413250 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v671: 112 pgs: 112 active+clean; 2549 bytes data, 121 MB used, 199 GB / 199 GB avail
2018-10-18 05:37:37.442077 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v855 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:37:39.280775 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v672: 112 pgs: 112 active+clean; 2549 bytes data, 121 MB used, 199 GB / 199 GB avail
2018-10-18 05:37:40.350267 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v856 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:37:40.379480 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v673: 112 pgs: 112 active+clean; 2549 bytes data, 121 MB used, 199 GB / 199 GB avail
2018-10-18 05:37:41.425368 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v857 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:37:41.430803 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v674: 112 pgs: 112 active+clean; 2549 bytes data, 121 MB used, 199 GB / 199 GB avail
2018-10-18 05:37:42.449153 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v858 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:37:47.924369 7f6c1a100700  0 log_channel(cluster) log [WRN] : mon.2 192.168.136.189:6789/0 clock skew 1167.74s > max 0.05s
2018-10-18 05:37:47.924530 7f6c1a100700  0 log_channel(cluster) log [WRN] : mon.1 192.168.136.188:6789/0 clock skew 1160.94s > max 0.05s
2018-10-18 05:37:47.985266 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v859 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:37:49.278381 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v675: 112 pgs: 112 active+clean; 2549 bytes data, 121 MB used, 199 GB / 199 GB avail; 3535 B/s rd, 342 B/s wr, 8 op/s
2018-10-18 05:37:50.290116 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v860 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:37:50.320761 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v676: 112 pgs: 112 active+clean; 2549 bytes data, 121 MB used, 199 GB / 199 GB avail; 5406 B/s rd, 345 B/s wr, 11 op/s
2018-10-18 05:37:51.333263 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v677: 112 pgs: 112 active+clean; 2549 bytes data, 121 MB used, 199 GB / 199 GB avail; 19481 B/s rd, 0 B/s wr, 29 op/s
2018-10-18 05:37:51.349618 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v861 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:37:52.359529 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v862 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:37:54.281751 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v678: 112 pgs: 112 active+clean; 2549 bytes data, 121 MB used, 199 GB / 199 GB avail; 5911 B/s rd, 0 B/s wr, 8 op/s
2018-10-18 05:37:55.296103 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v863 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:37:55.305548 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v679: 112 pgs: 112 active+clean; 2549 bytes data, 121 MB used, 199 GB / 199 GB avail
2018-10-18 05:37:56.312291 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v864 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:37:56.319399 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v680: 112 pgs: 112 active+clean; 2549 bytes data, 121 MB used, 199 GB / 199 GB avail
2018-10-18 05:37:57.324408 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v865 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:38:17.734926 7f6c1a901700  0 mon.ceph-node1@0(leader).data_health(224) update_stats avail 69% total 51175 MB, used 15465 MB, avail 35709 MB
2018-10-18 05:38:39.293960 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v681: 112 pgs: 112 active+clean; 2549 bytes data, 121 MB used, 199 GB / 199 GB avail; 238 B/s rd, 0 op/s
2018-10-18 05:38:40.307243 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v866 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:38:40.316663 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v682: 112 pgs: 112 active+clean; 2549 bytes data, 121 MB used, 199 GB / 199 GB avail; 605 B/s rd, 0 op/s
2018-10-18 05:38:41.323395 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v867 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:38:41.339131 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v683: 112 pgs: 112 active+clean; 2549 bytes data, 121 MB used, 199 GB / 199 GB avail; 11098 B/s rd, 16 op/s
2018-10-18 05:38:42.351403 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v868 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:38:44.300421 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v684: 112 pgs: 112 active+clean; 2549 bytes data, 121 MB used, 199 GB / 199 GB avail; 1539 B/s rd, 2 op/s
2018-10-18 05:38:45.324645 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v869 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:38:45.333295 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v685: 112 pgs: 112 active+clean; 2549 bytes data, 121 MB used, 199 GB / 199 GB avail
2018-10-18 05:38:46.344348 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v870 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:38:46.350164 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v686: 112 pgs: 112 active+clean; 2549 bytes data, 121 MB used, 199 GB / 199 GB avail
2018-10-18 05:38:47.370724 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v871 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:39:04.323826 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v687: 112 pgs: 112 active+clean; 2549 bytes data, 121 MB used, 199 GB / 199 GB avail; 539 B/s rd, 0 op/s
2018-10-18 05:39:05.351508 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v872 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:39:05.376888 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v688: 112 pgs: 112 active+clean; 2549 bytes data, 121 MB used, 199 GB / 199 GB avail; 2371 B/s rd, 0 B/s wr, 3 op/s
2018-10-18 05:39:06.382481 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v873 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:39:06.392418 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v689: 112 pgs: 112 active+clean; 2549 bytes data, 121 MB used, 199 GB / 199 GB avail; 20155 B/s rd, 491 B/s wr, 28 op/s
2018-10-18 05:39:07.402516 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v874 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:39:09.312655 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v690: 112 pgs: 112 active+clean; 2549 bytes data, 121 MB used, 199 GB / 199 GB avail; 10314 B/s rd, 773 B/s wr, 17 op/s
2018-10-18 05:39:10.321679 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v875 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:39:10.344964 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v691: 112 pgs: 112 active+clean; 2549 bytes data, 121 MB used, 199 GB / 199 GB avail; 15089 B/s rd, 520 B/s wr, 23 op/s
2018-10-18 05:39:11.362513 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v876 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:39:11.378427 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v692: 112 pgs: 112 active+clean; 2549 bytes data, 121 MB used, 199 GB / 199 GB avail; 16010 B/s rd, 500 B/s wr, 24 op/s
2018-10-18 05:39:12.391793 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v877 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:39:14.309722 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v693: 112 pgs: 112 active+clean; 2549 bytes data, 121 MB used, 199 GB / 199 GB avail; 1797 B/s rd, 256 B/s wr, 3 op/s
2018-10-18 05:39:15.323411 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v878 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:39:15.330079 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v694: 112 pgs: 112 active+clean; 2549 bytes data, 121 MB used, 199 GB / 199 GB avail
2018-10-18 05:39:16.347181 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v879 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:39:16.374094 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v695: 112 pgs: 112 active+clean; 2549 bytes data, 121 MB used, 199 GB / 199 GB avail
2018-10-18 05:39:17.710648 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v880 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:39:17.735984 7f6c1a901700  0 mon.ceph-node1@0(leader).data_health(224) update_stats avail 69% total 51175 MB, used 15465 MB, avail 35709 MB
2018-10-18 05:39:24.318246 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v696: 112 pgs: 112 active+clean; 2549 bytes data, 121 MB used, 199 GB / 199 GB avail; 1138 B/s rd, 1 op/s
2018-10-18 05:39:25.329172 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v881 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:39:25.358938 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v697: 112 pgs: 112 active+clean; 2549 bytes data, 121 MB used, 199 GB / 199 GB avail; 2962 B/s rd, 4 op/s
2018-10-18 05:39:26.372786 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v882 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:39:26.385012 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v698: 112 pgs: 112 active+clean; 2549 bytes data, 121 MB used, 199 GB / 199 GB avail; 10967 B/s rd, 16 op/s
2018-10-18 05:39:27.406522 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v883 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:39:29.314580 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v699: 112 pgs: 112 active+clean; 2549 bytes data, 121 MB used, 199 GB / 199 GB avail; 1540 B/s rd, 2 op/s
2018-10-18 05:39:30.338087 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v884 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:39:30.355763 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v700: 112 pgs: 112 active+clean; 2549 bytes data, 121 MB used, 199 GB / 199 GB avail
2018-10-18 05:39:31.368331 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v885 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:39:31.376662 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v701: 112 pgs: 112 active+clean; 2549 bytes data, 121 MB used, 199 GB / 199 GB avail
2018-10-18 05:39:32.407703 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v886 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:39:34.753182 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v702: 112 pgs: 112 active+clean; 2549 bytes data, 121 MB used, 199 GB / 199 GB avail
2018-10-18 05:39:35.762408 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v887 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:40:17.736538 7f6c1a901700  0 mon.ceph-node1@0(leader).data_health(224) update_stats avail 69% total 51175 MB, used 15466 MB, avail 35708 MB
2018-10-18 05:40:34.397339 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v703: 112 pgs: 112 active+clean; 2549 bytes data, 121 MB used, 199 GB / 199 GB avail; 51 B/s rd, 0 B/s wr, 0 op/s
2018-10-18 05:40:35.424928 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v888 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:40:35.437508 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v704: 112 pgs: 112 active+clean; 2549 bytes data, 121 MB used, 199 GB / 199 GB avail; 50 B/s rd, 0 B/s wr, 0 op/s
2018-10-18 05:40:36.456158 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v889 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:40:36.473982 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v705: 112 pgs: 112 active+clean; 2549 bytes data, 121 MB used, 199 GB / 199 GB avail
2018-10-18 05:40:37.480307 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v890 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:40:39.403717 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v706: 112 pgs: 112 active+clean; 2549 bytes data, 121 MB used, 199 GB / 199 GB avail
2018-10-18 05:40:40.418077 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v891 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:40:40.575317 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v707: 112 pgs: 112 active+clean; 2549 bytes data, 121 MB used, 199 GB / 199 GB avail
2018-10-18 05:40:41.604185 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v892 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:40:41.613242 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v708: 112 pgs: 112 active+clean; 2549 bytes data, 121 MB used, 199 GB / 199 GB avail
2018-10-18 05:40:42.637758 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v893 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:41:17.737072 7f6c1a901700  0 mon.ceph-node1@0(leader).data_health(224) update_stats avail 69% total 51175 MB, used 15466 MB, avail 35708 MB
2018-10-18 05:42:17.737850 7f6c1a901700  0 mon.ceph-node1@0(leader).data_health(224) update_stats avail 69% total 51175 MB, used 15466 MB, avail 35708 MB
2018-10-18 05:42:25.808657 7f6c1a100700  0 mon.ceph-node1@0(leader) e3 handle_command mon_command({"prefix": "health"} v 0) v1
2018-10-18 05:42:25.809051 7f6c1a100700  0 log_channel(audit) log [DBG] : from='client.? 192.168.136.187:0/1683301631' entity='client.bootstrap-rgw' cmd=[{"prefix": "health"}]: dispatch
2018-10-18 05:42:26.216071 7f6c1a100700  0 mon.ceph-node1@0(leader) e3 handle_command mon_command({"prefix": "auth get-or-create", "entity": "client.rgw.ceph-node1", "caps": ["osd", "allow rwx", "mon", "allow rw"]} v 0) v1
2018-10-18 05:42:26.216117 7f6c1a100700  0 log_channel(audit) log [INF] : from='client.? 192.168.136.187:0/3425021608' entity='client.bootstrap-rgw' cmd=[{"prefix": "auth get-or-create", "entity": "client.rgw.ceph-node1", "caps": ["osd", "allow rwx", "mon", "allow rw"]}]: dispatch
2018-10-18 05:42:26.886683 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v895 unable to write to '/var/log/ceph/ceph.audit.log' for channel 'audit': (2) No such file or directory
2018-10-18 05:42:29.453773 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v709: 112 pgs: 112 active+clean; 2549 bytes data, 121 MB used, 199 GB / 199 GB avail; 1082 B/s rd, 0 B/s wr, 1 op/s
2018-10-18 05:42:30.463446 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v896 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:42:30.500627 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v710: 112 pgs: 112 active+clean; 2549 bytes data, 121 MB used, 199 GB / 199 GB avail; 3752 B/s rd, 0 B/s wr, 6 op/s
2018-10-18 05:42:31.511380 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v897 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:42:31.524616 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v711: 112 pgs: 112 active+clean; 2549 bytes data, 121 MB used, 199 GB / 199 GB avail; 259 kB/s rd, 0 B/s wr, 435 op/s
2018-10-18 05:42:32.553958 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v898 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:42:34.452458 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v712: 112 pgs: 112 active+clean; 2549 bytes data, 116 MB used, 199 GB / 199 GB avail; 64725 B/s rd, 0 B/s wr, 106 op/s
2018-10-18 05:42:35.466744 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v899 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:42:35.474605 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v713: 112 pgs: 112 active+clean; 2549 bytes data, 116 MB used, 199 GB / 199 GB avail
2018-10-18 05:42:36.491657 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v900 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:42:36.524605 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v714: 112 pgs: 112 active+clean; 2549 bytes data, 117 MB used, 199 GB / 199 GB avail
2018-10-18 05:42:37.565996 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v901 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:42:39.448988 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v715: 112 pgs: 112 active+clean; 2549 bytes data, 117 MB used, 199 GB / 199 GB avail
2018-10-18 05:42:40.503037 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v902 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:42:47.930817 7f6c1a100700  0 log_channel(cluster) log [WRN] : mon.2 192.168.136.189:6789/0 clock skew 1167.74s > max 0.05s
2018-10-18 05:42:47.933188 7f6c1a100700  0 log_channel(cluster) log [WRN] : mon.1 192.168.136.188:6789/0 clock skew 1160.93s > max 0.05s
2018-10-18 05:42:47.989124 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v903 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:43:14.459021 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v716: 112 pgs: 112 active+clean; 2549 bytes data, 117 MB used, 199 GB / 199 GB avail; 292 B/s rd, 0 op/s
2018-10-18 05:43:15.471609 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v904 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:43:15.483746 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v717: 112 pgs: 112 active+clean; 2549 bytes data, 117 MB used, 199 GB / 199 GB avail; 739 B/s rd, 1 op/s
2018-10-18 05:43:16.489244 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v905 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:43:16.501850 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v718: 112 pgs: 112 active+clean; 2549 bytes data, 117 MB used, 199 GB / 199 GB avail; 11088 B/s rd, 16 op/s
2018-10-18 05:43:17.514172 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v906 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:43:17.738494 7f6c1a901700  0 mon.ceph-node1@0(leader).data_health(224) update_stats avail 69% total 51175 MB, used 15467 MB, avail 35707 MB
2018-10-18 05:43:19.459215 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v719: 112 pgs: 112 active+clean; 2549 bytes data, 117 MB used, 199 GB / 199 GB avail; 1537 B/s rd, 2 op/s
2018-10-18 05:43:20.467318 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v907 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:43:20.477037 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v720: 112 pgs: 112 active+clean; 2549 bytes data, 117 MB used, 199 GB / 199 GB avail
2018-10-18 05:43:21.503267 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v908 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:43:21.524114 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v721: 112 pgs: 112 active+clean; 2549 bytes data, 117 MB used, 199 GB / 199 GB avail
2018-10-18 05:43:22.547756 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v909 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:43:31.075514 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v722: 112 pgs: 112 active+clean; 2549 bytes data, 117 MB used, 199 GB / 199 GB avail; 579 B/s rd, 0 op/s
2018-10-18 05:43:32.111420 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v910 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:43:34.473473 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v723: 112 pgs: 112 active+clean; 2549 bytes data, 117 MB used, 199 GB / 199 GB avail; 1262 B/s rd, 1 op/s
2018-10-18 05:43:35.493540 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v911 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:43:35.504251 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v724: 112 pgs: 112 active+clean; 2549 bytes data, 117 MB used, 199 GB / 199 GB avail; 6030 B/s rd, 8 op/s
2018-10-18 05:43:36.510394 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v912 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:43:36.516222 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v725: 112 pgs: 112 active+clean; 2549 bytes data, 117 MB used, 199 GB / 199 GB avail; 8011 B/s rd, 11 op/s
2018-10-18 05:43:37.537321 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v913 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:43:39.481946 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v726: 112 pgs: 112 active+clean; 2549 bytes data, 117 MB used, 199 GB / 199 GB avail; 2570 B/s rd, 3 op/s
2018-10-18 05:43:40.493853 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v914 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:43:40.509139 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v727: 112 pgs: 112 active+clean; 2549 bytes data, 117 MB used, 199 GB / 199 GB avail; 6691 B/s rd, 9 op/s
2018-10-18 05:43:41.539163 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v915 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:43:41.555553 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v728: 112 pgs: 112 active+clean; 2549 bytes data, 117 MB used, 199 GB / 199 GB avail; 10968 B/s rd, 16 op/s
2018-10-18 05:43:42.569896 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v916 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:43:44.907673 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v729: 112 pgs: 112 active+clean; 2549 bytes data, 117 MB used, 199 GB / 199 GB avail; 1393 B/s rd, 2 op/s
2018-10-18 05:43:46.077687 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v917 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:43:46.085239 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v730: 112 pgs: 112 active+clean; 2549 bytes data, 117 MB used, 199 GB / 199 GB avail
2018-10-18 05:43:47.101063 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v918 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:44:17.738995 7f6c1a901700  0 mon.ceph-node1@0(leader).data_health(224) update_stats avail 69% total 51175 MB, used 15467 MB, avail 35707 MB
2018-10-18 05:45:17.739478 7f6c1a901700  0 mon.ceph-node1@0(leader).data_health(224) update_stats avail 69% total 51175 MB, used 15467 MB, avail 35707 MB
2018-10-18 05:45:24.526494 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v731: 112 pgs: 112 active+clean; 2549 bytes data, 117 MB used, 199 GB / 199 GB avail; 93 B/s rd, 0 B/s wr, 0 op/s
2018-10-18 05:45:25.543692 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v919 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:45:25.555365 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v732: 112 pgs: 112 active+clean; 2549 bytes data, 117 MB used, 199 GB / 199 GB avail; 247 B/s rd, 0 B/s wr, 0 op/s
2018-10-18 05:45:26.591826 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v920 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:45:26.628360 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v733: 112 pgs: 112 active+clean; 2549 bytes data, 117 MB used, 199 GB / 199 GB avail; 7504 B/s rd, 0 B/s wr, 9 op/s
2018-10-18 05:45:27.648545 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v921 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:45:29.518737 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v734: 112 pgs: 112 active+clean; 2549 bytes data, 117 MB used, 199 GB / 199 GB avail; 771 B/s rd, 0 B/s wr, 3 op/s
2018-10-18 05:45:30.527352 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v922 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:45:30.539995 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v735: 112 pgs: 112 active+clean; 2549 bytes data, 117 MB used, 199 GB / 199 GB avail; 1807 B/s rd, 0 B/s wr, 5 op/s
2018-10-18 05:45:31.550770 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v923 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:45:31.560720 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v736: 112 pgs: 112 active+clean; 2549 bytes data, 117 MB used, 199 GB / 199 GB avail; 2019 B/s rd, 0 B/s wr, 3 op/s
2018-10-18 05:45:32.593292 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v924 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:45:34.569068 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v737: 112 pgs: 112 active+clean; 2549 bytes data, 117 MB used, 199 GB / 199 GB avail
2018-10-18 05:45:35.580985 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v925 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:45:35.590933 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v738: 112 pgs: 112 active+clean; 2549 bytes data, 117 MB used, 199 GB / 199 GB avail
2018-10-18 05:45:36.604350 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v926 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:45:36.624893 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v739: 112 pgs: 112 active+clean; 2549 bytes data, 117 MB used, 199 GB / 199 GB avail
2018-10-18 05:45:37.636662 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v927 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:45:54.997342 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v740: 112 pgs: 112 active+clean; 12579 bytes data, 117 MB used, 199 GB / 199 GB avail; 1581 B/s rd, 580 B/s wr, 4 op/s
2018-10-18 05:45:56.018891 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v928 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:45:57.029811 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v741: 112 pgs: 112 active+clean; 23673 bytes data, 117 MB used, 199 GB / 199 GB avail; 1504 B/s rd, 1203 B/s wr, 6 op/s
2018-10-18 05:45:58.039712 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v929 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:45:59.538778 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v742: 112 pgs: 112 active+clean; 32627 bytes data, 117 MB used, 199 GB / 199 GB avail; 451 B/s rd, 4968 B/s wr, 13 op/s
2018-10-18 05:46:00.657085 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v930 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:46:00.665645 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v743: 112 pgs: 112 active+clean; 32627 bytes data, 117 MB used, 199 GB / 199 GB avail; 2821 B/s rd, 2539 B/s wr, 11 op/s
2018-10-18 05:46:01.697802 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v931 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:46:01.722289 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v744: 112 pgs: 112 active+clean; 32627 bytes data, 118 MB used, 199 GB / 199 GB avail; 3819 B/s rd, 0 B/s wr, 7 op/s
2018-10-18 05:46:02.730884 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v932 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:46:04.534602 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v745: 112 pgs: 112 active+clean; 32627 bytes data, 117 MB used, 199 GB / 199 GB avail
2018-10-18 05:46:05.553151 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v933 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:46:05.560898 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v746: 112 pgs: 112 active+clean; 32627 bytes data, 117 MB used, 199 GB / 199 GB avail
2018-10-18 05:46:06.567241 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v934 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:46:06.581671 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v747: 112 pgs: 112 active+clean; 32627 bytes data, 117 MB used, 199 GB / 199 GB avail
2018-10-18 05:46:07.587785 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v935 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:46:17.739991 7f6c1a901700  0 mon.ceph-node1@0(leader).data_health(224) update_stats avail 69% total 51175 MB, used 15468 MB, avail 35706 MB
2018-10-18 05:46:19.543569 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v748: 112 pgs: 112 active+clean; 32627 bytes data, 117 MB used, 199 GB / 199 GB avail; 365 B/s rd, 0 B/s wr, 0 op/s
2018-10-18 05:46:20.571694 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v936 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:46:20.591482 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v749: 112 pgs: 112 active+clean; 32627 bytes data, 117 MB used, 199 GB / 199 GB avail; 366 B/s rd, 0 B/s wr, 0 op/s
2018-10-18 05:46:21.754166 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v937 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:46:21.765166 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v750: 112 pgs: 112 active+clean; 32627 bytes data, 117 MB used, 199 GB / 199 GB avail; 1491 B/s rd, 0 B/s wr, 2 op/s
2018-10-18 05:46:22.770646 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v938 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:46:24.577053 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v751: 112 pgs: 112 active+clean; 32627 bytes data, 117 MB used, 199 GB / 199 GB avail; 16905 B/s rd, 0 B/s wr, 27 op/s
2018-10-18 05:46:25.593154 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v939 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:46:25.614076 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v752: 112 pgs: 112 active+clean; 32627 bytes data, 118 MB used, 199 GB / 199 GB avail; 58685 B/s rd, 0 B/s wr, 95 op/s
2018-10-18 05:46:26.630184 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v940 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:46:26.649112 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v753: 112 pgs: 112 active+clean; 32627 bytes data, 118 MB used, 199 GB / 199 GB avail; 152 kB/s rd, 0 B/s wr, 253 op/s
2018-10-18 05:46:27.663159 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v941 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:46:28.083674 7f6c16313700  1 leveldb: Level-0 table #166: started
2018-10-18 05:46:28.107568 7f6c16313700  1 leveldb: Level-0 table #166: 3445338 bytes OK
2018-10-18 05:46:28.108405 7f6c16313700  1 leveldb: Delete type=0 #159

2018-10-18 05:46:28.110169 7f6c16313700  1 leveldb: Manual compaction at level-0 from 'pgmap\x000' @ 72057594037927935 : 1 .. 'pgmap\x00253' @ 0 : 0; will stop at 'pgmap_pg\x006.7' @ 27309 : 1

2018-10-18 05:46:28.110193 7f6c16313700  1 leveldb: Compacting 1@0 + 4@1 files
2018-10-18 05:46:28.125643 7f6c16313700  1 leveldb: Generated table #167: 335 keys, 2162438 bytes
2018-10-18 05:46:28.140888 7f6c16313700  1 leveldb: Generated table #168: 274 keys, 2163831 bytes
2018-10-18 05:46:28.155532 7f6c16313700  1 leveldb: Generated table #169: 291 keys, 2131745 bytes
2018-10-18 05:46:28.170292 7f6c16313700  1 leveldb: Generated table #170: 244 keys, 2138292 bytes
2018-10-18 05:46:28.186513 7f6c16313700  1 leveldb: Generated table #171: 256 keys, 2146895 bytes
2018-10-18 05:46:28.197860 7f6c16313700  1 leveldb: Generated table #172: 723 keys, 917067 bytes
2018-10-18 05:46:28.198014 7f6c16313700  1 leveldb: Compacted 1@0 + 4@1 files => 11660268 bytes
2018-10-18 05:46:28.201740 7f6c16313700  1 leveldb: compacted to: files[ 0 6 3 0 0 0 0 ]
2018-10-18 05:46:28.202194 7f6c16313700  1 leveldb: Delete type=2 #163

2018-10-18 05:46:28.203319 7f6c16313700  1 leveldb: Delete type=2 #164

2018-10-18 05:46:28.204190 7f6c16313700  1 leveldb: Delete type=2 #161

2018-10-18 05:46:28.205434 7f6c16313700  1 leveldb: Delete type=2 #162

2018-10-18 05:46:28.206463 7f6c16313700  1 leveldb: Delete type=2 #166

2018-10-18 05:46:28.207349 7f6c16313700  1 leveldb: Compacting 1@1 + 3@2 files
2018-10-18 05:46:28.222197 7f6c16313700  1 leveldb: Generated table #173: 887 keys, 2133209 bytes
2018-10-18 05:46:28.235740 7f6c16313700  1 leveldb: Generated table #174: 155 keys, 2114171 bytes
2018-10-18 05:46:28.249479 7f6c16313700  1 leveldb: Generated table #175: 156 keys, 2101778 bytes
2018-10-18 05:46:28.262954 7f6c16313700  1 leveldb: Generated table #176: 111 keys, 1606915 bytes
2018-10-18 05:46:28.262999 7f6c16313700  1 leveldb: Compacted 1@1 + 3@2 files => 7956073 bytes
2018-10-18 05:46:28.264400 7f6c16313700  1 leveldb: compacted to: files[ 0 5 4 0 0 0 0 ]
2018-10-18 05:46:28.264889 7f6c16313700  1 leveldb: Delete type=2 #155

2018-10-18 05:46:28.266173 7f6c16313700  1 leveldb: Delete type=2 #156

2018-10-18 05:46:28.267082 7f6c16313700  1 leveldb: Delete type=2 #154

2018-10-18 05:46:28.268056 7f6c16313700  1 leveldb: Delete type=2 #167

2018-10-18 05:46:28.268692 7f6c16313700  1 leveldb: Manual compaction at level-0 from 'pgmap_pg\x006.7' @ 27309 : 1 .. 'pgmap\x00253' @ 0 : 0; will stop at (end)

2018-10-18 05:46:28.268939 7f6c16313700  1 leveldb: Level-0 table #178: started
2018-10-18 05:46:28.268985 7f6c16313700  1 leveldb: Level-0 table #178: 0 bytes OK
2018-10-18 05:46:28.272663 7f6c16313700  1 leveldb: Delete type=0 #165

2018-10-18 05:46:28.272842 7f6c16313700  1 leveldb: Manual compaction at level-0 from 'pgmap\x00full_0' @ 72057594037927935 : 1 .. 'pgmap\x00full_253' @ 0 : 0; will stop at (end)

2018-10-18 05:46:29.550848 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v754: 112 pgs: 112 active+clean; 32627 bytes data, 118 MB used, 199 GB / 199 GB avail; 38697 B/s rd, 0 B/s wr, 62 op/s
2018-10-18 05:46:30.564508 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v942 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:46:30.572579 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v755: 112 pgs: 112 active+clean; 32627 bytes data, 118 MB used, 199 GB / 199 GB avail
2018-10-18 05:46:32.031737 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v943 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:46:32.045445 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v756: 112 pgs: 112 active+clean; 32627 bytes data, 118 MB used, 199 GB / 199 GB avail
2018-10-18 05:46:33.061381 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v944 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:46:35.055889 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v757: 112 pgs: 112 active+clean; 32627 bytes data, 118 MB used, 199 GB / 199 GB avail
2018-10-18 05:46:36.066271 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v945 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:47:11.203242 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v758: 112 pgs: 112 active+clean; 32627 bytes data, 118 MB used, 199 GB / 199 GB avail; 113 B/s rd, 0 B/s wr, 0 op/s
2018-10-18 05:47:12.211947 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v946 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:47:12.964219 7f6c1a100700  0 mon.ceph-node1@0(leader) e3 handle_command mon_command({"prefix": "status"} v 0) v1
2018-10-18 05:47:12.964253 7f6c1a100700  0 log_channel(audit) log [DBG] : from='client.? 192.168.136.188:0/2533784632' entity='client.admin' cmd=[{"prefix": "status"}]: dispatch
2018-10-18 05:47:14.581577 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v759: 112 pgs: 112 active+clean; 32627 bytes data, 118 MB used, 199 GB / 199 GB avail; 1735 B/s rd, 0 B/s wr, 2 op/s
2018-10-18 05:47:15.589509 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v948 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:47:15.596162 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v760: 112 pgs: 112 active+clean; 32627 bytes data, 119 MB used, 199 GB / 199 GB avail; 53201 B/s rd, 0 B/s wr, 86 op/s
2018-10-18 05:47:16.608743 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v949 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:47:16.623537 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v761: 112 pgs: 112 active+clean; 32627 bytes data, 119 MB used, 199 GB / 199 GB avail; 154 kB/s rd, 0 B/s wr, 257 op/s
2018-10-18 05:47:17.629291 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v950 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:47:17.740548 7f6c1a901700  0 mon.ceph-node1@0(leader).data_health(224) update_stats avail 69% total 51175 MB, used 15468 MB, avail 35706 MB
2018-10-18 05:47:19.583404 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v762: 112 pgs: 112 active+clean; 32627 bytes data, 119 MB used, 199 GB / 199 GB avail; 38299 B/s rd, 0 B/s wr, 62 op/s
2018-10-18 05:47:20.686589 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v951 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:47:20.701663 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v763: 112 pgs: 112 active+clean; 32627 bytes data, 119 MB used, 199 GB / 199 GB avail
2018-10-18 05:47:21.732304 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v952 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:47:21.751195 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v764: 112 pgs: 112 active+clean; 32627 bytes data, 119 MB used, 199 GB / 199 GB avail
2018-10-18 05:47:22.772779 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v953 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:47:24.578136 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v765: 112 pgs: 112 active+clean; 32627 bytes data, 119 MB used, 199 GB / 199 GB avail
2018-10-18 05:47:25.594499 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v954 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:47:25.608936 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v766: 112 pgs: 112 active+clean; 32627 bytes data, 119 MB used, 199 GB / 199 GB avail
2018-10-18 05:47:26.625396 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v955 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:47:47.935053 7f6c1a100700  0 log_channel(cluster) log [WRN] : mon.2 192.168.136.189:6789/0 clock skew 1167.74s > max 0.05s
2018-10-18 05:47:47.936053 7f6c1a100700  0 log_channel(cluster) log [WRN] : mon.1 192.168.136.188:6789/0 clock skew 1160.94s > max 0.05s
2018-10-18 05:47:48.003134 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v956 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:47:51.749270 7f6c1a100700  0 mon.ceph-node1@0(leader) e3 handle_command mon_command({"prefix": "mon dump"} v 0) v1
2018-10-18 05:47:51.749311 7f6c1a100700  0 log_channel(audit) log [DBG] : from='client.? 192.168.136.188:0/3903589314' entity='client.admin' cmd=[{"prefix": "mon dump"}]: dispatch
2018-10-18 05:48:04.340632 7f6c1a100700  0 mon.ceph-node1@0(leader) e3 handle_command mon_command({"prefix": "mon dump"} v 0) v1
2018-10-18 05:48:04.340688 7f6c1a100700  0 log_channel(audit) log [DBG] : from='client.? 192.168.136.188:0/2422428401' entity='client.admin' cmd=[{"prefix": "mon dump"}]: dispatch
2018-10-18 05:48:14.182808 7f6c1a100700  0 mon.ceph-node1@0(leader) e3 handle_command mon_command({"prefix": "mon dump"} v 0) v1
2018-10-18 05:48:14.182968 7f6c1a100700  0 log_channel(audit) log [DBG] : from='client.? 192.168.136.188:0/277605102' entity='client.admin' cmd=[{"prefix": "mon dump"}]: dispatch
2018-10-18 05:48:17.741202 7f6c1a901700  0 mon.ceph-node1@0(leader).data_health(224) update_stats avail 69% total 51175 MB, used 15468 MB, avail 35706 MB
2018-10-18 05:48:17.827295 7f6c1a100700  0 mon.ceph-node1@0(leader) e3 handle_command mon_command({"prefix": "mon dump"} v 0) v1
2018-10-18 05:48:17.827362 7f6c1a100700  0 log_channel(audit) log [DBG] : from='client.? 192.168.136.188:0/2482426938' entity='client.admin' cmd=[{"prefix": "mon dump"}]: dispatch
2018-10-18 05:48:56.260634 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v767: 112 pgs: 112 active+clean; 32627 bytes data, 119 MB used, 199 GB / 199 GB avail
2018-10-18 05:48:57.282949 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v961 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:48:59.655035 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v768: 112 pgs: 112 active+clean; 23673 bytes data, 119 MB used, 199 GB / 199 GB avail; 206 B/s rd, 0 B/s wr, 0 op/s
2018-10-18 05:49:00.662003 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v769: 112 pgs: 112 active+clean; 13643 bytes data, 119 MB used, 199 GB / 199 GB avail; 18809 B/s rd, 0 B/s wr, 27 op/s
2018-10-18 05:49:00.675360 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v962 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:49:01.688734 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v963 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:49:01.710260 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v770: 112 pgs: 112 active+clean; 2549 bytes data, 119 MB used, 199 GB / 199 GB avail; 47670 B/s rd, 0 B/s wr, 68 op/s
2018-10-18 05:49:02.733335 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v964 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:49:04.653172 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v771: 112 pgs: 112 active+clean; 2549 bytes data, 119 MB used, 199 GB / 199 GB avail; 8479 B/s rd, 0 B/s wr, 10 op/s
2018-10-18 05:49:05.677315 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v965 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:49:05.692835 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v772: 112 pgs: 112 active+clean; 2549 bytes data, 119 MB used, 199 GB / 199 GB avail
2018-10-18 05:49:05.705765 7f6c16313700  1 leveldb: Level-0 table #180: started
2018-10-18 05:49:05.718842 7f6c16313700  1 leveldb: Level-0 table #180: 774415 bytes OK
2018-10-18 05:49:05.719531 7f6c16313700  1 leveldb: Delete type=0 #177

2018-10-18 05:49:05.720362 7f6c16313700  1 leveldb: Manual compaction at level-0 from 'paxos\x001255' @ 72057594037927935 : 1 .. 'paxos\x001507' @ 0 : 0; will stop at 'pgmap_pg\x006.7' @ 28223 : 1

2018-10-18 05:49:05.720391 7f6c16313700  1 leveldb: Compacting 1@0 + 5@1 files
2018-10-18 05:49:05.737726 7f6c16313700  1 leveldb: Generated table #181: 171 keys, 2105843 bytes
2018-10-18 05:49:05.758389 7f6c16313700  1 leveldb: Generated table #182: 438 keys, 2115795 bytes
2018-10-18 05:49:05.776861 7f6c16313700  1 leveldb: Generated table #183: 256 keys, 2146895 bytes
2018-10-18 05:49:05.789238 7f6c16313700  1 leveldb: Generated table #184: 787 keys, 1310531 bytes
2018-10-18 05:49:05.789285 7f6c16313700  1 leveldb: Compacted 1@0 + 5@1 files => 7679064 bytes
2018-10-18 05:49:05.789802 7f6c16313700  1 leveldb: compacted to: files[ 0 4 4 0 0 0 0 ]
2018-10-18 05:49:05.790179 7f6c16313700  1 leveldb: Delete type=2 #168

2018-10-18 05:49:05.790982 7f6c16313700  1 leveldb: Delete type=2 #169

2018-10-18 05:49:05.791718 7f6c16313700  1 leveldb: Delete type=2 #170

2018-10-18 05:49:05.792497 7f6c16313700  1 leveldb: Delete type=2 #171

2018-10-18 05:49:05.793211 7f6c16313700  1 leveldb: Delete type=2 #172

2018-10-18 05:49:05.793607 7f6c16313700  1 leveldb: Delete type=2 #180

2018-10-18 05:49:05.794051 7f6c16313700  1 leveldb: Manual compaction at level-0 from 'pgmap_pg\x006.7' @ 28223 : 1 .. 'paxos\x001507' @ 0 : 0; will stop at (end)

2018-10-18 05:49:06.707221 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v966 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:49:06.726727 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v773: 112 pgs: 112 active+clean; 2549 bytes data, 119 MB used, 199 GB / 199 GB avail
2018-10-18 05:49:07.734648 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v967 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:49:17.741702 7f6c1a901700  0 mon.ceph-node1@0(leader).data_health(224) update_stats avail 69% total 51175 MB, used 15466 MB, avail 35708 MB
2018-10-18 05:49:19.653156 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v774: 112 pgs: 112 active+clean; 2549 bytes data, 119 MB used, 199 GB / 199 GB avail; 146 B/s rd, 0 B/s wr, 0 op/s
2018-10-18 05:49:20.659711 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v968 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:49:20.669011 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v775: 112 pgs: 112 active+clean; 2549 bytes data, 119 MB used, 199 GB / 199 GB avail; 146 B/s rd, 0 B/s wr, 0 op/s
2018-10-18 05:49:21.685945 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v969 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:49:21.702973 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v776: 112 pgs: 112 active+clean; 2549 bytes data, 119 MB used, 199 GB / 199 GB avail
2018-10-18 05:49:22.753709 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v970 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:49:24.649201 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v777: 112 pgs: 112 active+clean; 2549 bytes data, 119 MB used, 199 GB / 199 GB avail
2018-10-18 05:49:25.662382 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v971 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:49:25.685003 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v778: 112 pgs: 112 active+clean; 2549 bytes data, 119 MB used, 199 GB / 199 GB avail
2018-10-18 05:49:26.695492 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v972 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:49:26.706170 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v779: 112 pgs: 112 active+clean; 2549 bytes data, 119 MB used, 199 GB / 199 GB avail
2018-10-18 05:49:27.728957 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v973 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:50:17.742221 7f6c1a901700  0 mon.ceph-node1@0(leader).data_health(224) update_stats avail 69% total 51175 MB, used 15466 MB, avail 35708 MB
2018-10-18 05:51:01.308118 7f6c1a100700  0 mon.ceph-node1@0(leader) e3 handle_command mon_command({"prefix": "health"} v 0) v1
2018-10-18 05:51:01.308163 7f6c1a100700  0 log_channel(audit) log [DBG] : from='client.? 192.168.136.187:0/3484994210' entity='client.bootstrap-osd' cmd=[{"prefix": "health"}]: dispatch
2018-10-18 05:51:07.918039 7f6c1a100700  0 mon.ceph-node1@0(leader) e3 handle_command mon_command({"prefix": "osd create", "uuid": "1c050b4a-cea9-462f-b9ae-1570b46e6cde"} v 0) v1
2018-10-18 05:51:07.918114 7f6c1a100700  0 log_channel(audit) log [INF] : from='client.? 192.168.136.187:0/1964531069' entity='client.bootstrap-osd' cmd=[{"prefix": "osd create", "uuid": "1c050b4a-cea9-462f-b9ae-1570b46e6cde"}]: dispatch
2018-10-18 05:51:07.983180 7f6c1c2d1700  1 mon.ceph-node1@0(leader).osd e146 e146: 4 osds: 3 up, 3 in
2018-10-18 05:51:07.984542 7f6c1c2d1700  0 log_channel(audit) log [INF] : from='client.? 192.168.136.187:0/1964531069' entity='client.bootstrap-osd' cmd='[{"prefix": "osd create", "uuid": "1c050b4a-cea9-462f-b9ae-1570b46e6cde"}]': finished
2018-10-18 05:51:07.988176 7f6c1c2d1700  0 log_channel(cluster) log [INF] : osdmap e146: 4 osds: 3 up, 3 in
2018-10-18 05:51:07.997330 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v975 unable to write to '/var/log/ceph/ceph.audit.log' for channel 'audit': (2) No such file or directory
2018-10-18 05:51:07.997828 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v780: 112 pgs: 112 active+clean; 2549 bytes data, 119 MB used, 199 GB / 199 GB avail
2018-10-18 05:51:08.432869 7f6c1a100700  0 mon.ceph-node1@0(leader) e3 handle_command mon_command({"prefix": "mon getmap"} v 0) v1
2018-10-18 05:51:08.432964 7f6c1a100700  0 log_channel(audit) log [DBG] : from='client.? 192.168.136.187:0/1406349014' entity='client.bootstrap-osd' cmd=[{"prefix": "mon getmap"}]: dispatch
2018-10-18 05:51:09.013684 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v976 unable to write to '/var/log/ceph/ceph.audit.log' for channel 'audit': (2) No such file or directory
2018-10-18 05:51:09.013795 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v976 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:51:09.278035 7f6c1a100700  0 mon.ceph-node1@0(leader) e3 handle_command mon_command({"prefix": "auth add", "entity": "osd.3", "caps": ["osd", "allow *", "mon", "allow profile osd"]} v 0) v1
2018-10-18 05:51:09.278100 7f6c1a100700  0 log_channel(audit) log [INF] : from='client.? 192.168.136.187:0/2272254911' entity='client.bootstrap-osd' cmd=[{"prefix": "auth add", "entity": "osd.3", "caps": ["osd", "allow *", "mon", "allow profile osd"]}]: dispatch
2018-10-18 05:51:09.296123 7f6c1c2d1700  0 log_channel(audit) log [INF] : from='client.? 192.168.136.187:0/2272254911' entity='client.bootstrap-osd' cmd='[{"prefix": "auth add", "entity": "osd.3", "caps": ["osd", "allow *", "mon", "allow profile osd"]}]': finished
2018-10-18 05:51:09.738203 7f6c1a100700  0 mon.ceph-node1@0(leader) e3 handle_command mon_command({"prefix": "osd find", "id": 3} v 0) v1
2018-10-18 05:51:09.738277 7f6c1a100700  0 log_channel(audit) log [DBG] : from='client.? 192.168.136.187:0/3938462002' entity='osd.3' cmd=[{"prefix": "osd find", "id": 3}]: dispatch
2018-10-18 05:51:10.019408 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v977 unable to write to '/var/log/ceph/ceph.audit.log' for channel 'audit': (2) No such file or directory
2018-10-18 05:51:10.108410 7f6c1a100700  0 mon.ceph-node1@0(leader) e3 handle_command mon_command({"prefix": "osd crush create-or-move", "args": ["root=default", "host=ceph-node1"], "id": 3, "weight": 0.08} v 0) v1
2018-10-18 05:51:10.108478 7f6c1a100700  0 log_channel(audit) log [INF] : from='client.? 192.168.136.187:0/3715333742' entity='osd.3' cmd=[{"prefix": "osd crush create-or-move", "args": ["root=default", "host=ceph-node1"], "id": 3, "weight": 0.08}]: dispatch
2018-10-18 05:51:10.108649 7f6c1a100700  0 mon.ceph-node1@0(leader).osd e146 create-or-move crush item name 'osd.3' initial_weight 0.08 at location {host=ceph-node1,root=default}
2018-10-18 05:51:10.325856 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v781: 112 pgs: 112 active+clean; 2549 bytes data, 119 MB used, 199 GB / 199 GB avail; 484 B/s rd, 0 op/s
2018-10-18 05:51:11.051546 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v978 unable to write to '/var/log/ceph/ceph.audit.log' for channel 'audit': (2) No such file or directory
2018-10-18 05:51:11.051586 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v978 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:51:11.074754 7f6c1c2d1700  1 mon.ceph-node1@0(leader).osd e147 e147: 4 osds: 3 up, 3 in
2018-10-18 05:51:11.076347 7f6c1c2d1700  0 log_channel(audit) log [INF] : from='client.? 192.168.136.187:0/3715333742' entity='osd.3' cmd='[{"prefix": "osd crush create-or-move", "args": ["root=default", "host=ceph-node1"], "id": 3, "weight": 0.08}]': finished
2018-10-18 05:51:11.077253 7f6c1c2d1700  0 log_channel(cluster) log [INF] : osdmap e147: 4 osds: 3 up, 3 in
2018-10-18 05:51:11.100659 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v782: 112 pgs: 112 active+clean; 2549 bytes data, 119 MB used, 199 GB / 199 GB avail; 16235 B/s rd, 19 op/s
2018-10-18 05:51:12.099270 7f6c1c2d1700  1 mon.ceph-node1@0(leader).osd e148 e148: 4 osds: 4 up, 4 in
2018-10-18 05:51:12.105285 7f6c1c2d1700  0 log_channel(cluster) log [INF] : osd.3 192.168.136.187:6804/26198 boot
2018-10-18 05:51:12.112368 7f6c1c2d1700  0 log_channel(cluster) log [INF] : osdmap e148: 4 osds: 4 up, 4 in
2018-10-18 05:51:12.137572 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v979 unable to write to '/var/log/ceph/ceph.audit.log' for channel 'audit': (2) No such file or directory
2018-10-18 05:51:12.137595 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v979 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:51:12.138390 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v783: 112 pgs: 10 remapped+peering, 102 active+clean; 2549 bytes data, 119 MB used, 199 GB / 199 GB avail; 1133 B/s rd, 1 op/s
2018-10-18 05:51:13.105075 7f6c1c2d1700  1 mon.ceph-node1@0(leader).osd e149 e149: 4 osds: 4 up, 4 in
2018-10-18 05:51:13.107743 7f6c1c2d1700  0 log_channel(cluster) log [INF] : osdmap e149: 4 osds: 4 up, 4 in
2018-10-18 05:51:13.138008 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v784: 112 pgs: 10 remapped+peering, 102 active+clean; 2549 bytes data, 119 MB used, 199 GB / 199 GB avail; 1008 B/s rd, 1 op/s
2018-10-18 05:51:13.149550 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v980 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:51:14.113199 7f6c1c2d1700  1 mon.ceph-node1@0(leader).osd e150 e150: 4 osds: 4 up, 4 in
2018-10-18 05:51:14.114838 7f6c1c2d1700  0 log_channel(cluster) log [INF] : osdmap e150: 4 osds: 4 up, 4 in
2018-10-18 05:51:14.135309 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v785: 112 pgs: 10 remapped+peering, 102 active+clean; 2549 bytes data, 119 MB used, 199 GB / 199 GB avail
2018-10-18 05:51:14.162436 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v981 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:51:15.196191 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v786: 112 pgs: 10 remapped+peering, 102 active+clean; 2549 bytes data, 119 MB used, 199 GB / 199 GB avail; 763 B/s, 0 keys/s, 5 objects/s recovering
2018-10-18 05:51:16.230273 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v982 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:51:16.246248 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v787: 112 pgs: 8 remapped+peering, 104 active+clean; 2549 bytes data, 120 MB used, 199 GB / 199 GB avail; 752 B/s, 0 keys/s, 5 objects/s recovering
2018-10-18 05:51:17.265018 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v983 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:51:17.301106 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v788: 112 pgs: 4 remapped+peering, 108 active+clean; 2549 bytes data, 120 MB used, 199 GB / 199 GB avail; 0 B/s, 0 keys/s, 54 objects/s recovering
2018-10-18 05:51:17.752784 7f6c1a901700  0 mon.ceph-node1@0(leader).data_health(224) update_stats avail 69% total 51175 MB, used 15467 MB, avail 35707 MB
2018-10-18 05:51:17.793055 7f6c1a901700  0 log_channel(cluster) log [INF] : HEALTH_WARN; clock skew detected on mon.ceph-node2, mon.ceph-node3; 4 pgs peering; Monitor clock skew detected 
2018-10-18 05:51:18.322358 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v984 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:51:18.335740 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v789: 112 pgs: 112 active+clean; 2549 bytes data, 163 MB used, 279 GB / 279 GB avail; 315 B/s, 0 keys/s, 79 objects/s recovering
2018-10-18 05:51:19.348313 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v985 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:51:20.367308 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v790: 112 pgs: 112 active+clean; 2549 bytes data, 164 MB used, 279 GB / 279 GB avail; 214 B/s, 17 objects/s recovering
2018-10-18 05:51:21.390361 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v986 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:51:21.414653 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v791: 112 pgs: 112 active+clean; 2549 bytes data, 164 MB used, 279 GB / 279 GB avail
2018-10-18 05:51:22.428954 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v792: 112 pgs: 112 active+clean; 2549 bytes data, 158 MB used, 279 GB / 279 GB avail
2018-10-18 05:51:22.448992 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v987 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:51:23.502118 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v988 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:51:23.771275 7f6c1a100700  0 mon.ceph-node1@0(leader) e3 handle_command mon_command({"prefix": "health"} v 0) v1
2018-10-18 05:51:23.771327 7f6c1a100700  0 log_channel(audit) log [DBG] : from='client.? 192.168.136.188:0/501727076' entity='client.bootstrap-osd' cmd=[{"prefix": "health"}]: dispatch
2018-10-18 05:51:25.542441 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v793: 112 pgs: 112 active+clean; 2549 bytes data, 158 MB used, 279 GB / 279 GB avail
2018-10-18 05:51:26.654442 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v990 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:51:29.863377 7f6c1a100700  0 mon.ceph-node1@0(leader) e3 handle_command mon_command({"prefix": "osd create", "uuid": "9f9d557e-8abc-4c77-9f99-87a76a8840fc"} v 0) v1
2018-10-18 05:51:29.863434 7f6c1a100700  0 log_channel(audit) log [INF] : from='client.? 192.168.136.188:0/3471404307' entity='client.bootstrap-osd' cmd=[{"prefix": "osd create", "uuid": "9f9d557e-8abc-4c77-9f99-87a76a8840fc"}]: dispatch
2018-10-18 05:51:30.081251 7f6c1c2d1700  1 mon.ceph-node1@0(leader).osd e151 e151: 5 osds: 4 up, 4 in
2018-10-18 05:51:30.083128 7f6c1c2d1700  0 log_channel(audit) log [INF] : from='client.? 192.168.136.188:0/3471404307' entity='client.bootstrap-osd' cmd='[{"prefix": "osd create", "uuid": "9f9d557e-8abc-4c77-9f99-87a76a8840fc"}]': finished
2018-10-18 05:51:30.085953 7f6c1c2d1700  0 log_channel(cluster) log [INF] : osdmap e151: 5 osds: 4 up, 4 in
2018-10-18 05:51:30.102511 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v991 unable to write to '/var/log/ceph/ceph.audit.log' for channel 'audit': (2) No such file or directory
2018-10-18 05:51:30.103044 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v794: 112 pgs: 112 active+clean; 2549 bytes data, 158 MB used, 279 GB / 279 GB avail
2018-10-18 05:51:30.526544 7f6c1a100700  0 mon.ceph-node1@0(leader) e3 handle_command mon_command({"prefix": "mon getmap"} v 0) v1
2018-10-18 05:51:30.526609 7f6c1a100700  0 log_channel(audit) log [DBG] : from='client.? 192.168.136.188:0/1972860948' entity='client.bootstrap-osd' cmd=[{"prefix": "mon getmap"}]: dispatch
2018-10-18 05:51:31.110362 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v992 unable to write to '/var/log/ceph/ceph.audit.log' for channel 'audit': (2) No such file or directory
2018-10-18 05:51:31.110400 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v992 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:51:31.117653 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v795: 112 pgs: 112 active+clean; 2549 bytes data, 158 MB used, 279 GB / 279 GB avail
2018-10-18 05:51:31.257107 7f6c1a100700  0 mon.ceph-node1@0(leader) e3 handle_command mon_command({"prefix": "auth add", "entity": "osd.4", "caps": ["osd", "allow *", "mon", "allow profile osd"]} v 0) v1
2018-10-18 05:51:31.257173 7f6c1a100700  0 log_channel(audit) log [INF] : from='client.? 192.168.136.188:0/2767781874' entity='client.bootstrap-osd' cmd=[{"prefix": "auth add", "entity": "osd.4", "caps": ["osd", "allow *", "mon", "allow profile osd"]}]: dispatch
2018-10-18 05:51:31.511269 7f6c1c2d1700  0 log_channel(audit) log [INF] : from='client.? 192.168.136.188:0/2767781874' entity='client.bootstrap-osd' cmd='[{"prefix": "auth add", "entity": "osd.4", "caps": ["osd", "allow *", "mon", "allow profile osd"]}]': finished
2018-10-18 05:51:32.052605 7f6c1a100700  0 mon.ceph-node1@0(leader) e3 handle_command mon_command({"prefix": "osd find", "id": 4} v 0) v1
2018-10-18 05:51:32.052673 7f6c1a100700  0 log_channel(audit) log [DBG] : from='client.? 192.168.136.188:0/3854610234' entity='osd.4' cmd=[{"prefix": "osd find", "id": 4}]: dispatch
2018-10-18 05:51:32.162581 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v993 unable to write to '/var/log/ceph/ceph.audit.log' for channel 'audit': (2) No such file or directory
2018-10-18 05:51:32.162613 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v993 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:51:32.775094 7f6c1a100700  0 mon.ceph-node1@0(leader) e3 handle_command mon_command({"prefix": "osd crush create-or-move", "args": ["root=default", "host=ceph-node2"], "id": 4, "weight": 0.06} v 0) v1
2018-10-18 05:51:32.775176 7f6c1a100700  0 log_channel(audit) log [INF] : from='client.? 192.168.136.188:0/3968894183' entity='osd.4' cmd=[{"prefix": "osd crush create-or-move", "args": ["root=default", "host=ceph-node2"], "id": 4, "weight": 0.06}]: dispatch
2018-10-18 05:51:32.775348 7f6c1a100700  0 mon.ceph-node1@0(leader).osd e151 create-or-move crush item name 'osd.4' initial_weight 0.06 at location {host=ceph-node2,root=default}
2018-10-18 05:51:33.175119 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v994 unable to write to '/var/log/ceph/ceph.audit.log' for channel 'audit': (2) No such file or directory
2018-10-18 05:51:33.191821 7f6c1c2d1700  1 mon.ceph-node1@0(leader).osd e152 e152: 5 osds: 4 up, 4 in
2018-10-18 05:51:33.197054 7f6c1c2d1700  0 log_channel(audit) log [INF] : from='client.? 192.168.136.188:0/3968894183' entity='osd.4' cmd='[{"prefix": "osd crush create-or-move", "args": ["root=default", "host=ceph-node2"], "id": 4, "weight": 0.06}]': finished
2018-10-18 05:51:33.197175 7f6c1c2d1700  0 log_channel(cluster) log [INF] : osdmap e152: 5 osds: 4 up, 4 in
2018-10-18 05:51:33.198960 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v796: 112 pgs: 112 active+clean; 2549 bytes data, 158 MB used, 279 GB / 279 GB avail
2018-10-18 05:51:33.274446 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v797: 112 pgs: 112 active+clean; 2549 bytes data, 158 MB used, 279 GB / 279 GB avail
2018-10-18 05:51:34.223271 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v995 unable to write to '/var/log/ceph/ceph.audit.log' for channel 'audit': (2) No such file or directory
2018-10-18 05:51:34.223302 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v995 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:51:34.263228 7f6c1c2d1700  1 mon.ceph-node1@0(leader).osd e153 e153: 5 osds: 4 up, 4 in
2018-10-18 05:51:34.270175 7f6c1c2d1700  0 log_channel(cluster) log [INF] : osdmap e153: 5 osds: 4 up, 4 in
2018-10-18 05:51:34.297476 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v798: 112 pgs: 112 active+clean; 2549 bytes data, 158 MB used, 279 GB / 279 GB avail
2018-10-18 05:51:35.280379 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v996 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:51:35.300363 7f6c1c2d1700  1 mon.ceph-node1@0(leader).osd e154 e154: 5 osds: 5 up, 5 in
2018-10-18 05:51:35.302743 7f6c1c2d1700  0 log_channel(cluster) log [INF] : osd.4 192.168.136.188:6801/8867 boot
2018-10-18 05:51:35.302892 7f6c1c2d1700  0 log_channel(cluster) log [INF] : osdmap e154: 5 osds: 5 up, 5 in
2018-10-18 05:51:35.346930 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v800: 112 pgs: 26 peering, 86 active+clean; 2549 bytes data, 158 MB used, 279 GB / 279 GB avail
2018-10-18 05:51:36.323489 7f6c1c2d1700  1 mon.ceph-node1@0(leader).osd e155 e155: 5 osds: 5 up, 5 in
2018-10-18 05:51:36.331229 7f6c1c2d1700  0 log_channel(cluster) log [INF] : osdmap e155: 5 osds: 5 up, 5 in
2018-10-18 05:51:36.358996 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v997 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:51:36.359494 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v801: 112 pgs: 17 remapped+peering, 26 peering, 69 active+clean; 2549 bytes data, 158 MB used, 279 GB / 279 GB avail
2018-10-18 05:51:37.336768 7f6c1c2d1700  1 mon.ceph-node1@0(leader).osd e156 e156: 5 osds: 5 up, 5 in
2018-10-18 05:51:37.344772 7f6c1c2d1700  0 log_channel(cluster) log [INF] : osdmap e156: 5 osds: 5 up, 5 in
2018-10-18 05:51:37.380853 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v802: 112 pgs: 17 remapped+peering, 40 peering, 55 active+clean; 2549 bytes data, 159 MB used, 279 GB / 279 GB avail
2018-10-18 05:51:37.395303 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v998 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:51:38.425628 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v999 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:51:39.769511 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v803: 112 pgs: 17 remapped+peering, 29 peering, 66 active+clean; 2549 bytes data, 160 MB used, 279 GB / 279 GB avail; 0 B/s, 16 objects/s recovering
2018-10-18 05:51:40.850724 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1000 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:51:40.870383 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v804: 112 pgs: 9 remapped+peering, 14 peering, 89 active+clean; 2549 bytes data, 197 MB used, 339 GB / 339 GB avail; 881 B/s, 1 keys/s, 47 objects/s recovering
2018-10-18 05:51:41.917694 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1001 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:51:41.939558 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v805: 112 pgs: 14 peering, 98 active+clean; 2549 bytes data, 198 MB used, 339 GB / 339 GB avail; 1748 B/s, 3 keys/s, 75 objects/s recovering
2018-10-18 05:51:42.962457 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1002 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:51:42.975646 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v806: 112 pgs: 112 active+clean; 2549 bytes data, 198 MB used, 339 GB / 339 GB avail; 307 B/s, 1 keys/s, 71 objects/s recovering
2018-10-18 05:51:43.139384 7f6c16313700  1 leveldb: Level-0 table #186: started
2018-10-18 05:51:43.150471 7f6c16313700  1 leveldb: Level-0 table #186: 1720733 bytes OK
2018-10-18 05:51:43.151133 7f6c16313700  1 leveldb: Delete type=0 #179

2018-10-18 05:51:43.152177 7f6c16313700  1 leveldb: Manual compaction at level-0 from 'logm\x00251' @ 72057594037927935 : 1 .. 'logm\x00502' @ 0 : 0; will stop at 'pgmap_pg\x006.7' @ 29127 : 1

2018-10-18 05:51:43.152203 7f6c16313700  1 leveldb: Compacting 1@0 + 4@1 files
2018-10-18 05:51:43.165281 7f6c16313700  1 leveldb: Generated table #187: 710 keys, 2117649 bytes
2018-10-18 05:51:43.178468 7f6c16313700  1 leveldb: Generated table #188: 424 keys, 2117297 bytes
2018-10-18 05:51:43.192584 7f6c16313700  1 leveldb: Generated table #189: 256 keys, 2138226 bytes
2018-10-18 05:51:43.209139 7f6c16313700  1 leveldb: Generated table #190: 241 keys, 2121349 bytes
2018-10-18 05:51:43.216123 7f6c16313700  1 leveldb: Generated table #191: 738 keys, 715563 bytes
2018-10-18 05:51:43.216173 7f6c16313700  1 leveldb: Compacted 1@0 + 4@1 files => 9210084 bytes
2018-10-18 05:51:43.216480 7f6c16313700  1 leveldb: compacted to: files[ 0 5 4 0 0 0 0 ]
2018-10-18 05:51:43.216859 7f6c16313700  1 leveldb: Delete type=2 #186

2018-10-18 05:51:43.217715 7f6c16313700  1 leveldb: Delete type=2 #181

2018-10-18 05:51:43.219054 7f6c16313700  1 leveldb: Delete type=2 #182

2018-10-18 05:51:43.220011 7f6c16313700  1 leveldb: Delete type=2 #183

2018-10-18 05:51:43.220982 7f6c16313700  1 leveldb: Delete type=2 #184

2018-10-18 05:51:43.221507 7f6c16313700  1 leveldb: Manual compaction at level-0 from 'pgmap_pg\x006.7' @ 29127 : 1 .. 'logm\x00502' @ 0 : 0; will stop at (end)

2018-10-18 05:51:43.221719 7f6c16313700  1 leveldb: Manual compaction at level-1 from 'logm\x00251' @ 72057594037927935 : 1 .. 'logm\x00502' @ 0 : 0; will stop at 'logm\x00full_945' @ 27953 : 1

2018-10-18 05:51:43.221739 7f6c16313700  1 leveldb: Compacting 1@1 + 4@2 files
2018-10-18 05:51:43.236088 7f6c16313700  1 leveldb: Generated table #192: 713 keys, 2152950 bytes
2018-10-18 05:51:43.251370 7f6c16313700  1 leveldb: Generated table #193: 151 keys, 2152084 bytes
2018-10-18 05:51:43.267458 7f6c16313700  1 leveldb: Generated table #194: 145 keys, 2112097 bytes
2018-10-18 05:51:43.272368 7f6c16313700  1 leveldb: Generated table #195: 7 keys, 103084 bytes
2018-10-18 05:51:43.272403 7f6c16313700  1 leveldb: Compacted 1@1 + 4@2 files => 6520215 bytes
2018-10-18 05:51:43.272715 7f6c16313700  1 leveldb: compacted to: files[ 0 4 4 0 0 0 0 ]
2018-10-18 05:51:43.273056 7f6c16313700  1 leveldb: Delete type=2 #173

2018-10-18 05:51:43.273915 7f6c16313700  1 leveldb: Delete type=2 #174

2018-10-18 05:51:43.274729 7f6c16313700  1 leveldb: Delete type=2 #175

2018-10-18 05:51:43.275565 7f6c16313700  1 leveldb: Delete type=2 #176

2018-10-18 05:51:43.276977 7f6c16313700  1 leveldb: Delete type=2 #187

2018-10-18 05:51:43.279699 7f6c16313700  1 leveldb: Manual compaction at level-1 from 'logm\x00full_945' @ 27953 : 1 .. 'logm\x00502' @ 0 : 0; will stop at (end)

2018-10-18 05:51:43.280035 7f6c16313700  1 leveldb: Level-0 table #197: started
2018-10-18 05:51:43.280094 7f6c16313700  1 leveldb: Level-0 table #197: 0 bytes OK
2018-10-18 05:51:43.280622 7f6c16313700  1 leveldb: Delete type=0 #185

2018-10-18 05:51:43.280889 7f6c16313700  1 leveldb: Manual compaction at level-0 from 'logm\x00full_251' @ 72057594037927935 : 1 .. 'logm\x00full_502' @ 0 : 0; will stop at (end)

2018-10-18 05:51:43.281059 7f6c16313700  1 leveldb: Manual compaction at level-1 from 'logm\x00full_251' @ 72057594037927935 : 1 .. 'logm\x00full_502' @ 0 : 0; will stop at (end)

2018-10-18 05:51:43.995665 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1003 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:51:45.078600 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v807: 112 pgs: 112 active+clean; 2549 bytes data, 198 MB used, 339 GB / 339 GB avail; 0 B/s, 32 objects/s recovering
2018-10-18 05:51:45.683027 7f6c1a100700  0 mon.ceph-node1@0(leader) e3 handle_command mon_command({"prefix": "health"} v 0) v1
2018-10-18 05:51:45.683084 7f6c1a100700  0 log_channel(audit) log [DBG] : from='client.? 192.168.136.189:0/259514029' entity='client.bootstrap-osd' cmd=[{"prefix": "health"}]: dispatch
2018-10-18 05:51:46.120798 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1004 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:51:46.137201 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v808: 112 pgs: 112 active+clean; 2549 bytes data, 193 MB used, 339 GB / 339 GB avail
2018-10-18 05:51:47.143871 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1005 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:51:47.155364 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v809: 112 pgs: 112 active+clean; 2549 bytes data, 192 MB used, 339 GB / 339 GB avail
2018-10-18 05:51:48.178389 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v810: 112 pgs: 112 active+clean; 2549 bytes data, 192 MB used, 339 GB / 339 GB avail
2018-10-18 05:51:48.243266 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1006 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:51:49.295467 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1007 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:51:50.304652 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v811: 112 pgs: 112 active+clean; 2549 bytes data, 192 MB used, 339 GB / 339 GB avail
2018-10-18 05:51:51.360954 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1008 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:51:52.331661 7f6c1a100700  0 mon.ceph-node1@0(leader) e3 handle_command mon_command({"prefix": "osd create", "uuid": "83f31687-c618-4841-9f85-8ba27db8da45"} v 0) v1
2018-10-18 05:51:52.331737 7f6c1a100700  0 log_channel(audit) log [INF] : from='client.? 192.168.136.189:0/3715285154' entity='client.bootstrap-osd' cmd=[{"prefix": "osd create", "uuid": "83f31687-c618-4841-9f85-8ba27db8da45"}]: dispatch
2018-10-18 05:51:52.385608 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1009 unable to write to '/var/log/ceph/ceph.audit.log' for channel 'audit': (2) No such file or directory
2018-10-18 05:51:52.408510 7f6c1c2d1700  1 mon.ceph-node1@0(leader).osd e157 e157: 6 osds: 5 up, 5 in
2018-10-18 05:51:52.409277 7f6c1c2d1700  0 log_channel(audit) log [INF] : from='client.? 192.168.136.189:0/3715285154' entity='client.bootstrap-osd' cmd='[{"prefix": "osd create", "uuid": "83f31687-c618-4841-9f85-8ba27db8da45"}]': finished
2018-10-18 05:51:52.410195 7f6c1c2d1700  0 log_channel(cluster) log [INF] : osdmap e157: 6 osds: 5 up, 5 in
2018-10-18 05:51:52.446780 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v812: 112 pgs: 112 active+clean; 2549 bytes data, 192 MB used, 339 GB / 339 GB avail
2018-10-18 05:51:52.967029 7f6c1a100700  0 mon.ceph-node1@0(leader) e3 handle_command mon_command({"prefix": "mon getmap"} v 0) v1
2018-10-18 05:51:52.967076 7f6c1a100700  0 log_channel(audit) log [DBG] : from='client.? 192.168.136.189:0/1605120536' entity='client.bootstrap-osd' cmd=[{"prefix": "mon getmap"}]: dispatch
2018-10-18 05:51:53.062220 7f6c1a100700  0 mon.ceph-node1@0(leader) e3 handle_command mon_command({"prefix": "osd tree"} v 0) v1
2018-10-18 05:51:53.062282 7f6c1a100700  0 log_channel(audit) log [DBG] : from='client.? 192.168.136.188:0/3407455927' entity='client.admin' cmd=[{"prefix": "osd tree"}]: dispatch
2018-10-18 05:51:53.430373 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1010 unable to write to '/var/log/ceph/ceph.audit.log' for channel 'audit': (2) No such file or directory
2018-10-18 05:51:53.430445 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1010 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:51:53.883681 7f6c1a100700  0 mon.ceph-node1@0(leader) e3 handle_command mon_command({"prefix": "auth add", "entity": "osd.5", "caps": ["osd", "allow *", "mon", "allow profile osd"]} v 0) v1
2018-10-18 05:51:53.883730 7f6c1a100700  0 log_channel(audit) log [INF] : from='client.? 192.168.136.189:0/2033291636' entity='client.bootstrap-osd' cmd=[{"prefix": "auth add", "entity": "osd.5", "caps": ["osd", "allow *", "mon", "allow profile osd"]}]: dispatch
2018-10-18 05:51:53.898153 7f6c1c2d1700  0 log_channel(audit) log [INF] : from='client.? 192.168.136.189:0/2033291636' entity='client.bootstrap-osd' cmd='[{"prefix": "auth add", "entity": "osd.5", "caps": ["osd", "allow *", "mon", "allow profile osd"]}]': finished
2018-10-18 05:51:54.447175 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1011 unable to write to '/var/log/ceph/ceph.audit.log' for channel 'audit': (2) No such file or directory
2018-10-18 05:51:54.556571 7f6c1a100700  0 mon.ceph-node1@0(leader) e3 handle_command mon_command({"prefix": "osd find", "id": 5} v 0) v1
2018-10-18 05:51:54.556725 7f6c1a100700  0 log_channel(audit) log [DBG] : from='client.? 192.168.136.189:0/970484473' entity='osd.5' cmd=[{"prefix": "osd find", "id": 5}]: dispatch
2018-10-18 05:51:55.139107 7f6c1a100700  0 mon.ceph-node1@0(leader) e3 handle_command mon_command({"prefix": "osd crush create-or-move", "args": ["root=default", "host=ceph-node3"], "id": 5, "weight": 0.06} v 0) v1
2018-10-18 05:51:55.139195 7f6c1a100700  0 log_channel(audit) log [INF] : from='client.? 192.168.136.189:0/2689784647' entity='osd.5' cmd=[{"prefix": "osd crush create-or-move", "args": ["root=default", "host=ceph-node3"], "id": 5, "weight": 0.06}]: dispatch
2018-10-18 05:51:55.139416 7f6c1a100700  0 mon.ceph-node1@0(leader).osd e157 create-or-move crush item name 'osd.5' initial_weight 0.06 at location {host=ceph-node3,root=default}
2018-10-18 05:51:55.465640 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v813: 112 pgs: 112 active+clean; 2549 bytes data, 192 MB used, 339 GB / 339 GB avail
2018-10-18 05:51:55.485057 7f6c1c2d1700  1 mon.ceph-node1@0(leader).osd e158 e158: 6 osds: 5 up, 5 in
2018-10-18 05:51:55.486042 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1012 unable to write to '/var/log/ceph/ceph.audit.log' for channel 'audit': (2) No such file or directory
2018-10-18 05:51:55.486702 7f6c1c2d1700  0 log_channel(audit) log [INF] : from='client.? 192.168.136.189:0/2689784647' entity='osd.5' cmd='[{"prefix": "osd crush create-or-move", "args": ["root=default", "host=ceph-node3"], "id": 5, "weight": 0.06}]': finished
2018-10-18 05:51:55.488747 7f6c1c2d1700  0 log_channel(cluster) log [INF] : osdmap e158: 6 osds: 5 up, 5 in
2018-10-18 05:51:55.521881 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v814: 112 pgs: 112 active+clean; 2549 bytes data, 192 MB used, 339 GB / 339 GB avail
2018-10-18 05:51:56.531824 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1013 unable to write to '/var/log/ceph/ceph.audit.log' for channel 'audit': (2) No such file or directory
2018-10-18 05:51:56.531865 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1013 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:51:56.553673 7f6c1c2d1700  1 mon.ceph-node1@0(leader).osd e159 e159: 6 osds: 5 up, 5 in
2018-10-18 05:51:56.558629 7f6c1c2d1700  0 log_channel(cluster) log [INF] : osdmap e159: 6 osds: 5 up, 5 in
2018-10-18 05:51:56.560838 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v815: 112 pgs: 10 remapped+peering, 102 active+clean; 2549 bytes data, 192 MB used, 339 GB / 339 GB avail
2018-10-18 05:51:56.635448 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v816: 112 pgs: 10 remapped+peering, 102 active+clean; 2549 bytes data, 192 MB used, 339 GB / 339 GB avail
2018-10-18 05:51:57.638276 7f6c1c2d1700  1 mon.ceph-node1@0(leader).osd e160 e160: 6 osds: 6 up, 6 in
2018-10-18 05:51:57.653651 7f6c1c2d1700  0 log_channel(cluster) log [INF] : osd.5 192.168.136.189:6804/14124 boot
2018-10-18 05:51:57.654340 7f6c1c2d1700  0 log_channel(cluster) log [INF] : osdmap e160: 6 osds: 6 up, 6 in
2018-10-18 05:51:58.154793 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1014 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:51:58.188091 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v818: 112 pgs: 10 peering, 9 remapped+peering, 93 active+clean; 2549 bytes data, 193 MB used, 339 GB / 339 GB avail
2018-10-18 05:51:58.303137 7f6c1c2d1700  1 mon.ceph-node1@0(leader).osd e161 e161: 6 osds: 6 up, 6 in
2018-10-18 05:51:58.360297 7f6c1c2d1700  0 log_channel(cluster) log [INF] : osdmap e161: 6 osds: 6 up, 6 in
2018-10-18 05:51:58.493728 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v819: 112 pgs: 10 peering, 9 remapped+peering, 93 active+clean; 2549 bytes data, 193 MB used, 339 GB / 339 GB avail
2018-10-18 05:51:59.132411 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1015 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:51:59.320791 7f6c1c2d1700  1 mon.ceph-node1@0(leader).osd e162 e162: 6 osds: 6 up, 6 in
2018-10-18 05:51:59.333527 7f6c1c2d1700  0 log_channel(cluster) log [INF] : osdmap e162: 6 osds: 6 up, 6 in
2018-10-18 05:51:59.355470 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v820: 112 pgs: 10 peering, 9 remapped+peering, 93 active+clean; 2549 bytes data, 193 MB used, 339 GB / 339 GB avail
2018-10-18 05:52:00.356598 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1016 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:52:00.373780 7f6c1c2d1700  1 mon.ceph-node1@0(leader).osd e163 e163: 6 osds: 6 up, 6 in
2018-10-18 05:52:00.378354 7f6c1c2d1700  0 log_channel(cluster) log [INF] : osdmap e163: 6 osds: 6 up, 6 in
2018-10-18 05:52:00.434430 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v822: 112 pgs: 1 activating, 21 peering, 9 remapped+peering, 1 activating+degraded, 80 active+clean; 2549 bytes data, 194 MB used, 339 GB / 339 GB avail; 2743 B/s, 4 objects/s recovering
2018-10-18 05:52:01.194445 7f6c1a100700  0 mon.ceph-node1@0(leader) e3 handle_command mon_command({"prefix": "osd tree"} v 0) v1
2018-10-18 05:52:01.194504 7f6c1a100700  0 log_channel(audit) log [DBG] : from='client.? 192.168.136.188:0/432934869' entity='client.admin' cmd=[{"prefix": "osd tree"}]: dispatch
2018-10-18 05:52:01.393310 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1017 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:52:01.453972 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v823: 112 pgs: 1 activating, 21 peering, 8 remapped+peering, 1 activating+degraded, 81 active+clean; 2549 bytes data, 195 MB used, 339 GB / 339 GB avail; 0 B/s, 61 objects/s recovering
2018-10-18 05:52:02.485411 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1018 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:52:02.499079 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v824: 112 pgs: 1 activating, 11 peering, 1 activating+degraded, 99 active+clean; 2549 bytes data, 238 MB used, 398 GB / 399 GB avail; 502 B/s rd, 0 op/s; 0 B/s, 29 objects/s recovering
2018-10-18 05:52:02.523122 7f6c1a100700  0 mon.ceph-node1@0(leader) e3 handle_command mon_command({"prefix": "osd tree"} v 0) v1
2018-10-18 05:52:02.523182 7f6c1a100700  0 log_channel(audit) log [DBG] : from='client.? 192.168.136.188:0/694855191' entity='client.admin' cmd=[{"prefix": "osd tree"}]: dispatch
2018-10-18 05:52:03.509399 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1019 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:52:04.791726 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v825: 112 pgs: 10 peering, 102 active+clean; 2549 bytes data, 238 MB used, 398 GB / 399 GB avail; 306 B/s rd, 0 op/s; 0 B/s, 15 objects/s recovering
2018-10-18 05:52:05.819148 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1020 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:52:05.838644 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v826: 112 pgs: 112 active+clean; 2549 bytes data, 239 MB used, 398 GB / 399 GB avail; 1 B/s, 0 keys/s, 43 objects/s recovering
2018-10-18 05:52:06.853409 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1021 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:52:06.862466 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v827: 112 pgs: 112 active+clean; 2549 bytes data, 234 MB used, 398 GB / 399 GB avail; 1 B/s, 0 keys/s, 42 objects/s recovering
2018-10-18 05:52:07.893282 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1022 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:52:07.909511 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v828: 112 pgs: 112 active+clean; 2549 bytes data, 234 MB used, 398 GB / 399 GB avail
2018-10-18 05:52:08.289591 7f6c1a100700  0 mon.ceph-node1@0(leader) e3 handle_command mon_command({"prefix": "osd tree"} v 0) v1
2018-10-18 05:52:08.289652 7f6c1a100700  0 log_channel(audit) log [DBG] : from='client.? 192.168.136.188:0/721738729' entity='client.admin' cmd=[{"prefix": "osd tree"}]: dispatch
2018-10-18 05:52:08.929559 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1023 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:52:09.944746 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v829: 112 pgs: 112 active+clean; 2549 bytes data, 234 MB used, 398 GB / 399 GB avail
2018-10-18 05:52:10.965664 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1024 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:52:10.983238 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v830: 112 pgs: 112 active+clean; 2549 bytes data, 234 MB used, 398 GB / 399 GB avail
2018-10-18 05:52:12.009975 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1025 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:52:12.021896 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v831: 112 pgs: 112 active+clean; 2549 bytes data, 233 MB used, 398 GB / 399 GB avail
2018-10-18 05:52:13.036311 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1026 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:52:15.476549 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v832: 112 pgs: 112 active+clean; 2549 bytes data, 233 MB used, 398 GB / 399 GB avail
2018-10-18 05:52:16.491257 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1027 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:52:17.753879 7f6c1a901700  0 mon.ceph-node1@0(leader).data_health(224) update_stats avail 69% total 51175 MB, used 15465 MB, avail 35709 MB
2018-10-18 05:52:17.793475 7f6c1a901700  0 log_channel(cluster) log [INF] : HEALTH_WARN; clock skew detected on mon.ceph-node2, mon.ceph-node3; Monitor clock skew detected 
2018-10-18 05:52:17.862323 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1028 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:52:20.467320 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v833: 112 pgs: 112 active+clean; 2549 bytes data, 233 MB used, 398 GB / 399 GB avail
2018-10-18 05:52:21.495493 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1029 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:52:21.501193 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v834: 112 pgs: 112 active+clean; 2549 bytes data, 233 MB used, 398 GB / 399 GB avail
2018-10-18 05:52:22.292980 7f6c1a100700  0 mon.ceph-node1@0(leader) e3 handle_command mon_command({"prefix": "osd tree"} v 0) v1
2018-10-18 05:52:22.293039 7f6c1a100700  0 log_channel(audit) log [DBG] : from='client.? 192.168.136.188:0/3940302103' entity='client.admin' cmd=[{"prefix": "osd tree"}]: dispatch
2018-10-18 05:52:22.517840 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1030 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:52:25.065973 7f6c1a100700  0 mon.ceph-node1@0(leader) e3 handle_command mon_command({"prefix": "osd tree"} v 0) v1
2018-10-18 05:52:25.066026 7f6c1a100700  0 log_channel(audit) log [DBG] : from='client.? 192.168.136.188:0/2857894790' entity='client.admin' cmd=[{"prefix": "osd tree"}]: dispatch
2018-10-18 05:52:26.878431 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v835: 112 pgs: 112 active+clean; 2549 bytes data, 233 MB used, 398 GB / 399 GB avail; 958 B/s rd, 0 B/s wr, 1 op/s
2018-10-18 05:52:28.016814 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1032 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:52:28.050579 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v836: 112 pgs: 112 active+clean; 2549 bytes data, 233 MB used, 398 GB / 399 GB avail; 3361 B/s rd, 0 B/s wr, 5 op/s
2018-10-18 05:52:29.062349 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1033 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:52:30.067049 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v837: 112 pgs: 112 active+clean; 2549 bytes data, 234 MB used, 398 GB / 399 GB avail; 25006 B/s rd, 0 B/s wr, 40 op/s
2018-10-18 05:52:31.081962 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1034 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:52:31.089116 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v838: 112 pgs: 112 active+clean; 2549 bytes data, 234 MB used, 398 GB / 399 GB avail; 57675 B/s rd, 0 B/s wr, 93 op/s
2018-10-18 05:52:32.096224 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1035 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:52:32.106394 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v839: 112 pgs: 112 active+clean; 2549 bytes data, 234 MB used, 398 GB / 399 GB avail; 130 kB/s rd, 0 B/s wr, 216 op/s
2018-10-18 05:52:33.140756 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1036 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:52:33.153570 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v840: 112 pgs: 112 active+clean; 2549 bytes data, 234 MB used, 398 GB / 399 GB avail; 89962 B/s rd, 0 B/s wr, 146 op/s
2018-10-18 05:52:34.176006 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1037 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:52:35.184971 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v841: 112 pgs: 112 active+clean; 2549 bytes data, 234 MB used, 398 GB / 399 GB avail; 10955 B/s rd, 0 B/s wr, 17 op/s
2018-10-18 05:52:36.219243 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1038 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:52:36.245542 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v842: 112 pgs: 112 active+clean; 2549 bytes data, 234 MB used, 398 GB / 399 GB avail
2018-10-18 05:52:37.258051 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1039 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:52:37.272565 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v843: 112 pgs: 112 active+clean; 2549 bytes data, 234 MB used, 398 GB / 399 GB avail
2018-10-18 05:52:38.275826 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1040 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:52:38.290573 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v844: 112 pgs: 112 active+clean; 2549 bytes data, 234 MB used, 398 GB / 399 GB avail
2018-10-18 05:52:39.302171 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1041 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:52:40.312739 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v845: 112 pgs: 112 active+clean; 2549 bytes data, 234 MB used, 398 GB / 399 GB avail
2018-10-18 05:52:41.333659 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1042 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:52:41.342437 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v846: 112 pgs: 112 active+clean; 2549 bytes data, 234 MB used, 398 GB / 399 GB avail
2018-10-18 05:52:42.375735 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1043 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:52:42.398281 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v847: 112 pgs: 112 active+clean; 2549 bytes data, 234 MB used, 398 GB / 399 GB avail
2018-10-18 05:52:43.442486 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1044 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:52:47.938538 7f6c1a100700  0 log_channel(cluster) log [WRN] : mon.1 192.168.136.188:6789/0 clock skew 1160.94s > max 0.05s
2018-10-18 05:52:47.942440 7f6c1a100700  0 log_channel(cluster) log [WRN] : mon.2 192.168.136.189:6789/0 clock skew 1167.73s > max 0.05s
2018-10-18 05:52:48.039530 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1045 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:52:51.474807 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v848: 112 pgs: 112 active+clean; 2549 bytes data, 234 MB used, 398 GB / 399 GB avail
2018-10-18 05:52:52.513447 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1046 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:52:52.665646 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v849: 112 pgs: 112 active+clean; 2549 bytes data, 234 MB used, 398 GB / 399 GB avail
2018-10-18 05:52:53.675472 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1047 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:52:54.813713 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v850: 112 pgs: 112 active+clean; 2549 bytes data, 234 MB used, 398 GB / 399 GB avail
2018-10-18 05:52:55.836019 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1048 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:52:55.850100 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v851: 112 pgs: 112 active+clean; 2549 bytes data, 234 MB used, 398 GB / 399 GB avail; 4917 B/s rd, 7 op/s
2018-10-18 05:52:56.864844 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1049 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:52:56.877099 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v852: 112 pgs: 112 active+clean; 2549 bytes data, 234 MB used, 398 GB / 399 GB avail; 7998 B/s rd, 11 op/s
2018-10-18 05:52:57.898188 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1050 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:52:57.908965 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v853: 112 pgs: 112 active+clean; 2549 bytes data, 234 MB used, 398 GB / 399 GB avail
2018-10-18 05:52:59.377493 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1051 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:53:00.393379 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v854: 112 pgs: 112 active+clean; 2549 bytes data, 234 MB used, 398 GB / 399 GB avail
2018-10-18 05:53:01.400690 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1052 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:53:01.413049 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v855: 112 pgs: 112 active+clean; 2549 bytes data, 234 MB used, 398 GB / 399 GB avail
2018-10-18 05:53:02.436104 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1053 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:53:02.453712 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v856: 112 pgs: 112 active+clean; 2549 bytes data, 234 MB used, 398 GB / 399 GB avail
2018-10-18 05:53:03.469393 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1054 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:53:05.736435 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1055 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:53:06.750830 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v857: 112 pgs: 112 active+clean; 2549 bytes data, 234 MB used, 398 GB / 399 GB avail
2018-10-18 05:53:07.761871 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1056 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:53:07.773515 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v858: 112 pgs: 112 active+clean; 2549 bytes data, 234 MB used, 398 GB / 399 GB avail
2018-10-18 05:53:08.797829 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1057 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:53:09.816707 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v859: 112 pgs: 112 active+clean; 2549 bytes data, 234 MB used, 398 GB / 399 GB avail
2018-10-18 05:53:10.829496 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1058 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:53:10.848280 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v860: 112 pgs: 112 active+clean; 2549 bytes data, 234 MB used, 398 GB / 399 GB avail; 5340 B/s rd, 7 op/s
2018-10-18 05:53:11.866529 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1059 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:53:11.896763 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v861: 112 pgs: 112 active+clean; 2549 bytes data, 234 MB used, 398 GB / 399 GB avail; 7980 B/s rd, 11 op/s
2018-10-18 05:53:12.905887 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1060 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:53:12.915081 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v862: 112 pgs: 112 active+clean; 2549 bytes data, 234 MB used, 398 GB / 399 GB avail
2018-10-18 05:53:13.935291 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1061 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:53:14.946646 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v863: 112 pgs: 112 active+clean; 2549 bytes data, 234 MB used, 398 GB / 399 GB avail
2018-10-18 05:53:15.962418 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1062 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:53:15.976494 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v864: 112 pgs: 112 active+clean; 2549 bytes data, 234 MB used, 398 GB / 399 GB avail
2018-10-18 05:53:16.987966 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1063 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:53:16.997250 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v865: 112 pgs: 112 active+clean; 2549 bytes data, 234 MB used, 398 GB / 399 GB avail
2018-10-18 05:53:17.754395 7f6c1a901700  0 mon.ceph-node1@0(leader).data_health(224) update_stats avail 69% total 51175 MB, used 15466 MB, avail 35708 MB
2018-10-18 05:53:17.793980 7f6c1a901700  0 log_channel(cluster) log [INF] : HEALTH_WARN; clock skew detected on mon.ceph-node2, mon.ceph-node3; 2 requests are blocked > 32 sec; Monitor clock skew detected 
2018-10-18 05:53:18.009224 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1064 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:53:59.845102 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v866: 112 pgs: 112 active+clean; 2549 bytes data, 234 MB used, 398 GB / 399 GB avail
2018-10-18 05:54:00.851004 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1065 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:54:00.859053 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v867: 112 pgs: 112 active+clean; 2549 bytes data, 234 MB used, 398 GB / 399 GB avail; 373 B/s rd, 0 op/s
2018-10-18 05:54:01.890963 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1066 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:54:01.921630 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v868: 112 pgs: 112 active+clean; 2549 bytes data, 234 MB used, 398 GB / 399 GB avail; 8053 B/s rd, 11 op/s
2018-10-18 05:54:02.948665 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1067 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:54:02.962543 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v869: 112 pgs: 112 active+clean; 2549 bytes data, 234 MB used, 398 GB / 399 GB avail
2018-10-18 05:54:03.981562 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1068 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:54:05.004236 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v870: 112 pgs: 112 active+clean; 2549 bytes data, 234 MB used, 398 GB / 399 GB avail
2018-10-18 05:54:06.009245 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1069 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:54:06.023741 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v871: 112 pgs: 112 active+clean; 2549 bytes data, 234 MB used, 398 GB / 399 GB avail
2018-10-18 05:54:07.037653 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1070 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:54:07.107005 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v872: 112 pgs: 112 active+clean; 2549 bytes data, 234 MB used, 398 GB / 399 GB avail
2018-10-18 05:54:08.230180 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1071 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:54:08.313894 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v873: 112 pgs: 112 active+clean; 2549 bytes data, 234 MB used, 398 GB / 399 GB avail
2018-10-18 05:54:09.676785 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1072 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:54:10.695178 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v874: 112 pgs: 112 active+clean; 2549 bytes data, 235 MB used, 398 GB / 399 GB avail; 8977 B/s rd, 13 op/s
2018-10-18 05:54:11.703823 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1073 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:54:11.711490 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v875: 112 pgs: 112 active+clean; 2549 bytes data, 235 MB used, 398 GB / 399 GB avail; 9169 B/s rd, 13 op/s
2018-10-18 05:54:12.739313 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1074 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:54:12.762275 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v876: 112 pgs: 112 active+clean; 2549 bytes data, 235 MB used, 398 GB / 399 GB avail
2018-10-18 05:54:13.784686 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1075 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:54:14.796041 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v877: 112 pgs: 112 active+clean; 2549 bytes data, 235 MB used, 398 GB / 399 GB avail
2018-10-18 05:54:15.819961 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1076 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:54:15.846023 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v878: 112 pgs: 112 active+clean; 2549 bytes data, 235 MB used, 398 GB / 399 GB avail
2018-10-18 05:54:16.863195 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1077 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:54:16.884252 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v879: 112 pgs: 112 active+clean; 2549 bytes data, 235 MB used, 398 GB / 399 GB avail
2018-10-18 05:54:17.755109 7f6c1a901700  0 mon.ceph-node1@0(leader).data_health(224) update_stats avail 69% total 51175 MB, used 15467 MB, avail 35707 MB
2018-10-18 05:54:17.900232 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1078 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:54:17.921971 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v880: 112 pgs: 112 active+clean; 2549 bytes data, 235 MB used, 398 GB / 399 GB avail
2018-10-18 05:54:18.944186 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1079 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:54:19.972849 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v881: 112 pgs: 112 active+clean; 2549 bytes data, 235 MB used, 398 GB / 399 GB avail
2018-10-18 05:54:21.011296 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1080 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:54:21.027226 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v882: 112 pgs: 112 active+clean; 2549 bytes data, 235 MB used, 398 GB / 399 GB avail
2018-10-18 05:54:22.051332 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1081 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:55:17.755735 7f6c1a901700  0 mon.ceph-node1@0(leader).data_health(224) update_stats avail 69% total 51175 MB, used 15472 MB, avail 35702 MB
2018-10-18 05:56:05.755203 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1082 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:56:07.886209 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1083 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:56:17.756321 7f6c1a901700  0 mon.ceph-node1@0(leader).data_health(224) update_stats avail 69% total 51175 MB, used 15472 MB, avail 35702 MB
2018-10-18 05:56:20.454427 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v883: 112 pgs: 112 active+clean; 2549 bytes data, 235 MB used, 398 GB / 399 GB avail
2018-10-18 05:56:21.466462 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1084 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:56:22.475885 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v884: 112 pgs: 112 active+clean; 2549 bytes data, 235 MB used, 398 GB / 399 GB avail; 193 B/s rd, 0 B/s wr, 0 op/s
2018-10-18 05:56:23.489594 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1085 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:56:23.499469 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v885: 112 pgs: 112 active+clean; 2549 bytes data, 235 MB used, 398 GB / 399 GB avail; 12852 B/s rd, 0 B/s wr, 21 op/s
2018-10-18 05:56:24.515344 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1086 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:56:25.529386 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v886: 112 pgs: 112 active+clean; 2549 bytes data, 235 MB used, 398 GB / 399 GB avail; 26192 B/s rd, 0 B/s wr, 42 op/s
2018-10-18 05:56:26.540320 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1087 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:56:26.548287 7f6c16313700  1 leveldb: Level-0 table #199: started
2018-10-18 05:56:26.549445 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v887: 112 pgs: 112 active+clean; 2549 bytes data, 235 MB used, 398 GB / 399 GB avail; 78390 B/s rd, 0 B/s wr, 127 op/s
2018-10-18 05:56:26.565633 7f6c16313700  1 leveldb: Level-0 table #199: 2972606 bytes OK
2018-10-18 05:56:26.566140 7f6c16313700  1 leveldb: Delete type=0 #196

2018-10-18 05:56:26.567504 7f6c16313700  1 leveldb: Manual compaction at level-0 from 'paxos\x001506' @ 72057594037927935 : 1 .. 'paxos\x001758' @ 0 : 0; will stop at 'pgmap_pg\x006.7' @ 30679 : 1

2018-10-18 05:56:26.567527 7f6c16313700  1 leveldb: Compacting 1@0 + 4@1 files
2018-10-18 05:56:26.581790 7f6c16313700  1 leveldb: Generated table #200: 269 keys, 2101332 bytes
2018-10-18 05:56:26.599691 7f6c16313700  1 leveldb: Generated table #201: 431 keys, 2112484 bytes
2018-10-18 05:56:26.613716 7f6c16313700  1 leveldb: Generated table #202: 230 keys, 2151639 bytes
2018-10-18 05:56:26.630063 7f6c16313700  1 leveldb: Generated table #203: 919 keys, 1474661 bytes
2018-10-18 05:56:26.630113 7f6c16313700  1 leveldb: Compacted 1@0 + 4@1 files => 7840116 bytes
2018-10-18 05:56:26.630377 7f6c16313700  1 leveldb: compacted to: files[ 0 4 4 0 0 0 0 ]
2018-10-18 05:56:26.630652 7f6c16313700  1 leveldb: Delete type=2 #189

2018-10-18 05:56:26.631466 7f6c16313700  1 leveldb: Delete type=2 #190

2018-10-18 05:56:26.632187 7f6c16313700  1 leveldb: Delete type=2 #191

2018-10-18 05:56:26.632674 7f6c16313700  1 leveldb: Delete type=2 #188

2018-10-18 05:56:26.633545 7f6c16313700  1 leveldb: Delete type=2 #199

2018-10-18 05:56:26.634424 7f6c16313700  1 leveldb: Manual compaction at level-0 from 'pgmap_pg\x006.7' @ 30679 : 1 .. 'paxos\x001758' @ 0 : 0; will stop at (end)

2018-10-18 05:56:27.563403 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1088 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:56:27.584928 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v888: 112 pgs: 112 active+clean; 2549 bytes data, 235 MB used, 398 GB / 399 GB avail; 121 kB/s rd, 0 B/s wr, 202 op/s
2018-10-18 05:56:28.611669 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v889: 112 pgs: 112 active+clean; 2549 bytes data, 235 MB used, 398 GB / 399 GB avail; 54874 B/s rd, 0 B/s wr, 89 op/s
2018-10-18 05:56:28.628502 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1089 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:56:29.656501 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1090 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:56:30.666462 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v890: 112 pgs: 112 active+clean; 2549 bytes data, 235 MB used, 398 GB / 399 GB avail; 16162 B/s rd, 0 B/s wr, 25 op/s
2018-10-18 05:56:31.679137 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v891: 112 pgs: 112 active+clean; 2549 bytes data, 235 MB used, 398 GB / 399 GB avail; 5317 B/s rd, 7 op/s
2018-10-18 05:56:31.698057 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1091 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:56:32.753505 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1092 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:56:32.771586 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v892: 112 pgs: 112 active+clean; 2549 bytes data, 236 MB used, 398 GB / 399 GB avail
2018-10-18 05:56:33.786995 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1093 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:56:34.920394 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v893: 112 pgs: 112 active+clean; 2549 bytes data, 236 MB used, 398 GB / 399 GB avail
2018-10-18 05:56:35.934933 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1094 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:56:35.945648 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v894: 112 pgs: 112 active+clean; 2549 bytes data, 236 MB used, 398 GB / 399 GB avail
2018-10-18 05:56:36.961126 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1095 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:56:36.976528 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v895: 112 pgs: 112 active+clean; 2549 bytes data, 236 MB used, 398 GB / 399 GB avail
2018-10-18 05:56:37.990101 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1096 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:56:38.005251 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v896: 112 pgs: 112 active+clean; 2549 bytes data, 235 MB used, 398 GB / 399 GB avail
2018-10-18 05:56:39.029696 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1097 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:57:11.590290 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v897: 112 pgs: 112 active+clean; 2549 bytes data, 235 MB used, 398 GB / 399 GB avail; 182 B/s rd, 0 B/s wr, 0 op/s
2018-10-18 05:57:12.613653 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1098 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:57:12.629856 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v898: 112 pgs: 112 active+clean; 2549 bytes data, 236 MB used, 398 GB / 399 GB avail; 2751 B/s rd, 0 B/s wr, 4 op/s
2018-10-18 05:57:13.652548 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1099 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:57:14.937440 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v899: 112 pgs: 112 active+clean; 2549 bytes data, 236 MB used, 398 GB / 399 GB avail; 45857 B/s rd, 0 B/s wr, 74 op/s
2018-10-18 05:57:15.959927 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1100 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:57:16.007327 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v900: 112 pgs: 112 active+clean; 2549 bytes data, 236 MB used, 398 GB / 399 GB avail; 55030 B/s rd, 0 B/s wr, 89 op/s
2018-10-18 05:57:17.013753 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1101 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:57:17.024486 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v901: 112 pgs: 112 active+clean; 2549 bytes data, 236 MB used, 398 GB / 399 GB avail; 102 kB/s rd, 0 B/s wr, 171 op/s
2018-10-18 05:57:17.756949 7f6c1a901700  0 mon.ceph-node1@0(leader).data_health(224) update_stats avail 69% total 51175 MB, used 15471 MB, avail 35703 MB
2018-10-18 05:57:18.038405 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1102 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:57:18.049181 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v902: 112 pgs: 112 active+clean; 2549 bytes data, 236 MB used, 398 GB / 399 GB avail; 52980 B/s rd, 0 B/s wr, 86 op/s
2018-10-18 05:57:19.058202 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1103 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:57:20.086545 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v903: 112 pgs: 112 active+clean; 2549 bytes data, 236 MB used, 398 GB / 399 GB avail; 4018 B/s rd, 0 B/s wr, 6 op/s
2018-10-18 05:57:21.098960 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1104 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:57:21.113115 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v904: 112 pgs: 112 active+clean; 2549 bytes data, 236 MB used, 398 GB / 399 GB avail
2018-10-18 05:57:22.137128 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1105 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:57:22.193795 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v905: 112 pgs: 112 active+clean; 2549 bytes data, 236 MB used, 398 GB / 399 GB avail
2018-10-18 05:57:23.206641 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1106 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:57:23.228786 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v906: 112 pgs: 112 active+clean; 2549 bytes data, 236 MB used, 398 GB / 399 GB avail
2018-10-18 05:57:24.258583 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1107 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:57:47.944588 7f6c1a100700  0 log_channel(cluster) log [WRN] : mon.1 192.168.136.188:6789/0 clock skew 1160.94s > max 0.05s
2018-10-18 05:57:47.944715 7f6c1a100700  0 log_channel(cluster) log [WRN] : mon.2 192.168.136.189:6789/0 clock skew 1167.74s > max 0.05s
2018-10-18 05:57:48.004463 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1108 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 05:58:17.758102 7f6c1a901700  0 mon.ceph-node1@0(leader).data_health(224) update_stats avail 69% total 51175 MB, used 15471 MB, avail 35703 MB
2018-10-18 05:59:17.758614 7f6c1a901700  0 mon.ceph-node1@0(leader).data_health(224) update_stats avail 69% total 51175 MB, used 15471 MB, avail 35703 MB
2018-10-18 06:00:00.000370 7f6c1a901700  0 log_channel(cluster) log [INF] : HEALTH_WARN; clock skew detected on mon.ceph-node2, mon.ceph-node3; 2 requests are blocked > 32 sec; Monitor clock skew detected 
2018-10-18 06:00:00.067882 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1109 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 06:00:05.762335 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1110 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 06:00:07.909530 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1111 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 06:00:17.760027 7f6c1a901700  0 mon.ceph-node1@0(leader).data_health(224) update_stats avail 69% total 51175 MB, used 15440 MB, avail 35734 MB
2018-10-18 06:00:50.954406 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v907: 112 pgs: 112 active+clean; 2549 bytes data, 236 MB used, 398 GB / 399 GB avail
2018-10-18 06:00:51.965315 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1112 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 06:00:51.997390 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v908: 112 pgs: 112 active+clean; 2549 bytes data, 236 MB used, 398 GB / 399 GB avail
2018-10-18 06:00:53.020558 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1113 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2010-10-11 06:20:43.570741 7f6c1a100700  0 log_channel(cluster) log [INF] : mon.ceph-node1 calling new monitor election
2010-10-11 06:20:43.570923 7f6c1a100700  1 mon.ceph-node1@0(electing).elector(225) init, last seen epoch 225
2010-10-11 06:20:43.581171 7f6c1a100700  0 log_channel(cluster) log [INF] : mon.ceph-node1@0 won leader election with quorum 0,1,2
2010-10-11 06:20:43.582507 7f6c1a100700  0 log_channel(cluster) log [INF] : HEALTH_WARN; 2 requests are blocked > 32 sec
2010-10-11 06:20:43.673731 7f6c1a100700  0 log_channel(cluster) log [WRN] : mon.2 192.168.136.189:6789/0 clock skew 2.53066e+08s > max 0.05s
2010-10-11 06:20:43.708120 7f6c1a100700  0 log_channel(cluster) log [INF] : monmap e3: 3 mons at {ceph-node1=192.168.136.187:6789/0,ceph-node2=192.168.136.188:6789/0,ceph-node3=192.168.136.189:6789/0}
2010-10-11 06:20:43.708218 7f6c1a100700  0 log_channel(cluster) log [INF] : pgmap v908: 112 pgs: 112 active+clean; 2549 bytes data, 236 MB used, 398 GB / 399 GB avail
2010-10-11 06:20:43.708271 7f6c1a100700  0 log_channel(cluster) log [INF] : fsmap e1:
2010-10-11 06:20:43.708400 7f6c1a100700  0 log_channel(cluster) log [INF] : osdmap e163: 6 osds: 6 up, 6 in
2010-10-11 06:20:43.716025 7f6c1a100700  0 log_channel(cluster) log [WRN] : mon.1 192.168.136.188:6789/0 clock skew 2.53066e+08s > max 0.05s
2010-10-11 06:20:43.716269 7f6c1a100700  0 log_channel(cluster) log [WRN] : message from mon.2 was stamped 253065605.199194s in the future, clocks not synchronized
2010-10-11 06:20:43.794663 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1114 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2010-10-11 06:20:59.916066 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v909: 112 pgs: 112 active+clean; 2549 bytes data, 236 MB used, 398 GB / 399 GB avail
2010-10-11 06:21:00.922060 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1115 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2010-10-11 06:21:02.614278 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v910: 112 pgs: 112 active+clean; 2549 bytes data, 236 MB used, 398 GB / 399 GB avail
2010-10-11 06:21:03.629204 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1116 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2010-10-11 06:21:03.638434 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v911: 112 pgs: 112 active+clean; 2549 bytes data, 236 MB used, 398 GB / 399 GB avail
2010-10-11 06:21:04.651727 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1117 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2010-10-11 06:21:04.666610 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v912: 112 pgs: 112 active+clean; 2549 bytes data, 236 MB used, 398 GB / 399 GB avail
2010-10-11 06:21:05.673167 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1118 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2010-10-11 06:21:07.617491 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v913: 112 pgs: 112 active+clean; 2549 bytes data, 236 MB used, 398 GB / 399 GB avail
2010-10-11 06:21:08.632768 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1119 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2010-10-11 06:21:08.648698 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v914: 112 pgs: 112 active+clean; 2549 bytes data, 236 MB used, 398 GB / 399 GB avail
2010-10-11 06:21:09.671191 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1120 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2010-10-11 06:21:09.692894 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v915: 112 pgs: 112 active+clean; 2549 bytes data, 236 MB used, 398 GB / 399 GB avail
2010-10-11 06:21:10.708411 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1121 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2010-10-11 06:21:13.717273 7f6c1a100700  0 log_channel(cluster) log [WRN] : mon.1 192.168.136.188:6789/0 clock skew 2.53066e+08s > max 0.05s
2010-10-11 06:21:13.718265 7f6c1a100700  0 log_channel(cluster) log [WRN] : mon.2 192.168.136.189:6789/0 clock skew 2.53066e+08s > max 0.05s
2010-10-11 06:21:13.780713 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1122 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2010-10-11 06:21:17.640454 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v916: 112 pgs: 112 active+clean; 2549 bytes data, 236 MB used, 398 GB / 399 GB avail; 4781 B/s rd, 5 op/s
2010-10-11 06:21:18.679044 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1123 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2010-10-11 06:21:18.691004 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v917: 112 pgs: 112 active+clean; 2549 bytes data, 236 MB used, 398 GB / 399 GB avail; 12983 B/s rd, 17 op/s
2010-10-11 06:21:19.701060 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1124 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2010-10-11 06:21:19.710361 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v918: 112 pgs: 112 active+clean; 2549 bytes data, 236 MB used, 398 GB / 399 GB avail; 57140 B/s rd, 83 op/s
2010-10-11 06:21:20.715227 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1125 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2010-10-11 06:21:22.635291 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v919: 112 pgs: 112 active+clean; 2549 bytes data, 236 MB used, 398 GB / 399 GB avail; 11364 B/s rd, 16 op/s
2010-10-11 06:21:23.654134 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1126 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2010-10-11 06:21:23.674260 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v920: 112 pgs: 112 active+clean; 2549 bytes data, 236 MB used, 398 GB / 399 GB avail
2010-10-11 06:21:24.687889 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1127 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2010-10-11 06:21:24.701777 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v921: 112 pgs: 112 active+clean; 2549 bytes data, 236 MB used, 398 GB / 399 GB avail
2010-10-11 06:21:25.718409 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1128 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2010-10-11 06:21:29.685334 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v922: 112 pgs: 112 active+clean; 2549 bytes data, 236 MB used, 398 GB / 399 GB avail
2010-10-11 06:21:30.697622 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1129 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2010-10-11 06:21:32.628047 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v923: 112 pgs: 112 active+clean; 2549 bytes data, 236 MB used, 398 GB / 399 GB avail
2010-10-11 06:21:33.660515 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1130 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2010-10-11 06:21:33.683896 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v924: 112 pgs: 112 active+clean; 2549 bytes data, 236 MB used, 398 GB / 399 GB avail
2010-10-11 06:21:34.702685 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1131 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2010-10-11 06:21:34.720577 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v925: 112 pgs: 112 active+clean; 2549 bytes data, 236 MB used, 398 GB / 399 GB avail
2010-10-11 06:21:35.732313 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1132 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2010-10-11 06:21:37.630034 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v926: 112 pgs: 112 active+clean; 2549 bytes data, 236 MB used, 398 GB / 399 GB avail
2010-10-11 06:21:38.654255 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1133 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2010-10-11 06:21:38.683969 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v927: 112 pgs: 112 active+clean; 2549 bytes data, 236 MB used, 398 GB / 399 GB avail
2010-10-11 06:21:39.695705 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1134 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2010-10-11 06:21:39.720122 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v928: 112 pgs: 112 active+clean; 2549 bytes data, 236 MB used, 398 GB / 399 GB avail
2010-10-11 06:21:40.740381 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1135 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2010-10-11 06:21:42.675776 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v929: 112 pgs: 112 active+clean; 2549 bytes data, 236 MB used, 398 GB / 399 GB avail; 3080 B/s rd, 3 op/s
2010-10-11 06:21:43.582697 7f6c1a901700  0 log_channel(cluster) log [INF] : HEALTH_WARN; clock skew detected on mon.ceph-node2, mon.ceph-node3; 2 requests are blocked > 32 sec; Monitor clock skew detected 
2010-10-11 06:21:43.684103 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1136 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2010-10-11 06:21:43.696379 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v930: 112 pgs: 112 active+clean; 2549 bytes data, 236 MB used, 398 GB / 399 GB avail; 6154 B/s rd, 8 op/s
2010-10-11 06:21:44.709432 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1137 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2010-10-11 06:21:44.772062 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v931: 112 pgs: 112 active+clean; 2549 bytes data, 236 MB used, 398 GB / 399 GB avail; 9873 B/s rd, 14 op/s
2010-10-11 06:21:45.786202 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1138 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2010-10-11 06:21:47.638739 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v932: 112 pgs: 112 active+clean; 2549 bytes data, 236 MB used, 398 GB / 399 GB avail; 2074 B/s rd, 3 op/s
2010-10-11 06:21:48.654559 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1139 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2010-10-11 06:21:48.662515 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v933: 112 pgs: 112 active+clean; 2549 bytes data, 236 MB used, 398 GB / 399 GB avail
2010-10-11 06:21:49.671859 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1140 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2010-10-11 06:21:49.685790 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v934: 112 pgs: 112 active+clean; 2549 bytes data, 236 MB used, 398 GB / 399 GB avail
2010-10-11 06:21:50.701385 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1141 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2010-10-11 06:21:52.643278 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v935: 112 pgs: 112 active+clean; 2549 bytes data, 236 MB used, 398 GB / 399 GB avail
2010-10-11 06:21:53.664775 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1142 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2010-10-11 06:21:59.709644 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v936: 112 pgs: 112 active+clean; 2549 bytes data, 236 MB used, 398 GB / 399 GB avail
2010-10-11 06:22:00.733865 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1143 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2010-10-11 06:22:02.662726 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v937: 112 pgs: 112 active+clean; 2549 bytes data, 236 MB used, 398 GB / 399 GB avail
2010-10-11 06:22:03.672280 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1144 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2010-10-11 06:22:03.688680 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v938: 112 pgs: 112 active+clean; 2549 bytes data, 236 MB used, 398 GB / 399 GB avail
2010-10-11 06:22:04.721175 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1145 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2010-10-11 06:22:04.737939 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v939: 112 pgs: 112 active+clean; 2549 bytes data, 236 MB used, 398 GB / 399 GB avail
2010-10-11 06:22:05.743851 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1146 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2010-10-11 06:22:07.675538 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v940: 112 pgs: 112 active+clean; 2549 bytes data, 236 MB used, 398 GB / 399 GB avail
2010-10-11 06:22:08.696804 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1147 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2010-10-11 06:22:08.716269 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v941: 112 pgs: 112 active+clean; 2549 bytes data, 236 MB used, 398 GB / 399 GB avail
2010-10-11 06:22:09.733101 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1148 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2010-10-11 06:22:09.742832 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v942: 112 pgs: 112 active+clean; 2549 bytes data, 236 MB used, 398 GB / 399 GB avail
2010-10-11 06:22:10.773638 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1149 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2010-10-11 06:22:13.720024 7f6c1a100700  0 log_channel(cluster) log [WRN] : mon.1 192.168.136.188:6789/0 clock skew 2.53066e+08s > max 0.05s
2010-10-11 06:22:13.720164 7f6c1a100700  0 log_channel(cluster) log [WRN] : mon.2 192.168.136.189:6789/0 clock skew 2.53066e+08s > max 0.05s
2010-10-11 06:22:13.787691 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1150 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2010-10-11 06:22:29.722005 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v943: 112 pgs: 112 active+clean; 2549 bytes data, 236 MB used, 398 GB / 399 GB avail
2010-10-11 06:22:30.756500 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1151 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2010-10-11 06:22:32.658278 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v944: 112 pgs: 112 active+clean; 2549 bytes data, 237 MB used, 398 GB / 399 GB avail
2010-10-11 06:22:33.670198 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1152 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2010-10-11 06:22:33.685708 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v945: 112 pgs: 112 active+clean; 2549 bytes data, 237 MB used, 398 GB / 399 GB avail
2010-10-11 06:22:34.712209 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1153 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2010-10-11 06:22:34.737498 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v946: 112 pgs: 112 active+clean; 2549 bytes data, 237 MB used, 398 GB / 399 GB avail
2010-10-11 06:22:35.758207 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1154 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 06:22:34.005987 7f6c1a901700  0 log_channel(cluster) log [INF] : HEALTH_WARN; clock skew detected on mon.ceph-node2, mon.ceph-node3; 2 requests are blocked > 32 sec; Monitor clock skew detected 
2018-10-18 06:22:34.007531 7f6c1a901700  0 log_channel(cluster) log [INF] : osd.1 marked down after no pg stats for 253065601.414482seconds
2018-10-18 06:22:34.007651 7f6c1a901700 -1 mon.ceph-node1@0(leader).osd e163 no osd or pg stats from osd.1 since 2010-10-11 06:22:32.593029, 253065601.414482 seconds ago.  marking down
2018-10-18 06:22:34.007667 7f6c1a901700  0 log_channel(cluster) log [INF] : osd.2 marked down after no pg stats for 253065599.786187seconds
2018-10-18 06:22:34.007823 7f6c1a901700 -1 mon.ceph-node1@0(leader).osd e163 no osd or pg stats from osd.2 since 2010-10-11 06:22:34.221324, 253065599.786187 seconds ago.  marking down
2018-10-18 06:22:34.007835 7f6c1a901700  0 log_channel(cluster) log [INF] : osd.4 marked down after no pg stats for 253065600.869419seconds
2018-10-18 06:22:34.007870 7f6c1a901700 -1 mon.ceph-node1@0(leader).osd e163 no osd or pg stats from osd.4 since 2010-10-11 06:22:33.138092, 253065600.869419 seconds ago.  marking down
2018-10-18 06:22:34.007877 7f6c1a901700  0 log_channel(cluster) log [INF] : osd.5 marked down after no pg stats for 253065599.350987seconds
2018-10-18 06:22:34.007909 7f6c1a901700 -1 mon.ceph-node1@0(leader).osd e163 no osd or pg stats from osd.5 since 2010-10-11 06:22:34.656524, 253065599.350987 seconds ago.  marking down
2018-10-18 06:22:34.019746 7f6c1a901700  0 mon.ceph-node1@0(leader).data_health(226) update_stats avail 69% total 51175 MB, used 15443 MB, avail 35731 MB
2018-10-18 06:22:34.020493 7f6c1a100700  0 log_channel(cluster) log [WRN] : message from mon.1 was stamped 0.715195s in the future, clocks not synchronized
2018-10-18 06:22:34.020823 7f6c1a100700  0 log_channel(cluster) log [WRN] : mon.2 192.168.136.189:6789/0 clock skew 7.50588s > max 0.05s
2018-10-18 06:22:34.035515 7f6c1a100700  0 log_channel(cluster) log [WRN] : mon.1 192.168.136.188:6789/0 clock skew 0.69593s > max 0.05s
2018-10-18 06:22:34.041960 7f6c1a100700  0 log_channel(cluster) log [INF] : scrub ok on 0,1,2: ScrubResult(keys {auth=68,logm=32} crc {auth=3899273675,logm=1069518884})
2018-10-18 06:22:34.046263 7f6c1c2d1700  1 mon.ceph-node1@0(leader).osd e164 e164: 6 osds: 2 up, 6 in
2018-10-18 06:22:34.048235 7f6c1c2d1700  0 log_channel(cluster) log [INF] : osdmap e164: 6 osds: 2 up, 6 in
2018-10-18 06:22:34.048748 7f6c1a100700  0 log_channel(cluster) log [INF] : scrub ok on 0,1,2: ScrubResult(keys {logm=100} crc {logm=149360053})
2018-10-18 06:22:34.058856 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v947: 112 pgs: 112 active+clean; 2549 bytes data, 237 MB used, 398 GB / 399 GB avail
2018-10-18 06:22:34.064485 7f6c1a100700  0 log_channel(cluster) log [INF] : scrub ok on 0,1,2: ScrubResult(keys {logm=100} crc {logm=2879860303})
2018-10-18 06:22:34.073154 7f6c1a100700  0 log_channel(cluster) log [INF] : scrub ok on 0,1,2: ScrubResult(keys {logm=100} crc {logm=4090605401})
2018-10-18 06:22:34.079417 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1155 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 06:22:34.080594 7f6c1a100700  0 log_channel(cluster) log [INF] : scrub ok on 0,1,2: ScrubResult(keys {logm=100} crc {logm=225247249})
2018-10-18 06:22:34.085444 7f6c1a100700  1 mon.ceph-node1@0(leader).osd e164 prepare_failure osd.0 192.168.136.187:6800/21887 from osd.3 192.168.136.187:6804/26198 is reporting failure:1
2018-10-18 06:22:34.085460 7f6c1a100700  0 log_channel(cluster) log [DBG] : osd.0 192.168.136.187:6800/21887 reported failed by osd.3 192.168.136.187:6804/26198
2018-10-18 06:22:34.087564 7f6c1a100700  0 log_channel(cluster) log [INF] : scrub ok on 0,1,2: ScrubResult(keys {logm=100} crc {logm=1217363744})
2018-10-18 06:22:34.089128 7f6c1a100700  1 mon.ceph-node1@0(leader).osd e164 prepare_failure osd.3 192.168.136.187:6804/26198 from osd.0 192.168.136.187:6800/21887 is reporting failure:1
2018-10-18 06:22:34.089140 7f6c1a100700  0 log_channel(cluster) log [DBG] : osd.3 192.168.136.187:6804/26198 reported failed by osd.0 192.168.136.187:6800/21887
2018-10-18 06:22:34.090078 7f6c1a100700  1 mon.ceph-node1@0(leader).osd e164 prepare_failure osd.3 192.168.136.187:6804/26198 from osd.0 192.168.136.187:6800/21887 is reporting failure:1
2018-10-18 06:22:34.090096 7f6c1a100700  0 log_channel(cluster) log [DBG] : osd.3 192.168.136.187:6804/26198 reported failed by osd.0 192.168.136.187:6800/21887
2018-10-18 06:22:34.093765 7f6c1a100700  0 log_channel(cluster) log [INF] : scrub ok on 0,1,2: ScrubResult(keys {logm=100} crc {logm=1190536712})
2018-10-18 06:22:34.100930 7f6c1a100700  0 log_channel(cluster) log [INF] : scrub ok on 0,1,2: ScrubResult(keys {logm=100} crc {logm=353867607})
2018-10-18 06:22:34.108232 7f6c1a100700  0 log_channel(cluster) log [INF] : scrub ok on 0,1,2: ScrubResult(keys {logm=100} crc {logm=525884988})
2018-10-18 06:22:34.115413 7f6c1a100700  0 log_channel(cluster) log [INF] : scrub ok on 0,1,2: ScrubResult(keys {logm=100} crc {logm=982097786})
2018-10-18 06:22:34.124119 7f6c1a100700  0 log_channel(cluster) log [INF] : scrub ok on 0,1,2: ScrubResult(keys {logm=100} crc {logm=1406689225})
2018-10-18 06:22:34.129873 7f6c1a100700  0 log_channel(cluster) log [INF] : scrub ok on 0,1,2: ScrubResult(keys {logm=100} crc {logm=39012161})
2018-10-18 06:22:34.139726 7f6c1a100700  0 log_channel(cluster) log [INF] : scrub ok on 0,1,2: ScrubResult(keys {logm=100} crc {logm=2336802274})
2018-10-18 06:22:34.147811 7f6c1a100700  0 log_channel(cluster) log [INF] : scrub ok on 0,1,2: ScrubResult(keys {logm=78,mdsmap=3,monmap=5,osdmap=14} crc {logm=1970943519,mdsmap=4078752127,monmap=2053587612,osdmap=3955884309})
2018-10-18 06:22:34.152177 7f6c1a100700  0 log_channel(cluster) log [INF] : scrub ok on 0,1,2: ScrubResult(keys {osdmap=100} crc {osdmap=729843007})
2018-10-18 06:22:34.154739 7f6c1a100700  0 log_channel(cluster) log [INF] : scrub ok on 0,1,2: ScrubResult(keys {osdmap=100} crc {osdmap=1597680919})
2018-10-18 06:22:34.157735 7f6c1a100700  0 log_channel(cluster) log [INF] : scrub ok on 0,1,2: ScrubResult(keys {osdmap=100} crc {osdmap=3360451690})
2018-10-18 06:22:34.161467 7f6c1a100700  0 log_channel(cluster) log [INF] : scrub ok on 0,1,2: ScrubResult(keys {osdmap=17,pgmap=83} crc {osdmap=3999316477,pgmap=2165515522})
2018-10-18 06:22:34.166452 7f6c1a100700  0 log_channel(cluster) log [INF] : scrub ok on 0,1,2: ScrubResult(keys {pgmap=100} crc {pgmap=4257875460})
2018-10-18 06:22:34.168581 7f6c1a100700  0 log_channel(cluster) log [INF] : scrub ok on 0,1,2: ScrubResult(keys {pgmap=100} crc {pgmap=1158462451})
2018-10-18 06:22:34.170254 7f6c1a100700  0 log_channel(cluster) log [INF] : scrub ok on 0,1,2: ScrubResult(keys {pgmap=100} crc {pgmap=1207401955})
2018-10-18 06:22:34.172235 7f6c1a100700  0 log_channel(cluster) log [INF] : scrub ok on 0,1,2: ScrubResult(keys {pgmap=100} crc {pgmap=1330829389})
2018-10-18 06:22:34.177408 7f6c1a100700  0 log_channel(cluster) log [INF] : scrub ok on 0,1,2: ScrubResult(keys {pgmap=100} crc {pgmap=989312530})
2018-10-18 06:22:34.181561 7f6c1a100700  0 log_channel(cluster) log [INF] : scrub ok on 0,1,2: ScrubResult(keys {pgmap=100} crc {pgmap=2670639064})
2018-10-18 06:22:34.184826 7f6c1a100700  0 log_channel(cluster) log [INF] : scrub ok on 0,1,2: ScrubResult(keys {pgmap=15,pgmap_meta=6,pgmap_osd=6,pgmap_pg=73} crc {pgmap=201793700,pgmap_meta=851033900,pgmap_osd=4154891056,pgmap_pg=1215916922})
2018-10-18 06:22:34.187032 7f6c1a100700  0 log_channel(cluster) log [INF] : scrub ok on 0,1,2: ScrubResult(keys {pgmap_pg=39} crc {pgmap_pg=2172790972})
2018-10-18 06:22:35.086708 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v948: 112 pgs: 112 active+clean; 2549 bytes data, 237 MB used, 398 GB / 399 GB avail; 0 B/s rd, 0 op/s
2018-10-18 06:22:35.098906 7f6c1c2d1700  1 mon.ceph-node1@0(leader).osd e165 e165: 6 osds: 3 up, 6 in
2018-10-18 06:22:35.099757 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1156 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 06:22:35.100505 7f6c1c2d1700  0 log_channel(cluster) log [INF] : osd.4 192.168.136.188:6801/8867 boot
2018-10-18 06:22:35.102829 7f6c1c2d1700  0 log_channel(cluster) log [INF] : osdmap e165: 6 osds: 3 up, 6 in
2018-10-18 06:22:35.121566 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v949: 112 pgs: 75 stale+active+clean, 37 active+clean; 2549 bytes data, 237 MB used, 398 GB / 399 GB avail; 31105 B/s rd, 45 op/s
2018-10-18 06:22:36.111724 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1157 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 06:22:36.128836 7f6c1c2d1700  1 mon.ceph-node1@0(leader).osd e166 e166: 6 osds: 3 up, 6 in
2018-10-18 06:22:36.131288 7f6c1c2d1700  0 log_channel(cluster) log [INF] : osdmap e166: 6 osds: 3 up, 6 in
2018-10-18 06:22:36.138116 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v950: 112 pgs: 75 stale+active+clean, 37 active+clean; 2549 bytes data, 237 MB used, 398 GB / 399 GB avail
2018-10-18 06:22:37.144241 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1158 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 06:22:37.175176 7f6c1c2d1700  1 mon.ceph-node1@0(leader).osd e167 e167: 6 osds: 4 up, 6 in
2018-10-18 06:22:37.176392 7f6c1c2d1700  0 log_channel(cluster) log [INF] : osd.5 192.168.136.189:6804/14124 boot
2018-10-18 06:22:37.178428 7f6c1c2d1700  0 log_channel(cluster) log [INF] : osdmap e167: 6 osds: 4 up, 6 in
2018-10-18 06:22:37.203777 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v951: 112 pgs: 75 stale+active+clean, 37 active+clean; 2549 bytes data, 237 MB used, 398 GB / 399 GB avail
2018-10-18 06:22:38.231049 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1159 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 06:22:38.303632 7f6c1c2d1700  1 mon.ceph-node1@0(leader).osd e168 e168: 6 osds: 4 up, 6 in
2018-10-18 06:22:38.309217 7f6c1c2d1700  0 log_channel(cluster) log [INF] : osdmap e168: 6 osds: 4 up, 6 in
2018-10-18 06:22:38.328308 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v952: 112 pgs: 75 stale+active+clean, 37 active+clean; 2549 bytes data, 237 MB used, 398 GB / 399 GB avail
2018-10-18 06:22:39.271829 7f6c1a100700  1 mon.ceph-node1@0(leader).pg v952  ignoring stats from non-active osd.
2018-10-18 06:22:39.309922 7f6c1a100700  1 mon.ceph-node1@0(leader).osd e168 prepare_failure osd.0 192.168.136.187:6800/21887 from osd.3 192.168.136.187:6804/26198 is reporting failure:0
2018-10-18 06:22:39.310010 7f6c1a100700  0 log_channel(cluster) log [DBG] : osd.0 192.168.136.187:6800/21887 failure report canceled by osd.3 192.168.136.187:6804/26198
2018-10-18 06:22:39.317849 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1160 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 06:22:39.913053 7f6c1a100700  1 mon.ceph-node1@0(leader).osd e168 prepare_failure osd.3 192.168.136.187:6804/26198 from osd.0 192.168.136.187:6800/21887 is reporting failure:0
2018-10-18 06:22:39.913074 7f6c1a100700  0 log_channel(cluster) log [DBG] : osd.3 192.168.136.187:6804/26198 failure report canceled by osd.0 192.168.136.187:6800/21887
2018-10-18 06:22:40.439063 7f6c1c2d1700  1 mon.ceph-node1@0(leader).osd e169 e169: 6 osds: 6 up, 6 in
2018-10-18 06:22:40.445991 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v953: 112 pgs: 27 undersized+degraded+peered, 57 active+undersized+degraded, 28 active+clean; 2549 bytes data, 238 MB used, 398 GB / 399 GB avail; 0 B/s wr, 2 op/s; 178/651 objects degraded (27.343%); 0 B/s, 0 objects/s recovering
2018-10-18 06:22:40.446422 7f6c1c2d1700  0 log_channel(cluster) log [INF] : osd.1 192.168.136.188:6800/2838 boot
2018-10-18 06:22:40.446551 7f6c1c2d1700  0 log_channel(cluster) log [INF] : osd.2 192.168.136.189:6800/8942 boot
2018-10-18 06:22:40.446642 7f6c1c2d1700  0 log_channel(cluster) log [INF] : osdmap e169: 6 osds: 6 up, 6 in
2018-10-18 06:22:40.457483 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v954: 112 pgs: 27 undersized+degraded+peered, 57 active+undersized+degraded, 28 active+clean; 2549 bytes data, 238 MB used, 398 GB / 399 GB avail; 0 B/s wr, 3 op/s; 178/651 objects degraded (27.343%); 0 B/s, 0 objects/s recovering
2018-10-18 06:22:41.477004 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1162 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 06:22:41.503974 7f6c1c2d1700  1 mon.ceph-node1@0(leader).osd e170 e170: 6 osds: 6 up, 6 in
2018-10-18 06:22:41.506003 7f6c1c2d1700  0 log_channel(cluster) log [INF] : osdmap e170: 6 osds: 6 up, 6 in
2018-10-18 06:22:41.508461 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v955: 112 pgs: 15 peering, 19 undersized+degraded+peered, 50 active+undersized+degraded, 28 active+clean; 2549 bytes data, 239 MB used, 398 GB / 399 GB avail; 8648 B/s rd, 7 op/s; 111/651 objects degraded (17.051%)
2018-10-18 06:22:41.583058 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v956: 112 pgs: 15 peering, 19 undersized+degraded+peered, 50 active+undersized+degraded, 28 active+clean; 2549 bytes data, 239 MB used, 398 GB / 399 GB avail; 8680 B/s rd, 7 op/s; 111/651 objects degraded (17.051%)
2018-10-18 06:22:42.515222 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1163 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 06:22:44.348445 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v957: 112 pgs: 15 peering, 9 undersized+degraded+peered, 40 active+undersized+degraded, 48 active+clean; 2549 bytes data, 239 MB used, 398 GB / 399 GB avail; 22492 B/s rd, 0 B/s wr, 36 op/s; 77/651 objects degraded (11.828%); 351 B/s, 0 objects/s recovering
2018-10-18 06:22:45.375907 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1164 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 06:22:45.412897 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v958: 112 pgs: 15 peering, 97 active+clean; 2549 bytes data, 241 MB used, 398 GB / 399 GB avail; 83918 B/s rd, 0 B/s wr, 136 op/s; 262 B/s, 1 objects/s recovering
2018-10-18 06:22:46.432129 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v959: 112 pgs: 112 active+clean; 2549 bytes data, 242 MB used, 398 GB / 399 GB avail; 146 kB/s rd, 0 B/s wr, 244 op/s; 0 B/s, 0 objects/s recovering
2018-10-18 06:22:46.456762 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1165 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 06:22:47.471072 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1166 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 06:22:48.496386 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1167 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 06:22:49.508706 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v960: 112 pgs: 112 active+clean; 2549 bytes data, 242 MB used, 398 GB / 399 GB avail; 13337 B/s rd, 0 B/s wr, 21 op/s
2018-10-18 06:22:50.516066 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1168 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 06:22:50.528882 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v961: 112 pgs: 112 active+clean; 2549 bytes data, 242 MB used, 398 GB / 399 GB avail
2018-10-18 06:22:51.550058 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1169 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 06:22:51.563518 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v962: 112 pgs: 112 active+clean; 2549 bytes data, 242 MB used, 398 GB / 399 GB avail
2018-10-18 06:22:52.586952 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1170 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 06:22:54.345803 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v963: 112 pgs: 112 active+clean; 2549 bytes data, 242 MB used, 398 GB / 399 GB avail
2018-10-18 06:22:55.359711 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1171 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 06:22:55.399427 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v964: 112 pgs: 112 active+clean; 2549 bytes data, 242 MB used, 398 GB / 399 GB avail; 4562 B/s rd, 268 B/s wr, 7 op/s
2018-10-18 06:22:56.416971 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1172 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 06:22:56.430298 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v965: 112 pgs: 112 active+clean; 2549 bytes data, 242 MB used, 398 GB / 399 GB avail; 8382 B/s rd, 493 B/s wr, 13 op/s
2018-10-18 06:22:57.447490 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1173 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 06:22:59.339737 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v966: 112 pgs: 112 active+clean; 2549 bytes data, 242 MB used, 398 GB / 399 GB avail
2018-10-18 06:23:00.362052 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1174 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 06:23:00.383547 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v967: 112 pgs: 112 active+clean; 2549 bytes data, 242 MB used, 398 GB / 399 GB avail
2018-10-18 06:23:01.393347 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1175 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 06:23:34.006339 7f6c1a901700  0 log_channel(cluster) log [INF] : HEALTH_WARN; clock skew detected on mon.ceph-node2, mon.ceph-node3; Monitor clock skew detected 
2018-10-18 06:23:34.020522 7f6c1a901700  0 mon.ceph-node1@0(leader).data_health(226) update_stats avail 69% total 51175 MB, used 15445 MB, avail 35729 MB
2018-10-18 06:23:34.068150 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1176 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 06:23:39.362645 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v968: 112 pgs: 112 active+clean; 2549 bytes data, 242 MB used, 398 GB / 399 GB avail
2018-10-18 06:23:40.373197 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1177 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 06:23:40.397836 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v969: 112 pgs: 112 active+clean; 9169 bytes data, 242 MB used, 398 GB / 399 GB avail; 1330 B/s rd, 179 B/s wr, 2 op/s
2018-10-18 06:23:41.412218 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1178 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 06:23:41.419025 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v970: 112 pgs: 112 active+clean; 16897 bytes data, 242 MB used, 398 GB / 399 GB avail; 26511 B/s rd, 7503 B/s wr, 63 op/s
2018-10-18 06:23:42.431871 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1179 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 06:23:44.372496 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v971: 112 pgs: 112 active+clean; 19657 bytes data, 242 MB used, 398 GB / 399 GB avail; 256 B/s rd, 2818 B/s wr, 7 op/s
2018-10-18 06:23:45.391026 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1180 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 06:23:45.405957 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v972: 112 pgs: 112 active+clean; 38557 bytes data, 242 MB used, 398 GB / 399 GB avail; 10552 B/s rd, 6434 B/s wr, 33 op/s
2018-10-18 06:23:46.418579 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1181 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 06:23:46.437384 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v973: 112 pgs: 112 active+clean; 38557 bytes data, 242 MB used, 398 GB / 399 GB avail; 20522 B/s rd, 11012 B/s wr, 61 op/s
2018-10-18 06:23:47.463975 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1182 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 06:23:49.382098 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v974: 112 pgs: 112 active+clean; 38557 bytes data, 242 MB used, 398 GB / 399 GB avail
2018-10-18 06:23:50.391042 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v975: 112 pgs: 112 active+clean; 38557 bytes data, 242 MB used, 398 GB / 399 GB avail
2018-10-18 06:23:50.404108 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1183 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 06:23:51.432936 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1184 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 06:23:51.450489 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v976: 112 pgs: 112 active+clean; 38557 bytes data, 242 MB used, 398 GB / 399 GB avail
2018-10-18 06:23:52.457917 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1185 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 06:23:56.057640 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v977: 112 pgs: 112 active+clean; 30829 bytes data, 242 MB used, 398 GB / 399 GB avail; 3072 B/s rd, 0 B/s wr, 3 op/s
2018-10-18 06:23:57.072916 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1186 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 06:23:59.374071 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v978: 112 pgs: 112 active+clean; 28069 bytes data, 242 MB used, 398 GB / 399 GB avail; 3216 B/s rd, 0 B/s wr, 3 op/s
2018-10-18 06:24:00.409184 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1187 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 06:24:00.432083 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v979: 112 pgs: 112 active+clean; 2549 bytes data, 242 MB used, 398 GB / 399 GB avail; 27407 B/s rd, 0 B/s wr, 41 op/s
2018-10-18 06:24:01.446485 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v980: 112 pgs: 112 active+clean; 2549 bytes data, 242 MB used, 398 GB / 399 GB avail; 53551 B/s rd, 0 B/s wr, 81 op/s
2018-10-18 06:24:01.470078 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1188 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 06:24:02.488302 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1189 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 06:24:04.383119 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v981: 112 pgs: 112 active+clean; 2549 bytes data, 242 MB used, 398 GB / 399 GB avail
2018-10-18 06:24:05.394352 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v982: 112 pgs: 112 active+clean; 2549 bytes data, 242 MB used, 398 GB / 399 GB avail
2018-10-18 06:24:05.410020 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1190 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 06:24:06.421915 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1191 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 06:24:06.441964 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v983: 112 pgs: 112 active+clean; 2549 bytes data, 242 MB used, 398 GB / 399 GB avail
2018-10-18 06:24:07.470536 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1192 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 06:24:19.386852 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v984: 112 pgs: 112 active+clean; 2549 bytes data, 242 MB used, 398 GB / 399 GB avail
2018-10-18 06:24:20.397731 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1193 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 06:24:20.404523 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v985: 112 pgs: 112 active+clean; 2549 bytes data, 242 MB used, 398 GB / 399 GB avail; 512 B/s rd, 0 B/s wr, 1 op/s
2018-10-18 06:24:21.423654 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1194 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 06:24:24.401260 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v986: 112 pgs: 112 active+clean; 2549 bytes data, 242 MB used, 398 GB / 399 GB avail; 1431 B/s rd, 0 B/s wr, 4 op/s
2018-10-18 06:24:25.431823 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1195 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 06:24:25.448324 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v987: 112 pgs: 112 active+clean; 2549 bytes data, 242 MB used, 398 GB / 399 GB avail; 1429 B/s rd, 0 B/s wr, 4 op/s
2018-10-18 06:24:26.460229 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1196 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 06:24:29.386199 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v988: 112 pgs: 112 active+clean; 2549 bytes data, 242 MB used, 398 GB / 399 GB avail; 1433 B/s rd, 0 B/s wr, 4 op/s
2018-10-18 06:24:30.408297 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1197 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 06:24:30.424649 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v989: 112 pgs: 112 active+clean; 2549 bytes data, 242 MB used, 398 GB / 399 GB avail
2018-10-18 06:24:31.436001 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1198 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 06:24:34.021001 7f6c1a901700  0 mon.ceph-node1@0(leader).data_health(226) update_stats avail 69% total 51175 MB, used 15445 MB, avail 35729 MB
2018-10-18 06:24:34.039826 7f6c1a100700  0 log_channel(cluster) log [WRN] : mon.2 192.168.136.189:6789/0 clock skew 7.52631s > max 0.05s
2018-10-18 06:24:34.040321 7f6c1a100700  0 log_channel(cluster) log [WRN] : mon.1 192.168.136.188:6789/0 clock skew 0.723332s > max 0.05s
2018-10-18 06:24:34.100879 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1199 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 06:24:39.392722 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v990: 112 pgs: 112 active+clean; 6585 bytes data, 242 MB used, 398 GB / 399 GB avail; 409 B/s wr, 0 op/s
2018-10-18 06:24:40.463906 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1200 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 06:24:40.498629 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v991: 112 pgs: 112 active+clean; 50462 bytes data, 242 MB used, 398 GB / 399 GB avail; 5321 B/s rd, 5321 B/s wr, 20 op/s
2018-10-18 06:24:41.516655 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1201 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 06:24:41.550141 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v992: 112 pgs: 112 active+clean; 55266 bytes data, 242 MB used, 398 GB / 399 GB avail; 25165 B/s rd, 25649 B/s wr, 95 op/s
2018-10-18 06:24:42.568583 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1202 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 06:24:44.399753 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v993: 112 pgs: 112 active+clean; 55266 bytes data, 242 MB used, 398 GB / 399 GB avail; 1281 B/s wr, 2 op/s
2018-10-18 06:24:45.416315 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v994: 112 pgs: 112 active+clean; 55266 bytes data, 243 MB used, 398 GB / 399 GB avail
2018-10-18 06:24:45.440629 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1203 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 06:24:46.455727 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1204 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 06:24:49.398398 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v995: 112 pgs: 112 active+clean; 55266 bytes data, 242 MB used, 398 GB / 399 GB avail
2018-10-18 06:24:50.410825 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1205 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 06:24:50.419391 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v996: 112 pgs: 112 active+clean; 55266 bytes data, 242 MB used, 398 GB / 399 GB avail
2018-10-18 06:24:51.432605 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1206 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 06:25:04.406809 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v997: 112 pgs: 112 active+clean; 51230 bytes data, 242 MB used, 398 GB / 399 GB avail; 613 B/s rd, 0 B/s wr, 0 op/s
2018-10-18 06:25:05.435257 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1207 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 06:25:05.454808 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v998: 112 pgs: 112 active+clean; 12152 bytes data, 242 MB used, 398 GB / 399 GB avail; 9274 B/s rd, 0 B/s wr, 11 op/s
2018-10-18 06:25:06.486551 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1208 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 06:25:06.499380 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v999: 112 pgs: 112 active+clean; 7348 bytes data, 242 MB used, 398 GB / 399 GB avail; 67905 B/s rd, 0 B/s wr, 86 op/s
2018-10-18 06:25:07.516705 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1209 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 06:25:09.410201 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v1000: 112 pgs: 112 active+clean; 7348 bytes data, 242 MB used, 398 GB / 399 GB avail; 2570 B/s rd, 0 B/s wr, 2 op/s
2018-10-18 06:25:10.705355 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1210 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 06:25:10.737351 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v1001: 112 pgs: 112 active+clean; 2549 bytes data, 242 MB used, 398 GB / 399 GB avail; 3890 B/s rd, 0 B/s wr, 5 op/s
2018-10-18 06:25:11.749164 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1211 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 06:25:11.756019 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v1002: 112 pgs: 112 active+clean; 2549 bytes data, 242 MB used, 398 GB / 399 GB avail; 6563 B/s rd, 0 B/s wr, 8 op/s
2018-10-18 06:25:12.773129 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1212 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 06:25:14.406467 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v1003: 112 pgs: 112 active+clean; 2549 bytes data, 242 MB used, 398 GB / 399 GB avail
2018-10-18 06:25:15.413499 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1213 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 06:25:15.437835 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v1004: 112 pgs: 112 active+clean; 2549 bytes data, 242 MB used, 398 GB / 399 GB avail
2018-10-18 06:25:16.448425 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1214 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 06:25:19.047889 7f6c16313700  1 leveldb: Level-0 table #205: started
2018-10-18 06:25:19.075265 7f6c16313700  1 leveldb: Level-0 table #205: 4533241 bytes OK
2018-10-18 06:25:19.077334 7f6c16313700  1 leveldb: Delete type=0 #198

2018-10-18 06:25:19.079515 7f6c16313700  1 leveldb: Manual compaction at level-0 from 'pgmap\x00252' @ 72057594037927935 : 1 .. 'pgmap\x00504' @ 0 : 0; will stop at 'pgmap_pg\x006.7' @ 34050 : 1

2018-10-18 06:25:19.079542 7f6c16313700  1 leveldb: Compacting 1@0 + 4@1 files
2018-10-18 06:25:19.093842 7f6c16313700  1 leveldb: Generated table #206: 358 keys, 2158581 bytes
2018-10-18 06:25:19.109022 7f6c16313700  1 leveldb: Generated table #207: 335 keys, 2118453 bytes
2018-10-18 06:25:19.122659 7f6c16313700  1 leveldb: Generated table #208: 305 keys, 2117912 bytes
2018-10-18 06:25:19.135520 7f6c16313700  1 leveldb: Generated table #209: 221 keys, 2120750 bytes
2018-10-18 06:25:19.152635 7f6c16313700  1 leveldb: Generated table #210: 252 keys, 2129520 bytes
2018-10-18 06:25:19.164127 7f6c16313700  1 leveldb: Generated table #211: 762 keys, 1378617 bytes
2018-10-18 06:25:19.164179 7f6c16313700  1 leveldb: Compacted 1@0 + 4@1 files => 12023833 bytes
2018-10-18 06:25:19.165022 7f6c16313700  1 leveldb: compacted to: files[ 0 6 4 0 0 0 0 ]
2018-10-18 06:25:19.165354 7f6c16313700  1 leveldb: Delete type=2 #202

2018-10-18 06:25:19.166126 7f6c16313700  1 leveldb: Delete type=2 #203

2018-10-18 06:25:19.166811 7f6c16313700  1 leveldb: Delete type=2 #200

2018-10-18 06:25:19.167702 7f6c16313700  1 leveldb: Delete type=2 #201

2018-10-18 06:25:19.168751 7f6c16313700  1 leveldb: Delete type=2 #205

2018-10-18 06:25:19.169859 7f6c16313700  1 leveldb: Expanding@1 1+4 (2118453+6520215 bytes) to 2+4 (4277034+6520215 bytes)

2018-10-18 06:25:19.169887 7f6c16313700  1 leveldb: Compacting 2@1 + 4@2 files
2018-10-18 06:25:19.184435 7f6c16313700  1 leveldb: Generated table #212: 907 keys, 2146116 bytes
2018-10-18 06:25:19.200376 7f6c16313700  1 leveldb: Generated table #213: 156 keys, 2141964 bytes
2018-10-18 06:25:19.213043 7f6c16313700  1 leveldb: Generated table #214: 158 keys, 2162153 bytes
2018-10-18 06:25:19.223767 7f6c16313700  1 leveldb: Generated table #215: 145 keys, 2107309 bytes
2018-10-18 06:25:19.235546 7f6c16313700  1 leveldb: Generated table #216: 327 keys, 2162505 bytes
2018-10-18 06:25:19.240042 7f6c16313700  1 leveldb: Generated table #217: 14 keys, 77153 bytes
2018-10-18 06:25:19.240079 7f6c16313700  1 leveldb: Compacted 2@1 + 4@2 files => 10797200 bytes
2018-10-18 06:25:19.240378 7f6c16313700  1 leveldb: compacted to: files[ 0 4 6 0 0 0 0 ]
2018-10-18 06:25:19.240757 7f6c16313700  1 leveldb: Delete type=2 #194

2018-10-18 06:25:19.241367 7f6c16313700  1 leveldb: Delete type=2 #195

2018-10-18 06:25:19.241800 7f6c16313700  1 leveldb: Delete type=2 #192

2018-10-18 06:25:19.242602 7f6c16313700  1 leveldb: Delete type=2 #193

2018-10-18 06:25:19.243430 7f6c16313700  1 leveldb: Delete type=2 #206

2018-10-18 06:25:19.244260 7f6c16313700  1 leveldb: Delete type=2 #207

2018-10-18 06:25:19.244871 7f6c16313700  1 leveldb: Manual compaction at level-0 from 'pgmap_pg\x006.7' @ 34050 : 1 .. 'pgmap\x00504' @ 0 : 0; will stop at (end)

2018-10-18 06:25:19.245201 7f6c16313700  1 leveldb: Level-0 table #219: started
2018-10-18 06:25:19.253774 7f6c16313700  1 leveldb: Level-0 table #219: 11620 bytes OK
2018-10-18 06:25:19.257276 7f6c16313700  1 leveldb: Delete type=0 #204

2018-10-18 06:25:19.257953 7f6c16313700  1 leveldb: Manual compaction at level-0 from 'pgmap\x00full_252' @ 72057594037927935 : 1 .. 'pgmap\x00full_504' @ 0 : 0; will stop at (end)

2018-10-18 06:25:19.259120 7f6c16313700  1 leveldb: Level-0 table #221: started
2018-10-18 06:25:19.259184 7f6c16313700  1 leveldb: Level-0 table #221: 0 bytes OK
2018-10-18 06:25:19.260815 7f6c16313700  1 leveldb: Delete type=0 #218

2018-10-18 06:25:19.261091 7f6c16313700  1 leveldb: Manual compaction at level-0 from 'paxos\x001757' @ 72057594037927935 : 1 .. 'paxos\x002009' @ 0 : 0; will stop at 'paxos\x00pending_v' @ 35566 : 1

2018-10-18 06:25:19.261116 7f6c16313700  1 leveldb: Compacting 1@0 + 4@1 files
2018-10-18 06:25:19.275257 7f6c16313700  1 leveldb: Generated table #222: 275 keys, 2105316 bytes
2018-10-18 06:25:19.290419 7f6c16313700  1 leveldb: Generated table #223: 252 keys, 2129520 bytes
2018-10-18 06:25:19.309807 7f6c16313700  1 leveldb: Generated table #224: 763 keys, 1386799 bytes
2018-10-18 06:25:19.309856 7f6c16313700  1 leveldb: Compacted 1@0 + 4@1 files => 5621635 bytes
2018-10-18 06:25:19.313369 7f6c16313700  1 leveldb: compacted to: files[ 0 3 6 0 0 0 0 ]
2018-10-18 06:25:19.313707 7f6c16313700  1 leveldb: Delete type=2 #208

2018-10-18 06:25:19.314529 7f6c16313700  1 leveldb: Delete type=2 #209

2018-10-18 06:25:19.315288 7f6c16313700  1 leveldb: Delete type=2 #210

2018-10-18 06:25:19.316045 7f6c16313700  1 leveldb: Delete type=2 #211

2018-10-18 06:25:19.316515 7f6c16313700  1 leveldb: Delete type=2 #219

2018-10-18 06:25:19.317079 7f6c16313700  1 leveldb: Manual compaction at level-0 from 'paxos\x00pending_v' @ 35566 : 1 .. 'paxos\x002009' @ 0 : 0; will stop at (end)

2018-10-18 06:25:20.080040 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v1005: 112 pgs: 112 active+clean; 19288 bytes data, 243 MB used, 398 GB / 399 GB avail; 362 B/s rd, 3620 B/s wr, 10 op/s
2018-10-18 06:25:21.097796 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v1006: 112 pgs: 112 active+clean; 48385 bytes data, 243 MB used, 398 GB / 399 GB avail; 9567 B/s rd, 9026 B/s wr, 34 op/s
2018-10-18 06:25:21.113350 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1215 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 06:25:22.110888 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v1007: 112 pgs: 112 active+clean; 55266 bytes data, 243 MB used, 398 GB / 399 GB avail; 26115 B/s rd, 18582 B/s wr, 77 op/s
2018-10-18 06:25:22.148228 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1216 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 06:25:24.415595 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v1008: 112 pgs: 112 active+clean; 55266 bytes data, 243 MB used, 398 GB / 399 GB avail; 307 B/s rd, 2155 B/s wr, 6 op/s
2018-10-18 06:25:25.429275 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1217 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 06:25:25.441264 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v1009: 112 pgs: 112 active+clean; 55266 bytes data, 243 MB used, 398 GB / 399 GB avail
2018-10-18 06:25:26.464207 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1218 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 06:25:26.474037 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v1010: 112 pgs: 112 active+clean; 55266 bytes data, 243 MB used, 398 GB / 399 GB avail
2018-10-18 06:25:27.494062 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1219 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 06:25:34.021461 7f6c1a901700  0 mon.ceph-node1@0(leader).data_health(226) update_stats avail 69% total 51175 MB, used 15444 MB, avail 35730 MB
2018-10-18 06:25:34.979494 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v1011: 112 pgs: 112 active+clean; 55266 bytes data, 243 MB used, 398 GB / 399 GB avail; 214 B/s rd, 0 B/s wr, 0 op/s
2018-10-18 06:25:36.003926 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1220 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 06:25:36.015370 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v1012: 112 pgs: 112 active+clean; 55266 bytes data, 243 MB used, 398 GB / 399 GB avail; 214 B/s rd, 0 B/s wr, 0 op/s
2018-10-18 06:25:37.034028 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1221 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 06:25:37.054353 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v1013: 112 pgs: 112 active+clean; 55266 bytes data, 243 MB used, 398 GB / 399 GB avail
2018-10-18 06:25:38.074162 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1222 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 06:25:39.994423 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v1014: 112 pgs: 112 active+clean; 55266 bytes data, 243 MB used, 398 GB / 399 GB avail
2018-10-18 06:25:41.017062 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1223 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 06:25:41.034027 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v1015: 112 pgs: 112 active+clean; 55266 bytes data, 243 MB used, 398 GB / 399 GB avail
2018-10-18 06:25:42.047018 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1224 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 06:25:42.063478 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v1016: 112 pgs: 112 active+clean; 55266 bytes data, 243 MB used, 398 GB / 399 GB avail
2018-10-18 06:25:43.075820 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1225 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 06:25:44.426002 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v1017: 112 pgs: 112 active+clean; 55266 bytes data, 243 MB used, 398 GB / 399 GB avail; 16181 B/s rd, 0 B/s wr, 26 op/s
2018-10-18 06:25:45.460373 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1226 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 06:25:45.508473 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v1018: 112 pgs: 112 active+clean; 55266 bytes data, 243 MB used, 398 GB / 399 GB avail; 89792 B/s rd, 0 B/s wr, 146 op/s
2018-10-18 06:25:46.548030 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1227 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 06:25:46.584415 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v1019: 112 pgs: 112 active+clean; 55266 bytes data, 243 MB used, 398 GB / 399 GB avail; 142 kB/s rd, 0 B/s wr, 237 op/s
2018-10-18 06:25:47.611977 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1228 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 06:25:49.419962 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v1020: 112 pgs: 112 active+clean; 55266 bytes data, 243 MB used, 398 GB / 399 GB avail; 16199 B/s rd, 0 B/s wr, 26 op/s
2018-10-18 06:25:50.438497 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1229 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 06:25:50.449877 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v1021: 112 pgs: 112 active+clean; 55266 bytes data, 244 MB used, 398 GB / 399 GB avail; 7587 B/s rd, 0 B/s wr, 12 op/s
2018-10-18 06:25:51.465559 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1230 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 06:25:51.479616 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v1022: 112 pgs: 112 active+clean; 55266 bytes data, 244 MB used, 398 GB / 399 GB avail; 10061 B/s rd, 0 B/s wr, 16 op/s
2018-10-18 06:25:52.498872 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1231 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 06:25:54.435073 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v1023: 112 pgs: 112 active+clean; 55266 bytes data, 244 MB used, 398 GB / 399 GB avail
2018-10-18 06:25:55.452032 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1232 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 06:25:55.466662 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v1024: 112 pgs: 112 active+clean; 55266 bytes data, 244 MB used, 398 GB / 399 GB avail
2018-10-18 06:25:56.488508 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1233 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 06:26:34.022245 7f6c1a901700  0 mon.ceph-node1@0(leader).data_health(226) update_stats avail 69% total 51175 MB, used 15444 MB, avail 35730 MB
2018-10-18 06:26:34.447516 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v1025: 112 pgs: 112 active+clean; 55266 bytes data, 244 MB used, 398 GB / 399 GB avail; 1654 B/s rd, 0 B/s wr, 2 op/s
2018-10-18 06:26:35.456789 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1234 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 06:26:35.475345 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v1026: 112 pgs: 112 active+clean; 55266 bytes data, 244 MB used, 398 GB / 399 GB avail; 8369 B/s rd, 0 B/s wr, 13 op/s
2018-10-18 06:26:36.487609 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v1027: 112 pgs: 112 active+clean; 55266 bytes data, 244 MB used, 398 GB / 399 GB avail; 156 kB/s rd, 0 B/s wr, 260 op/s
2018-10-18 06:26:36.502319 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1235 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 06:26:37.516195 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1236 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 06:26:39.451885 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v1028: 112 pgs: 112 active+clean; 55266 bytes data, 244 MB used, 398 GB / 399 GB avail; 13845 B/s rd, 0 B/s wr, 22 op/s
2018-10-18 06:26:40.472205 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v1029: 112 pgs: 112 active+clean; 55266 bytes data, 245 MB used, 398 GB / 399 GB avail; 514 B/s rd, 0 B/s wr, 1 op/s
2018-10-18 06:26:40.501037 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1237 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 06:26:41.515143 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1238 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 06:26:41.521148 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v1030: 112 pgs: 112 active+clean; 55266 bytes data, 245 MB used, 398 GB / 399 GB avail; 994 B/s rd, 0 B/s wr, 1 op/s
2018-10-18 06:26:42.542129 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1239 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 06:26:44.469021 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v1031: 112 pgs: 112 active+clean; 55266 bytes data, 244 MB used, 398 GB / 399 GB avail
2018-10-18 06:26:45.482832 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v1032: 112 pgs: 112 active+clean; 55266 bytes data, 245 MB used, 398 GB / 399 GB avail
2018-10-18 06:26:45.501220 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1240 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 06:26:46.519492 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1241 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 06:26:46.531615 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v1033: 112 pgs: 112 active+clean; 55266 bytes data, 244 MB used, 398 GB / 399 GB avail
2018-10-18 06:26:47.548082 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1242 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 06:26:50.197174 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v1034: 112 pgs: 112 active+clean; 55266 bytes data, 244 MB used, 398 GB / 399 GB avail
2018-10-18 06:26:51.219348 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1243 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 06:27:04.044147 7f6c1a100700  0 log_channel(cluster) log [WRN] : mon.1 192.168.136.188:6789/0 clock skew 0.723259s > max 0.05s
2018-10-18 06:27:04.044492 7f6c1a100700  0 log_channel(cluster) log [WRN] : mon.2 192.168.136.189:6789/0 clock skew 7.52459s > max 0.05s
2018-10-18 06:27:04.117748 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1244 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 06:27:34.022769 7f6c1a901700  0 mon.ceph-node1@0(leader).data_health(226) update_stats avail 69% total 51175 MB, used 15445 MB, avail 35729 MB
2018-10-18 06:28:21.208149 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v1035: 112 pgs: 112 active+clean; 55266 bytes data, 244 MB used, 398 GB / 399 GB avail
2018-10-18 06:28:22.223589 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1245 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 06:28:26.214342 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v1036: 112 pgs: 112 active+clean; 55266 bytes data, 244 MB used, 398 GB / 399 GB avail
2018-10-18 06:28:27.224162 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1246 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 06:28:34.023318 7f6c1a901700  0 mon.ceph-node1@0(leader).data_health(226) update_stats avail 69% total 51175 MB, used 15445 MB, avail 35729 MB
2018-10-18 06:29:34.023782 7f6c1a901700  0 mon.ceph-node1@0(leader).data_health(226) update_stats avail 69% total 51175 MB, used 15448 MB, avail 35726 MB
2018-10-18 06:30:04.052910 7f6c1a100700  0 log_channel(cluster) log [WRN] : mon.1 192.168.136.188:6789/0 clock skew 0.721069s > max 0.05s
2018-10-18 06:30:04.054967 7f6c1a100700  0 log_channel(cluster) log [WRN] : mon.2 192.168.136.189:6789/0 clock skew 7.52045s > max 0.05s
2018-10-18 06:30:04.116093 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1247 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 06:30:34.024192 7f6c1a901700  0 mon.ceph-node1@0(leader).data_health(226) update_stats avail 69% total 51175 MB, used 15448 MB, avail 35726 MB
2018-10-18 06:31:10.335086 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v1037: 112 pgs: 112 active+clean; 55266 bytes data, 244 MB used, 398 GB / 399 GB avail
2018-10-18 06:31:11.345913 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1248 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 06:31:11.361121 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v1038: 112 pgs: 112 active+clean; 55266 bytes data, 244 MB used, 398 GB / 399 GB avail
2018-10-18 06:31:12.369587 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1249 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 06:31:14.587408 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v1039: 112 pgs: 112 active+clean; 55266 bytes data, 244 MB used, 398 GB / 399 GB avail
2018-10-18 06:31:15.597341 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1250 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 06:31:15.613573 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v1040: 112 pgs: 112 active+clean; 55266 bytes data, 244 MB used, 398 GB / 399 GB avail
2018-10-18 06:31:16.624207 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1251 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 06:31:34.024608 7f6c1a901700  0 mon.ceph-node1@0(leader).data_health(226) update_stats avail 69% total 51175 MB, used 15449 MB, avail 35725 MB
2018-10-18 06:32:34.025129 7f6c1a901700  0 mon.ceph-node1@0(leader).data_health(226) update_stats avail 69% total 51175 MB, used 15449 MB, avail 35725 MB
2018-10-18 06:32:35.205426 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v1041: 112 pgs: 112 active+clean; 55266 bytes data, 244 MB used, 398 GB / 399 GB avail
2018-10-18 06:32:36.214165 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1252 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 06:32:36.222269 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v1042: 112 pgs: 112 active+clean; 55266 bytes data, 245 MB used, 398 GB / 399 GB avail; 495 B/s rd, 0 B/s wr, 0 op/s
2018-10-18 06:32:37.235885 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1253 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 06:32:37.249415 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v1043: 112 pgs: 112 active+clean; 55266 bytes data, 245 MB used, 398 GB / 399 GB avail; 42534 B/s rd, 0 B/s wr, 69 op/s
2018-10-18 06:32:38.262851 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1254 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 06:32:39.110797 7f6c16313700  1 leveldb: Level-0 table #226: started
2018-10-18 06:32:39.119753 7f6c16313700  1 leveldb: Level-0 table #226: 1316463 bytes OK
2018-10-18 06:32:39.121450 7f6c16313700  1 leveldb: Delete type=0 #220

2018-10-18 06:32:39.122410 7f6c16313700  1 leveldb: Manual compaction at level-0 from 'logm\x00501' @ 72057594037927935 : 1 .. 'logm\x00754' @ 0 : 0; will stop at 'pgmap_pg\x006.7' @ 35848 : 1

2018-10-18 06:32:39.122431 7f6c16313700  1 leveldb: Compacting 1@0 + 3@1 files
2018-10-18 06:32:39.137122 7f6c16313700  1 leveldb: Generated table #227: 807 keys, 2128516 bytes
2018-10-18 06:32:39.150132 7f6c16313700  1 leveldb: Generated table #228: 233 keys, 2114591 bytes
2018-10-18 06:32:39.166780 7f6c16313700  1 leveldb: Generated table #229: 233 keys, 2108249 bytes
2018-10-18 06:32:39.173527 7f6c16313700  1 leveldb: Generated table #230: 723 keys, 546819 bytes
2018-10-18 06:32:39.173604 7f6c16313700  1 leveldb: Compacted 1@0 + 3@1 files => 6898175 bytes
2018-10-18 06:32:39.174197 7f6c16313700  1 leveldb: compacted to: files[ 0 4 6 0 0 0 0 ]
2018-10-18 06:32:39.174672 7f6c16313700  1 leveldb: Delete type=2 #222

2018-10-18 06:32:39.175618 7f6c16313700  1 leveldb: Delete type=2 #223

2018-10-18 06:32:39.176417 7f6c16313700  1 leveldb: Delete type=2 #224

2018-10-18 06:32:39.177072 7f6c16313700  1 leveldb: Delete type=2 #226

2018-10-18 06:32:39.177575 7f6c16313700  1 leveldb: Manual compaction at level-0 from 'pgmap_pg\x006.7' @ 35848 : 1 .. 'logm\x00754' @ 0 : 0; will stop at (end)

2018-10-18 06:32:39.177976 7f6c16313700  1 leveldb: Manual compaction at level-1 from 'logm\x00501' @ 72057594037927935 : 1 .. 'logm\x00754' @ 0 : 0; will stop at 'paxos\x002073' @ 29373 : 1

2018-10-18 06:32:39.178001 7f6c16313700  1 leveldb: Compacting 1@1 + 6@2 files
2018-10-18 06:32:39.205079 7f6c16313700  1 leveldb: Generated table #231: 704 keys, 2153147 bytes
2018-10-18 06:32:39.218162 7f6c16313700  1 leveldb: Generated table #232: 150 keys, 2149061 bytes
2018-10-18 06:32:39.230299 7f6c16313700  1 leveldb: Generated table #233: 145 keys, 2112711 bytes
2018-10-18 06:32:39.242964 7f6c16313700  1 leveldb: Generated table #234: 414 keys, 2122185 bytes
2018-10-18 06:32:39.248157 7f6c16313700  1 leveldb: Generated table #235: 90 keys, 810464 bytes
2018-10-18 06:32:39.248193 7f6c16313700  1 leveldb: Compacted 1@1 + 6@2 files => 9347568 bytes
2018-10-18 06:32:39.248466 7f6c16313700  1 leveldb: compacted to: files[ 0 3 5 0 0 0 0 ]
2018-10-18 06:32:39.248785 7f6c16313700  1 leveldb: Delete type=2 #213

2018-10-18 06:32:39.249508 7f6c16313700  1 leveldb: Delete type=2 #214

2018-10-18 06:32:39.250727 7f6c16313700  1 leveldb: Delete type=2 #215

2018-10-18 06:32:39.251626 7f6c16313700  1 leveldb: Delete type=2 #216

2018-10-18 06:32:39.252274 7f6c16313700  1 leveldb: Delete type=2 #217

2018-10-18 06:32:39.252707 7f6c16313700  1 leveldb: Delete type=2 #212

2018-10-18 06:32:39.253586 7f6c16313700  1 leveldb: Delete type=2 #227

2018-10-18 06:32:39.255011 7f6c16313700  1 leveldb: Manual compaction at level-1 from 'paxos\x002073' @ 29373 : 1 .. 'logm\x00754' @ 0 : 0; will stop at (end)

2018-10-18 06:32:39.255322 7f6c16313700  1 leveldb: Level-0 table #237: started
2018-10-18 06:32:39.255382 7f6c16313700  1 leveldb: Level-0 table #237: 0 bytes OK
2018-10-18 06:32:39.256022 7f6c16313700  1 leveldb: Delete type=0 #225

2018-10-18 06:32:39.256178 7f6c16313700  1 leveldb: Manual compaction at level-0 from 'logm\x00full_501' @ 72057594037927935 : 1 .. 'logm\x00full_754' @ 0 : 0; will stop at (end)

2018-10-18 06:32:39.256296 7f6c16313700  1 leveldb: Manual compaction at level-1 from 'logm\x00full_501' @ 72057594037927935 : 1 .. 'logm\x00full_754' @ 0 : 0; will stop at (end)

2018-10-18 06:32:40.121988 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v1044: 112 pgs: 112 active+clean; 55266 bytes data, 245 MB used, 398 GB / 399 GB avail; 54312 B/s rd, 0 B/s wr, 88 op/s
2018-10-18 06:32:41.153745 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1255 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 06:32:41.173216 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v1045: 112 pgs: 112 active+clean; 55266 bytes data, 245 MB used, 398 GB / 399 GB avail; 75505 B/s rd, 0 B/s wr, 122 op/s
2018-10-18 06:32:42.185792 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1256 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 06:32:42.198227 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v1046: 112 pgs: 112 active+clean; 55266 bytes data, 245 MB used, 398 GB / 399 GB avail; 66855 B/s rd, 0 B/s wr, 108 op/s
2018-10-18 06:32:43.227049 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1257 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 06:32:44.612041 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v1047: 112 pgs: 112 active+clean; 55266 bytes data, 245 MB used, 398 GB / 399 GB avail; 2653 B/s rd, 0 B/s wr, 4 op/s
2018-10-18 06:32:45.617460 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1258 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 06:32:45.627997 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v1048: 112 pgs: 112 active+clean; 55266 bytes data, 245 MB used, 398 GB / 399 GB avail
2018-10-18 06:32:46.640791 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1259 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 06:32:46.661293 7f6c1c2d1700  0 log_channel(cluster) log [INF] : pgmap v1049: 112 pgs: 112 active+clean; 55266 bytes data, 245 MB used, 398 GB / 399 GB avail
2018-10-18 06:32:47.671886 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1260 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
2018-10-18 06:33:34.025774 7f6c1a901700  0 mon.ceph-node1@0(leader).data_health(226) update_stats avail 69% total 51175 MB, used 15446 MB, avail 35728 MB
2018-10-18 06:33:34.060637 7f6c1a100700  0 log_channel(cluster) log [WRN] : mon.1 192.168.136.188:6789/0 clock skew 0.72189s > max 0.05s
2018-10-18 06:33:34.060786 7f6c1a100700  0 log_channel(cluster) log [WRN] : mon.2 192.168.136.189:6789/0 clock skew 7.5241s > max 0.05s
2018-10-18 06:33:34.138792 7f6c1c2d1700  1 mon.ceph-node1@0(leader).log v1261 unable to write to '/var/log/ceph/ceph.log' for channel 'cluster': (2) No such file or directory
